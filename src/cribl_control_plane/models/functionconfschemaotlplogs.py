"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import Any, List, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class OTLPLogsBatchOTLPLogsTrueTypedDict(TypedDict):
    batch_otlp_logs: NotRequired[bool]
    r"""Batch OTLP log records by shared top-level `resource` attributes"""
    send_batch_size: NotRequired[float]
    r"""Number of log records after which a batch will be sent, regardless of the timeout"""
    timeout: NotRequired[float]
    r"""Time duration after which a batch will be sent, regardless of size"""
    send_batch_max_size: NotRequired[float]
    r"""Maximum batch size. Enter 0 for no maximum."""
    metadata_keys: NotRequired[List[Any]]
    r"""When set, this processor will create one batcher instance per distinct combination of values in the metadata"""
    metadata_cardinality_limit: NotRequired[float]
    r"""Limit the number of unique combinations of metadata key values that will be processed over the lifetime of the process. After the limit is reached, events with new metadata key value combinations will be dropped."""
    drop_non_log_events: NotRequired[bool]


class OTLPLogsBatchOTLPLogsTrue(BaseModel):
    batch_otlp_logs: Annotated[
        Optional[bool], pydantic.Field(alias="batchOTLPLogs")
    ] = None
    r"""Batch OTLP log records by shared top-level `resource` attributes"""

    send_batch_size: Annotated[
        Optional[float], pydantic.Field(alias="sendBatchSize")
    ] = None
    r"""Number of log records after which a batch will be sent, regardless of the timeout"""

    timeout: Optional[float] = None
    r"""Time duration after which a batch will be sent, regardless of size"""

    send_batch_max_size: Annotated[
        Optional[float], pydantic.Field(alias="sendBatchMaxSize")
    ] = None
    r"""Maximum batch size. Enter 0 for no maximum."""

    metadata_keys: Annotated[
        Optional[List[Any]], pydantic.Field(alias="metadataKeys")
    ] = None
    r"""When set, this processor will create one batcher instance per distinct combination of values in the metadata"""

    metadata_cardinality_limit: Annotated[
        Optional[float], pydantic.Field(alias="metadataCardinalityLimit")
    ] = None
    r"""Limit the number of unique combinations of metadata key values that will be processed over the lifetime of the process. After the limit is reached, events with new metadata key value combinations will be dropped."""

    drop_non_log_events: Annotated[
        Optional[bool], pydantic.Field(alias="dropNonLogEvents")
    ] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "batchOTLPLogs",
                "sendBatchSize",
                "timeout",
                "sendBatchMaxSize",
                "metadataKeys",
                "metadataCardinalityLimit",
                "dropNonLogEvents",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class OTLPLogsBatchOTLPLogsFalseTypedDict(TypedDict):
    batch_otlp_logs: NotRequired[bool]
    r"""Batch OTLP log records by shared top-level `resource` attributes"""
    drop_non_log_events: NotRequired[bool]


class OTLPLogsBatchOTLPLogsFalse(BaseModel):
    batch_otlp_logs: Annotated[
        Optional[bool], pydantic.Field(alias="batchOTLPLogs")
    ] = None
    r"""Batch OTLP log records by shared top-level `resource` attributes"""

    drop_non_log_events: Annotated[
        Optional[bool], pydantic.Field(alias="dropNonLogEvents")
    ] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["batchOTLPLogs", "dropNonLogEvents"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


FunctionConfSchemaOtlpLogsTypedDict = TypeAliasType(
    "FunctionConfSchemaOtlpLogsTypedDict",
    Union[OTLPLogsBatchOTLPLogsFalseTypedDict, OTLPLogsBatchOTLPLogsTrueTypedDict],
)


FunctionConfSchemaOtlpLogs = TypeAliasType(
    "FunctionConfSchemaOtlpLogs",
    Union[OTLPLogsBatchOTLPLogsFalse, OTLPLogsBatchOTLPLogsTrue],
)
