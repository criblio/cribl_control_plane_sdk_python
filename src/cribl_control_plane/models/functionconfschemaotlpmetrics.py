"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .otlpversionoptions import OtlpVersionOptions
from cribl_control_plane import models
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import field_serializer, model_serializer
from typing import Any, List, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class OTLPMetricsBatchOTLPMetricsTrueTypedDict(TypedDict):
    batch_otlp_metrics: NotRequired[bool]
    r"""Batch OTLP metrics by shared top-level `resource` attributes"""
    send_batch_size: NotRequired[float]
    r"""Number of metric data points after which a batch will be sent, regardless of the timeout"""
    timeout: NotRequired[float]
    r"""Time duration after which a batch will be sent, regardless of size"""
    send_batch_max_size: NotRequired[float]
    r"""Maximum batch size. Enter 0 for no maximum."""
    metadata_keys: NotRequired[List[Any]]
    r"""When set, this processor will create one batcher instance per distinct combination of values in the metadata"""
    metadata_cardinality_limit: NotRequired[float]
    r"""Limit the number of unique combinations of metadata key values that will be processed over the lifetime of the process. After the limit is reached, events with new metadata key value combinations will be dropped."""
    resource_attribute_prefixes: NotRequired[List[str]]
    r"""The prefixes of top-level attributes to add as resource attributes. Each attribute must match the regex pattern `^[a-zA-Z0-9_\.]+$`. Use Eval to copy nested attributes to the top level for matching."""
    drop_non_metric_events: NotRequired[bool]
    otlp_version: NotRequired[OtlpVersionOptions]


class OTLPMetricsBatchOTLPMetricsTrue(BaseModel):
    batch_otlp_metrics: Annotated[
        Optional[bool], pydantic.Field(alias="batchOTLPMetrics")
    ] = None
    r"""Batch OTLP metrics by shared top-level `resource` attributes"""

    send_batch_size: Annotated[
        Optional[float], pydantic.Field(alias="sendBatchSize")
    ] = None
    r"""Number of metric data points after which a batch will be sent, regardless of the timeout"""

    timeout: Optional[float] = None
    r"""Time duration after which a batch will be sent, regardless of size"""

    send_batch_max_size: Annotated[
        Optional[float], pydantic.Field(alias="sendBatchMaxSize")
    ] = None
    r"""Maximum batch size. Enter 0 for no maximum."""

    metadata_keys: Annotated[
        Optional[List[Any]], pydantic.Field(alias="metadataKeys")
    ] = None
    r"""When set, this processor will create one batcher instance per distinct combination of values in the metadata"""

    metadata_cardinality_limit: Annotated[
        Optional[float], pydantic.Field(alias="metadataCardinalityLimit")
    ] = None
    r"""Limit the number of unique combinations of metadata key values that will be processed over the lifetime of the process. After the limit is reached, events with new metadata key value combinations will be dropped."""

    resource_attribute_prefixes: Annotated[
        Optional[List[str]], pydantic.Field(alias="resourceAttributePrefixes")
    ] = None
    r"""The prefixes of top-level attributes to add as resource attributes. Each attribute must match the regex pattern `^[a-zA-Z0-9_\.]+$`. Use Eval to copy nested attributes to the top level for matching."""

    drop_non_metric_events: Annotated[
        Optional[bool], pydantic.Field(alias="dropNonMetricEvents")
    ] = None

    otlp_version: Annotated[
        Optional[OtlpVersionOptions], pydantic.Field(alias="otlpVersion")
    ] = None

    @field_serializer("otlp_version")
    def serialize_otlp_version(self, value):
        if isinstance(value, str):
            try:
                return models.OtlpVersionOptions(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "batchOTLPMetrics",
                "sendBatchSize",
                "timeout",
                "sendBatchMaxSize",
                "metadataKeys",
                "metadataCardinalityLimit",
                "resourceAttributePrefixes",
                "dropNonMetricEvents",
                "otlpVersion",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class OTLPMetricsBatchOTLPMetricsFalseTypedDict(TypedDict):
    batch_otlp_metrics: NotRequired[bool]
    r"""Batch OTLP metrics by shared top-level `resource` attributes"""
    resource_attribute_prefixes: NotRequired[List[str]]
    r"""The prefixes of top-level attributes to add as resource attributes. Each attribute must match the regex pattern `^[a-zA-Z0-9_\.]+$`. Use Eval to copy nested attributes to the top level for matching."""
    drop_non_metric_events: NotRequired[bool]
    otlp_version: NotRequired[OtlpVersionOptions]


class OTLPMetricsBatchOTLPMetricsFalse(BaseModel):
    batch_otlp_metrics: Annotated[
        Optional[bool], pydantic.Field(alias="batchOTLPMetrics")
    ] = None
    r"""Batch OTLP metrics by shared top-level `resource` attributes"""

    resource_attribute_prefixes: Annotated[
        Optional[List[str]], pydantic.Field(alias="resourceAttributePrefixes")
    ] = None
    r"""The prefixes of top-level attributes to add as resource attributes. Each attribute must match the regex pattern `^[a-zA-Z0-9_\.]+$`. Use Eval to copy nested attributes to the top level for matching."""

    drop_non_metric_events: Annotated[
        Optional[bool], pydantic.Field(alias="dropNonMetricEvents")
    ] = None

    otlp_version: Annotated[
        Optional[OtlpVersionOptions], pydantic.Field(alias="otlpVersion")
    ] = None

    @field_serializer("otlp_version")
    def serialize_otlp_version(self, value):
        if isinstance(value, str):
            try:
                return models.OtlpVersionOptions(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "batchOTLPMetrics",
                "resourceAttributePrefixes",
                "dropNonMetricEvents",
                "otlpVersion",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


FunctionConfSchemaOtlpMetricsTypedDict = TypeAliasType(
    "FunctionConfSchemaOtlpMetricsTypedDict",
    Union[
        OTLPMetricsBatchOTLPMetricsFalseTypedDict,
        OTLPMetricsBatchOTLPMetricsTrueTypedDict,
    ],
)


FunctionConfSchemaOtlpMetrics = TypeAliasType(
    "FunctionConfSchemaOtlpMetrics",
    Union[OTLPMetricsBatchOTLPMetricsFalse, OTLPMetricsBatchOTLPMetricsTrue],
)


try:
    OTLPMetricsBatchOTLPMetricsTrue.model_rebuild()
except NameError:
    pass
try:
    OTLPMetricsBatchOTLPMetricsFalse.model_rebuild()
except NameError:
    pass
