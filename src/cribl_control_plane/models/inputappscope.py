"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .authtype2options import AuthType2Options
from .connectionstype import ConnectionsType, ConnectionsTypeTypedDict
from .metadata1type import Metadata1Type, Metadata1TypeTypedDict
from .persistence1type import Persistence1Type, Persistence1TypeTypedDict
from .pqtype import PqType, PqTypeTypedDict
from .tls2type import Tls2Type, Tls2TypeTypedDict
from cribl_control_plane import models
from cribl_control_plane.types import BaseModel
from cribl_control_plane.utils import validate_open_enum
from enum import Enum
import pydantic
from pydantic import field_serializer
from pydantic.functional_validators import PlainValidator
from typing import List, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class InputAppscopeType8(str, Enum):
    APPSCOPE = "appscope"


class Allow8TypedDict(TypedDict):
    procname: str
    r"""Specify the name of a process or family of processes."""
    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""
    arg: NotRequired[str]
    r"""Specify a string to substring-match against process command-line."""


class Allow8(BaseModel):
    procname: str
    r"""Specify the name of a process or family of processes."""

    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""

    arg: Optional[str] = None
    r"""Specify a string to substring-match against process command-line."""


class InputAppscopeFilter8TypedDict(TypedDict):
    allow: NotRequired[List[Allow8TypedDict]]
    r"""Specify processes that AppScope should be loaded into, and the config to use."""
    transport_url: NotRequired[str]
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeFilter8(BaseModel):
    allow: Optional[List[Allow8]] = None
    r"""Specify processes that AppScope should be loaded into, and the config to use."""

    transport_url: Annotated[Optional[str], pydantic.Field(alias="transportURL")] = None
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeAppscope8TypedDict(TypedDict):
    type: InputAppscopeType8
    text_secret: str
    r"""Select or create a stored text secret"""
    auth_type: NotRequired[AuthType2Options]
    r"""Enter credentials directly, or select a stored secret"""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    ip_whitelist_regex: NotRequired[str]
    r"""Regex matching IP addresses that are allowed to establish a connection"""
    max_active_cxn: NotRequired[float]
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""
    socket_idle_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""
    socket_ending_max_wait: NotRequired[float]
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""
    socket_max_lifespan: NotRequired[float]
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    breaker_rulesets: NotRequired[List[str]]
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""
    stale_channel_flush_ms: NotRequired[float]
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""
    enable_unix_path: NotRequired[bool]
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""
    filter_: NotRequired[InputAppscopeFilter8TypedDict]
    persistence: NotRequired[Persistence1TypeTypedDict]
    description: NotRequired[str]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: NotRequired[float]
    r"""Port to listen on"""
    tls: NotRequired[Tls2TypeTypedDict]
    unix_socket_path: NotRequired[str]
    r"""Path to the UNIX domain socket to listen on."""
    unix_socket_perms: NotRequired[str]
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""
    auth_token: NotRequired[str]
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""


class InputAppscopeAppscope8(BaseModel):
    type: InputAppscopeType8

    text_secret: Annotated[str, pydantic.Field(alias="textSecret")]
    r"""Select or create a stored text secret"""

    auth_type: Annotated[
        Annotated[
            Optional[AuthType2Options], PlainValidator(validate_open_enum(False))
        ],
        pydantic.Field(alias="authType"),
    ] = AuthType2Options.MANUAL
    r"""Enter credentials directly, or select a stored secret"""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    ip_whitelist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipWhitelistRegex")
    ] = "/.*/"
    r"""Regex matching IP addresses that are allowed to establish a connection"""

    max_active_cxn: Annotated[Optional[float], pydantic.Field(alias="maxActiveCxn")] = (
        1000
    )
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""

    socket_idle_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketIdleTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""

    socket_ending_max_wait: Annotated[
        Optional[float], pydantic.Field(alias="socketEndingMaxWait")
    ] = 30
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""

    socket_max_lifespan: Annotated[
        Optional[float], pydantic.Field(alias="socketMaxLifespan")
    ] = 0
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    breaker_rulesets: Annotated[
        Optional[List[str]], pydantic.Field(alias="breakerRulesets")
    ] = None
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""

    stale_channel_flush_ms: Annotated[
        Optional[float], pydantic.Field(alias="staleChannelFlushMs")
    ] = 10000
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""

    enable_unix_path: Annotated[
        Optional[bool], pydantic.Field(alias="enableUnixPath")
    ] = False
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""

    filter_: Annotated[
        Optional[InputAppscopeFilter8], pydantic.Field(alias="filter")
    ] = None

    persistence: Optional[Persistence1Type] = None

    description: Optional[str] = None

    host: Optional[str] = None
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: Optional[float] = None
    r"""Port to listen on"""

    tls: Optional[Tls2Type] = None

    unix_socket_path: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPath")
    ] = "$CRIBL_HOME/state/appscope.sock"
    r"""Path to the UNIX domain socket to listen on."""

    unix_socket_perms: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPerms")
    ] = None
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""

    auth_token: Annotated[Optional[str], pydantic.Field(alias="authToken")] = ""
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthType2Options(value)
            except ValueError:
                return value
        return value


class InputAppscopeType7(str, Enum):
    APPSCOPE = "appscope"


class Allow7TypedDict(TypedDict):
    procname: str
    r"""Specify the name of a process or family of processes."""
    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""
    arg: NotRequired[str]
    r"""Specify a string to substring-match against process command-line."""


class Allow7(BaseModel):
    procname: str
    r"""Specify the name of a process or family of processes."""

    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""

    arg: Optional[str] = None
    r"""Specify a string to substring-match against process command-line."""


class InputAppscopeFilter7TypedDict(TypedDict):
    allow: NotRequired[List[Allow7TypedDict]]
    r"""Specify processes that AppScope should be loaded into, and the config to use."""
    transport_url: NotRequired[str]
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeFilter7(BaseModel):
    allow: Optional[List[Allow7]] = None
    r"""Specify processes that AppScope should be loaded into, and the config to use."""

    transport_url: Annotated[Optional[str], pydantic.Field(alias="transportURL")] = None
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeAppscope7TypedDict(TypedDict):
    type: InputAppscopeType7
    auth_type: NotRequired[AuthType2Options]
    r"""Enter credentials directly, or select a stored secret"""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    ip_whitelist_regex: NotRequired[str]
    r"""Regex matching IP addresses that are allowed to establish a connection"""
    max_active_cxn: NotRequired[float]
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""
    socket_idle_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""
    socket_ending_max_wait: NotRequired[float]
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""
    socket_max_lifespan: NotRequired[float]
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    breaker_rulesets: NotRequired[List[str]]
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""
    stale_channel_flush_ms: NotRequired[float]
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""
    enable_unix_path: NotRequired[bool]
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""
    filter_: NotRequired[InputAppscopeFilter7TypedDict]
    persistence: NotRequired[Persistence1TypeTypedDict]
    description: NotRequired[str]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: NotRequired[float]
    r"""Port to listen on"""
    tls: NotRequired[Tls2TypeTypedDict]
    unix_socket_path: NotRequired[str]
    r"""Path to the UNIX domain socket to listen on."""
    unix_socket_perms: NotRequired[str]
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""
    auth_token: NotRequired[str]
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""
    text_secret: NotRequired[str]
    r"""Select or create a stored text secret"""


class InputAppscopeAppscope7(BaseModel):
    type: InputAppscopeType7

    auth_type: Annotated[
        Annotated[
            Optional[AuthType2Options], PlainValidator(validate_open_enum(False))
        ],
        pydantic.Field(alias="authType"),
    ] = AuthType2Options.MANUAL
    r"""Enter credentials directly, or select a stored secret"""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    ip_whitelist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipWhitelistRegex")
    ] = "/.*/"
    r"""Regex matching IP addresses that are allowed to establish a connection"""

    max_active_cxn: Annotated[Optional[float], pydantic.Field(alias="maxActiveCxn")] = (
        1000
    )
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""

    socket_idle_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketIdleTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""

    socket_ending_max_wait: Annotated[
        Optional[float], pydantic.Field(alias="socketEndingMaxWait")
    ] = 30
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""

    socket_max_lifespan: Annotated[
        Optional[float], pydantic.Field(alias="socketMaxLifespan")
    ] = 0
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    breaker_rulesets: Annotated[
        Optional[List[str]], pydantic.Field(alias="breakerRulesets")
    ] = None
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""

    stale_channel_flush_ms: Annotated[
        Optional[float], pydantic.Field(alias="staleChannelFlushMs")
    ] = 10000
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""

    enable_unix_path: Annotated[
        Optional[bool], pydantic.Field(alias="enableUnixPath")
    ] = False
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""

    filter_: Annotated[
        Optional[InputAppscopeFilter7], pydantic.Field(alias="filter")
    ] = None

    persistence: Optional[Persistence1Type] = None

    description: Optional[str] = None

    host: Optional[str] = None
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: Optional[float] = None
    r"""Port to listen on"""

    tls: Optional[Tls2Type] = None

    unix_socket_path: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPath")
    ] = "$CRIBL_HOME/state/appscope.sock"
    r"""Path to the UNIX domain socket to listen on."""

    unix_socket_perms: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPerms")
    ] = None
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""

    auth_token: Annotated[Optional[str], pydantic.Field(alias="authToken")] = ""
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""

    text_secret: Annotated[Optional[str], pydantic.Field(alias="textSecret")] = None
    r"""Select or create a stored text secret"""

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthType2Options(value)
            except ValueError:
                return value
        return value


class InputAppscopeType6(str, Enum):
    APPSCOPE = "appscope"


class Allow6TypedDict(TypedDict):
    procname: str
    r"""Specify the name of a process or family of processes."""
    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""
    arg: NotRequired[str]
    r"""Specify a string to substring-match against process command-line."""


class Allow6(BaseModel):
    procname: str
    r"""Specify the name of a process or family of processes."""

    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""

    arg: Optional[str] = None
    r"""Specify a string to substring-match against process command-line."""


class InputAppscopeFilter6TypedDict(TypedDict):
    allow: NotRequired[List[Allow6TypedDict]]
    r"""Specify processes that AppScope should be loaded into, and the config to use."""
    transport_url: NotRequired[str]
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeFilter6(BaseModel):
    allow: Optional[List[Allow6]] = None
    r"""Specify processes that AppScope should be loaded into, and the config to use."""

    transport_url: Annotated[Optional[str], pydantic.Field(alias="transportURL")] = None
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeAppscope6TypedDict(TypedDict):
    type: InputAppscopeType6
    unix_socket_perms: str
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""
    enable_unix_path: NotRequired[bool]
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    ip_whitelist_regex: NotRequired[str]
    r"""Regex matching IP addresses that are allowed to establish a connection"""
    max_active_cxn: NotRequired[float]
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""
    socket_idle_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""
    socket_ending_max_wait: NotRequired[float]
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""
    socket_max_lifespan: NotRequired[float]
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    breaker_rulesets: NotRequired[List[str]]
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""
    stale_channel_flush_ms: NotRequired[float]
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""
    filter_: NotRequired[InputAppscopeFilter6TypedDict]
    persistence: NotRequired[Persistence1TypeTypedDict]
    auth_type: NotRequired[AuthType2Options]
    r"""Enter credentials directly, or select a stored secret"""
    description: NotRequired[str]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: NotRequired[float]
    r"""Port to listen on"""
    tls: NotRequired[Tls2TypeTypedDict]
    unix_socket_path: NotRequired[str]
    r"""Path to the UNIX domain socket to listen on."""
    auth_token: NotRequired[str]
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""
    text_secret: NotRequired[str]
    r"""Select or create a stored text secret"""


class InputAppscopeAppscope6(BaseModel):
    type: InputAppscopeType6

    unix_socket_perms: Annotated[str, pydantic.Field(alias="unixSocketPerms")]
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""

    enable_unix_path: Annotated[
        Optional[bool], pydantic.Field(alias="enableUnixPath")
    ] = False
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    ip_whitelist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipWhitelistRegex")
    ] = "/.*/"
    r"""Regex matching IP addresses that are allowed to establish a connection"""

    max_active_cxn: Annotated[Optional[float], pydantic.Field(alias="maxActiveCxn")] = (
        1000
    )
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""

    socket_idle_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketIdleTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""

    socket_ending_max_wait: Annotated[
        Optional[float], pydantic.Field(alias="socketEndingMaxWait")
    ] = 30
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""

    socket_max_lifespan: Annotated[
        Optional[float], pydantic.Field(alias="socketMaxLifespan")
    ] = 0
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    breaker_rulesets: Annotated[
        Optional[List[str]], pydantic.Field(alias="breakerRulesets")
    ] = None
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""

    stale_channel_flush_ms: Annotated[
        Optional[float], pydantic.Field(alias="staleChannelFlushMs")
    ] = 10000
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""

    filter_: Annotated[
        Optional[InputAppscopeFilter6], pydantic.Field(alias="filter")
    ] = None

    persistence: Optional[Persistence1Type] = None

    auth_type: Annotated[
        Annotated[
            Optional[AuthType2Options], PlainValidator(validate_open_enum(False))
        ],
        pydantic.Field(alias="authType"),
    ] = AuthType2Options.MANUAL
    r"""Enter credentials directly, or select a stored secret"""

    description: Optional[str] = None

    host: Optional[str] = None
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: Optional[float] = None
    r"""Port to listen on"""

    tls: Optional[Tls2Type] = None

    unix_socket_path: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPath")
    ] = "$CRIBL_HOME/state/appscope.sock"
    r"""Path to the UNIX domain socket to listen on."""

    auth_token: Annotated[Optional[str], pydantic.Field(alias="authToken")] = ""
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""

    text_secret: Annotated[Optional[str], pydantic.Field(alias="textSecret")] = None
    r"""Select or create a stored text secret"""

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthType2Options(value)
            except ValueError:
                return value
        return value


class InputAppscopeType5(str, Enum):
    APPSCOPE = "appscope"


class Allow5TypedDict(TypedDict):
    procname: str
    r"""Specify the name of a process or family of processes."""
    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""
    arg: NotRequired[str]
    r"""Specify a string to substring-match against process command-line."""


class Allow5(BaseModel):
    procname: str
    r"""Specify the name of a process or family of processes."""

    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""

    arg: Optional[str] = None
    r"""Specify a string to substring-match against process command-line."""


class InputAppscopeFilter5TypedDict(TypedDict):
    allow: NotRequired[List[Allow5TypedDict]]
    r"""Specify processes that AppScope should be loaded into, and the config to use."""
    transport_url: NotRequired[str]
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeFilter5(BaseModel):
    allow: Optional[List[Allow5]] = None
    r"""Specify processes that AppScope should be loaded into, and the config to use."""

    transport_url: Annotated[Optional[str], pydantic.Field(alias="transportURL")] = None
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeAppscope5TypedDict(TypedDict):
    type: InputAppscopeType5
    host: str
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: float
    r"""Port to listen on"""
    tls: Tls2TypeTypedDict
    enable_unix_path: NotRequired[bool]
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    ip_whitelist_regex: NotRequired[str]
    r"""Regex matching IP addresses that are allowed to establish a connection"""
    max_active_cxn: NotRequired[float]
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""
    socket_idle_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""
    socket_ending_max_wait: NotRequired[float]
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""
    socket_max_lifespan: NotRequired[float]
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    breaker_rulesets: NotRequired[List[str]]
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""
    stale_channel_flush_ms: NotRequired[float]
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""
    filter_: NotRequired[InputAppscopeFilter5TypedDict]
    persistence: NotRequired[Persistence1TypeTypedDict]
    auth_type: NotRequired[AuthType2Options]
    r"""Enter credentials directly, or select a stored secret"""
    description: NotRequired[str]
    unix_socket_path: NotRequired[str]
    r"""Path to the UNIX domain socket to listen on."""
    unix_socket_perms: NotRequired[str]
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""
    auth_token: NotRequired[str]
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""
    text_secret: NotRequired[str]
    r"""Select or create a stored text secret"""


class InputAppscopeAppscope5(BaseModel):
    type: InputAppscopeType5

    host: str
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: float
    r"""Port to listen on"""

    tls: Tls2Type

    enable_unix_path: Annotated[
        Optional[bool], pydantic.Field(alias="enableUnixPath")
    ] = False
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    ip_whitelist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipWhitelistRegex")
    ] = "/.*/"
    r"""Regex matching IP addresses that are allowed to establish a connection"""

    max_active_cxn: Annotated[Optional[float], pydantic.Field(alias="maxActiveCxn")] = (
        1000
    )
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""

    socket_idle_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketIdleTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""

    socket_ending_max_wait: Annotated[
        Optional[float], pydantic.Field(alias="socketEndingMaxWait")
    ] = 30
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""

    socket_max_lifespan: Annotated[
        Optional[float], pydantic.Field(alias="socketMaxLifespan")
    ] = 0
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    breaker_rulesets: Annotated[
        Optional[List[str]], pydantic.Field(alias="breakerRulesets")
    ] = None
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""

    stale_channel_flush_ms: Annotated[
        Optional[float], pydantic.Field(alias="staleChannelFlushMs")
    ] = 10000
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""

    filter_: Annotated[
        Optional[InputAppscopeFilter5], pydantic.Field(alias="filter")
    ] = None

    persistence: Optional[Persistence1Type] = None

    auth_type: Annotated[
        Annotated[
            Optional[AuthType2Options], PlainValidator(validate_open_enum(False))
        ],
        pydantic.Field(alias="authType"),
    ] = AuthType2Options.MANUAL
    r"""Enter credentials directly, or select a stored secret"""

    description: Optional[str] = None

    unix_socket_path: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPath")
    ] = "$CRIBL_HOME/state/appscope.sock"
    r"""Path to the UNIX domain socket to listen on."""

    unix_socket_perms: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPerms")
    ] = None
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""

    auth_token: Annotated[Optional[str], pydantic.Field(alias="authToken")] = ""
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""

    text_secret: Annotated[Optional[str], pydantic.Field(alias="textSecret")] = None
    r"""Select or create a stored text secret"""

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthType2Options(value)
            except ValueError:
                return value
        return value


class InputAppscopeType4(str, Enum):
    APPSCOPE = "appscope"


class Allow4TypedDict(TypedDict):
    procname: str
    r"""Specify the name of a process or family of processes."""
    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""
    arg: NotRequired[str]
    r"""Specify a string to substring-match against process command-line."""


class Allow4(BaseModel):
    procname: str
    r"""Specify the name of a process or family of processes."""

    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""

    arg: Optional[str] = None
    r"""Specify a string to substring-match against process command-line."""


class InputAppscopeFilter4TypedDict(TypedDict):
    allow: NotRequired[List[Allow4TypedDict]]
    r"""Specify processes that AppScope should be loaded into, and the config to use."""
    transport_url: NotRequired[str]
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeFilter4(BaseModel):
    allow: Optional[List[Allow4]] = None
    r"""Specify processes that AppScope should be loaded into, and the config to use."""

    transport_url: Annotated[Optional[str], pydantic.Field(alias="transportURL")] = None
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeAppscope4TypedDict(TypedDict):
    type: InputAppscopeType4
    pq: PqTypeTypedDict
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    ip_whitelist_regex: NotRequired[str]
    r"""Regex matching IP addresses that are allowed to establish a connection"""
    max_active_cxn: NotRequired[float]
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""
    socket_idle_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""
    socket_ending_max_wait: NotRequired[float]
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""
    socket_max_lifespan: NotRequired[float]
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    breaker_rulesets: NotRequired[List[str]]
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""
    stale_channel_flush_ms: NotRequired[float]
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""
    enable_unix_path: NotRequired[bool]
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""
    filter_: NotRequired[InputAppscopeFilter4TypedDict]
    persistence: NotRequired[Persistence1TypeTypedDict]
    auth_type: NotRequired[AuthType2Options]
    r"""Enter credentials directly, or select a stored secret"""
    description: NotRequired[str]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: NotRequired[float]
    r"""Port to listen on"""
    tls: NotRequired[Tls2TypeTypedDict]
    unix_socket_path: NotRequired[str]
    r"""Path to the UNIX domain socket to listen on."""
    unix_socket_perms: NotRequired[str]
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""
    auth_token: NotRequired[str]
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""
    text_secret: NotRequired[str]
    r"""Select or create a stored text secret"""


class InputAppscopeAppscope4(BaseModel):
    type: InputAppscopeType4

    pq: PqType

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    ip_whitelist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipWhitelistRegex")
    ] = "/.*/"
    r"""Regex matching IP addresses that are allowed to establish a connection"""

    max_active_cxn: Annotated[Optional[float], pydantic.Field(alias="maxActiveCxn")] = (
        1000
    )
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""

    socket_idle_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketIdleTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""

    socket_ending_max_wait: Annotated[
        Optional[float], pydantic.Field(alias="socketEndingMaxWait")
    ] = 30
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""

    socket_max_lifespan: Annotated[
        Optional[float], pydantic.Field(alias="socketMaxLifespan")
    ] = 0
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    breaker_rulesets: Annotated[
        Optional[List[str]], pydantic.Field(alias="breakerRulesets")
    ] = None
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""

    stale_channel_flush_ms: Annotated[
        Optional[float], pydantic.Field(alias="staleChannelFlushMs")
    ] = 10000
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""

    enable_unix_path: Annotated[
        Optional[bool], pydantic.Field(alias="enableUnixPath")
    ] = False
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""

    filter_: Annotated[
        Optional[InputAppscopeFilter4], pydantic.Field(alias="filter")
    ] = None

    persistence: Optional[Persistence1Type] = None

    auth_type: Annotated[
        Annotated[
            Optional[AuthType2Options], PlainValidator(validate_open_enum(False))
        ],
        pydantic.Field(alias="authType"),
    ] = AuthType2Options.MANUAL
    r"""Enter credentials directly, or select a stored secret"""

    description: Optional[str] = None

    host: Optional[str] = None
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: Optional[float] = None
    r"""Port to listen on"""

    tls: Optional[Tls2Type] = None

    unix_socket_path: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPath")
    ] = "$CRIBL_HOME/state/appscope.sock"
    r"""Path to the UNIX domain socket to listen on."""

    unix_socket_perms: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPerms")
    ] = None
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""

    auth_token: Annotated[Optional[str], pydantic.Field(alias="authToken")] = ""
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""

    text_secret: Annotated[Optional[str], pydantic.Field(alias="textSecret")] = None
    r"""Select or create a stored text secret"""

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthType2Options(value)
            except ValueError:
                return value
        return value


class InputAppscopeType3(str, Enum):
    APPSCOPE = "appscope"


class Allow3TypedDict(TypedDict):
    procname: str
    r"""Specify the name of a process or family of processes."""
    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""
    arg: NotRequired[str]
    r"""Specify a string to substring-match against process command-line."""


class Allow3(BaseModel):
    procname: str
    r"""Specify the name of a process or family of processes."""

    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""

    arg: Optional[str] = None
    r"""Specify a string to substring-match against process command-line."""


class InputAppscopeFilter3TypedDict(TypedDict):
    allow: NotRequired[List[Allow3TypedDict]]
    r"""Specify processes that AppScope should be loaded into, and the config to use."""
    transport_url: NotRequired[str]
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeFilter3(BaseModel):
    allow: Optional[List[Allow3]] = None
    r"""Specify processes that AppScope should be loaded into, and the config to use."""

    transport_url: Annotated[Optional[str], pydantic.Field(alias="transportURL")] = None
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeAppscope3TypedDict(TypedDict):
    type: InputAppscopeType3
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    ip_whitelist_regex: NotRequired[str]
    r"""Regex matching IP addresses that are allowed to establish a connection"""
    max_active_cxn: NotRequired[float]
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""
    socket_idle_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""
    socket_ending_max_wait: NotRequired[float]
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""
    socket_max_lifespan: NotRequired[float]
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    breaker_rulesets: NotRequired[List[str]]
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""
    stale_channel_flush_ms: NotRequired[float]
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""
    enable_unix_path: NotRequired[bool]
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""
    filter_: NotRequired[InputAppscopeFilter3TypedDict]
    persistence: NotRequired[Persistence1TypeTypedDict]
    auth_type: NotRequired[AuthType2Options]
    r"""Enter credentials directly, or select a stored secret"""
    description: NotRequired[str]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: NotRequired[float]
    r"""Port to listen on"""
    tls: NotRequired[Tls2TypeTypedDict]
    unix_socket_path: NotRequired[str]
    r"""Path to the UNIX domain socket to listen on."""
    unix_socket_perms: NotRequired[str]
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""
    auth_token: NotRequired[str]
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""
    text_secret: NotRequired[str]
    r"""Select or create a stored text secret"""


class InputAppscopeAppscope3(BaseModel):
    type: InputAppscopeType3

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    ip_whitelist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipWhitelistRegex")
    ] = "/.*/"
    r"""Regex matching IP addresses that are allowed to establish a connection"""

    max_active_cxn: Annotated[Optional[float], pydantic.Field(alias="maxActiveCxn")] = (
        1000
    )
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""

    socket_idle_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketIdleTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""

    socket_ending_max_wait: Annotated[
        Optional[float], pydantic.Field(alias="socketEndingMaxWait")
    ] = 30
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""

    socket_max_lifespan: Annotated[
        Optional[float], pydantic.Field(alias="socketMaxLifespan")
    ] = 0
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    breaker_rulesets: Annotated[
        Optional[List[str]], pydantic.Field(alias="breakerRulesets")
    ] = None
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""

    stale_channel_flush_ms: Annotated[
        Optional[float], pydantic.Field(alias="staleChannelFlushMs")
    ] = 10000
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""

    enable_unix_path: Annotated[
        Optional[bool], pydantic.Field(alias="enableUnixPath")
    ] = False
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""

    filter_: Annotated[
        Optional[InputAppscopeFilter3], pydantic.Field(alias="filter")
    ] = None

    persistence: Optional[Persistence1Type] = None

    auth_type: Annotated[
        Annotated[
            Optional[AuthType2Options], PlainValidator(validate_open_enum(False))
        ],
        pydantic.Field(alias="authType"),
    ] = AuthType2Options.MANUAL
    r"""Enter credentials directly, or select a stored secret"""

    description: Optional[str] = None

    host: Optional[str] = None
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: Optional[float] = None
    r"""Port to listen on"""

    tls: Optional[Tls2Type] = None

    unix_socket_path: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPath")
    ] = "$CRIBL_HOME/state/appscope.sock"
    r"""Path to the UNIX domain socket to listen on."""

    unix_socket_perms: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPerms")
    ] = None
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""

    auth_token: Annotated[Optional[str], pydantic.Field(alias="authToken")] = ""
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""

    text_secret: Annotated[Optional[str], pydantic.Field(alias="textSecret")] = None
    r"""Select or create a stored text secret"""

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthType2Options(value)
            except ValueError:
                return value
        return value


class InputAppscopeType2(str, Enum):
    APPSCOPE = "appscope"


class Allow2TypedDict(TypedDict):
    procname: str
    r"""Specify the name of a process or family of processes."""
    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""
    arg: NotRequired[str]
    r"""Specify a string to substring-match against process command-line."""


class Allow2(BaseModel):
    procname: str
    r"""Specify the name of a process or family of processes."""

    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""

    arg: Optional[str] = None
    r"""Specify a string to substring-match against process command-line."""


class InputAppscopeFilter2TypedDict(TypedDict):
    allow: NotRequired[List[Allow2TypedDict]]
    r"""Specify processes that AppScope should be loaded into, and the config to use."""
    transport_url: NotRequired[str]
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeFilter2(BaseModel):
    allow: Optional[List[Allow2]] = None
    r"""Specify processes that AppScope should be loaded into, and the config to use."""

    transport_url: Annotated[Optional[str], pydantic.Field(alias="transportURL")] = None
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeAppscope2TypedDict(TypedDict):
    type: InputAppscopeType2
    connections: List[ConnectionsTypeTypedDict]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    pq: NotRequired[PqTypeTypedDict]
    ip_whitelist_regex: NotRequired[str]
    r"""Regex matching IP addresses that are allowed to establish a connection"""
    max_active_cxn: NotRequired[float]
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""
    socket_idle_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""
    socket_ending_max_wait: NotRequired[float]
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""
    socket_max_lifespan: NotRequired[float]
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    breaker_rulesets: NotRequired[List[str]]
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""
    stale_channel_flush_ms: NotRequired[float]
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""
    enable_unix_path: NotRequired[bool]
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""
    filter_: NotRequired[InputAppscopeFilter2TypedDict]
    persistence: NotRequired[Persistence1TypeTypedDict]
    auth_type: NotRequired[AuthType2Options]
    r"""Enter credentials directly, or select a stored secret"""
    description: NotRequired[str]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: NotRequired[float]
    r"""Port to listen on"""
    tls: NotRequired[Tls2TypeTypedDict]
    unix_socket_path: NotRequired[str]
    r"""Path to the UNIX domain socket to listen on."""
    unix_socket_perms: NotRequired[str]
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""
    auth_token: NotRequired[str]
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""
    text_secret: NotRequired[str]
    r"""Select or create a stored text secret"""


class InputAppscopeAppscope2(BaseModel):
    type: InputAppscopeType2

    connections: List[ConnectionsType]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    pq: Optional[PqType] = None

    ip_whitelist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipWhitelistRegex")
    ] = "/.*/"
    r"""Regex matching IP addresses that are allowed to establish a connection"""

    max_active_cxn: Annotated[Optional[float], pydantic.Field(alias="maxActiveCxn")] = (
        1000
    )
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""

    socket_idle_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketIdleTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""

    socket_ending_max_wait: Annotated[
        Optional[float], pydantic.Field(alias="socketEndingMaxWait")
    ] = 30
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""

    socket_max_lifespan: Annotated[
        Optional[float], pydantic.Field(alias="socketMaxLifespan")
    ] = 0
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    breaker_rulesets: Annotated[
        Optional[List[str]], pydantic.Field(alias="breakerRulesets")
    ] = None
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""

    stale_channel_flush_ms: Annotated[
        Optional[float], pydantic.Field(alias="staleChannelFlushMs")
    ] = 10000
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""

    enable_unix_path: Annotated[
        Optional[bool], pydantic.Field(alias="enableUnixPath")
    ] = False
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""

    filter_: Annotated[
        Optional[InputAppscopeFilter2], pydantic.Field(alias="filter")
    ] = None

    persistence: Optional[Persistence1Type] = None

    auth_type: Annotated[
        Annotated[
            Optional[AuthType2Options], PlainValidator(validate_open_enum(False))
        ],
        pydantic.Field(alias="authType"),
    ] = AuthType2Options.MANUAL
    r"""Enter credentials directly, or select a stored secret"""

    description: Optional[str] = None

    host: Optional[str] = None
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: Optional[float] = None
    r"""Port to listen on"""

    tls: Optional[Tls2Type] = None

    unix_socket_path: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPath")
    ] = "$CRIBL_HOME/state/appscope.sock"
    r"""Path to the UNIX domain socket to listen on."""

    unix_socket_perms: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPerms")
    ] = None
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""

    auth_token: Annotated[Optional[str], pydantic.Field(alias="authToken")] = ""
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""

    text_secret: Annotated[Optional[str], pydantic.Field(alias="textSecret")] = None
    r"""Select or create a stored text secret"""

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthType2Options(value)
            except ValueError:
                return value
        return value


class InputAppscopeType1(str, Enum):
    APPSCOPE = "appscope"


class Allow1TypedDict(TypedDict):
    procname: str
    r"""Specify the name of a process or family of processes."""
    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""
    arg: NotRequired[str]
    r"""Specify a string to substring-match against process command-line."""


class Allow1(BaseModel):
    procname: str
    r"""Specify the name of a process or family of processes."""

    config: str
    r"""Choose a config to apply to processes that match the process name and/or argument."""

    arg: Optional[str] = None
    r"""Specify a string to substring-match against process command-line."""


class InputAppscopeFilter1TypedDict(TypedDict):
    allow: NotRequired[List[Allow1TypedDict]]
    r"""Specify processes that AppScope should be loaded into, and the config to use."""
    transport_url: NotRequired[str]
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeFilter1(BaseModel):
    allow: Optional[List[Allow1]] = None
    r"""Specify processes that AppScope should be loaded into, and the config to use."""

    transport_url: Annotated[Optional[str], pydantic.Field(alias="transportURL")] = None
    r"""To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL."""


class InputAppscopeAppscope1TypedDict(TypedDict):
    type: InputAppscopeType1
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    ip_whitelist_regex: NotRequired[str]
    r"""Regex matching IP addresses that are allowed to establish a connection"""
    max_active_cxn: NotRequired[float]
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""
    socket_idle_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""
    socket_ending_max_wait: NotRequired[float]
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""
    socket_max_lifespan: NotRequired[float]
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    breaker_rulesets: NotRequired[List[str]]
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""
    stale_channel_flush_ms: NotRequired[float]
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""
    enable_unix_path: NotRequired[bool]
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""
    filter_: NotRequired[InputAppscopeFilter1TypedDict]
    persistence: NotRequired[Persistence1TypeTypedDict]
    auth_type: NotRequired[AuthType2Options]
    r"""Enter credentials directly, or select a stored secret"""
    description: NotRequired[str]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: NotRequired[float]
    r"""Port to listen on"""
    tls: NotRequired[Tls2TypeTypedDict]
    unix_socket_path: NotRequired[str]
    r"""Path to the UNIX domain socket to listen on."""
    unix_socket_perms: NotRequired[str]
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""
    auth_token: NotRequired[str]
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""
    text_secret: NotRequired[str]
    r"""Select or create a stored text secret"""


class InputAppscopeAppscope1(BaseModel):
    type: InputAppscopeType1

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    ip_whitelist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipWhitelistRegex")
    ] = "/.*/"
    r"""Regex matching IP addresses that are allowed to establish a connection"""

    max_active_cxn: Annotated[Optional[float], pydantic.Field(alias="maxActiveCxn")] = (
        1000
    )
    r"""Maximum number of active connections allowed per Worker Process. Use 0 for unlimited."""

    socket_idle_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketIdleTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring."""

    socket_ending_max_wait: Annotated[
        Optional[float], pydantic.Field(alias="socketEndingMaxWait")
    ] = 30
    r"""How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring."""

    socket_max_lifespan: Annotated[
        Optional[float], pydantic.Field(alias="socketMaxLifespan")
    ] = 0
    r"""The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable if the connection is proxied by a device that supports proxy protocol v1 or v2"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    breaker_rulesets: Annotated[
        Optional[List[str]], pydantic.Field(alias="breakerRulesets")
    ] = None
    r"""A list of event-breaking rulesets that will be applied, in order, to the input data stream"""

    stale_channel_flush_ms: Annotated[
        Optional[float], pydantic.Field(alias="staleChannelFlushMs")
    ] = 10000
    r"""How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines"""

    enable_unix_path: Annotated[
        Optional[bool], pydantic.Field(alias="enableUnixPath")
    ] = False
    r"""Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port."""

    filter_: Annotated[
        Optional[InputAppscopeFilter1], pydantic.Field(alias="filter")
    ] = None

    persistence: Optional[Persistence1Type] = None

    auth_type: Annotated[
        Annotated[
            Optional[AuthType2Options], PlainValidator(validate_open_enum(False))
        ],
        pydantic.Field(alias="authType"),
    ] = AuthType2Options.MANUAL
    r"""Enter credentials directly, or select a stored secret"""

    description: Optional[str] = None

    host: Optional[str] = None
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: Optional[float] = None
    r"""Port to listen on"""

    tls: Optional[Tls2Type] = None

    unix_socket_path: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPath")
    ] = "$CRIBL_HOME/state/appscope.sock"
    r"""Path to the UNIX domain socket to listen on."""

    unix_socket_perms: Annotated[
        Optional[str], pydantic.Field(alias="unixSocketPerms")
    ] = None
    r"""Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions."""

    auth_token: Annotated[Optional[str], pydantic.Field(alias="authToken")] = ""
    r"""Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted."""

    text_secret: Annotated[Optional[str], pydantic.Field(alias="textSecret")] = None
    r"""Select or create a stored text secret"""

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthType2Options(value)
            except ValueError:
                return value
        return value


InputAppscopeTypedDict = TypeAliasType(
    "InputAppscopeTypedDict",
    Union[
        InputAppscopeAppscope1TypedDict,
        InputAppscopeAppscope2TypedDict,
        InputAppscopeAppscope3TypedDict,
        InputAppscopeAppscope4TypedDict,
        InputAppscopeAppscope5TypedDict,
        InputAppscopeAppscope6TypedDict,
        InputAppscopeAppscope7TypedDict,
        InputAppscopeAppscope8TypedDict,
    ],
)


InputAppscope = TypeAliasType(
    "InputAppscope",
    Union[
        InputAppscopeAppscope1,
        InputAppscopeAppscope2,
        InputAppscopeAppscope3,
        InputAppscopeAppscope4,
        InputAppscopeAppscope5,
        InputAppscopeAppscope6,
        InputAppscopeAppscope7,
        InputAppscopeAppscope8,
    ],
)
