"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .connectionstype import ConnectionsType, ConnectionsTypeTypedDict
from .metadata1type import Metadata1Type, Metadata1TypeTypedDict
from .podfiltertype import PodFilterType, PodFilterTypeTypedDict
from .pqtype import PqType, PqTypeTypedDict
from cribl_control_plane.types import BaseModel
from enum import Enum
import pydantic
from typing import List, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class InputKubeEventsType4(str, Enum):
    KUBE_EVENTS = "kube_events"


class InputKubeEventsKubeEvents4TypedDict(TypedDict):
    type: InputKubeEventsType4
    pq: PqTypeTypedDict
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    rules: NotRequired[List[PodFilterTypeTypedDict]]
    r"""Filtering on event fields"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    description: NotRequired[str]


class InputKubeEventsKubeEvents4(BaseModel):
    type: InputKubeEventsType4

    pq: PqType

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    rules: Optional[List[PodFilterType]] = None
    r"""Filtering on event fields"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    description: Optional[str] = None


class InputKubeEventsType3(str, Enum):
    KUBE_EVENTS = "kube_events"


class InputKubeEventsKubeEvents3TypedDict(TypedDict):
    type: InputKubeEventsType3
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    rules: NotRequired[List[PodFilterTypeTypedDict]]
    r"""Filtering on event fields"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    description: NotRequired[str]


class InputKubeEventsKubeEvents3(BaseModel):
    type: InputKubeEventsType3

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    rules: Optional[List[PodFilterType]] = None
    r"""Filtering on event fields"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    description: Optional[str] = None


class InputKubeEventsType2(str, Enum):
    KUBE_EVENTS = "kube_events"


class InputKubeEventsKubeEvents2TypedDict(TypedDict):
    type: InputKubeEventsType2
    connections: List[ConnectionsTypeTypedDict]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    pq: NotRequired[PqTypeTypedDict]
    rules: NotRequired[List[PodFilterTypeTypedDict]]
    r"""Filtering on event fields"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    description: NotRequired[str]


class InputKubeEventsKubeEvents2(BaseModel):
    type: InputKubeEventsType2

    connections: List[ConnectionsType]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    pq: Optional[PqType] = None

    rules: Optional[List[PodFilterType]] = None
    r"""Filtering on event fields"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    description: Optional[str] = None


class InputKubeEventsType1(str, Enum):
    KUBE_EVENTS = "kube_events"


class InputKubeEventsKubeEvents1TypedDict(TypedDict):
    type: InputKubeEventsType1
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ConnectionsTypeTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    rules: NotRequired[List[PodFilterTypeTypedDict]]
    r"""Filtering on event fields"""
    metadata: NotRequired[List[Metadata1TypeTypedDict]]
    r"""Fields to add to events from this input"""
    description: NotRequired[str]


class InputKubeEventsKubeEvents1(BaseModel):
    type: InputKubeEventsType1

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ConnectionsType]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    rules: Optional[List[PodFilterType]] = None
    r"""Filtering on event fields"""

    metadata: Optional[List[Metadata1Type]] = None
    r"""Fields to add to events from this input"""

    description: Optional[str] = None


InputKubeEventsTypedDict = TypeAliasType(
    "InputKubeEventsTypedDict",
    Union[
        InputKubeEventsKubeEvents1TypedDict,
        InputKubeEventsKubeEvents2TypedDict,
        InputKubeEventsKubeEvents3TypedDict,
        InputKubeEventsKubeEvents4TypedDict,
    ],
)


InputKubeEvents = TypeAliasType(
    "InputKubeEvents",
    Union[
        InputKubeEventsKubeEvents1,
        InputKubeEventsKubeEvents2,
        InputKubeEventsKubeEvents3,
        InputKubeEventsKubeEvents4,
    ],
)
