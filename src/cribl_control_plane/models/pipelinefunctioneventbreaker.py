"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .eventbreakertypeoptionseventbreakerexistingornewnew import (
    EventBreakerTypeOptionsEventBreakerExistingOrNewNew,
)
from .timestamptypeoptionseventbreakerexistingornewnewtimestamp import (
    TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp,
)
from cribl_control_plane import models, utils
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
from cribl_control_plane.utils import get_discriminator
from enum import Enum
import pydantic
from pydantic import Discriminator, Tag, field_serializer, model_serializer
from typing import List, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class PipelineFunctionEventBreakerID(str, Enum):
    r"""Function ID"""

    EVENT_BREAKER = "event_breaker"


class EventBreakerExistingOrNewExistingExistingOrNew(
    str, Enum, metaclass=utils.OpenEnumMeta
):
    # Use Existing
    EXISTING = "existing"
    # Create New
    NEW = "new"


class EventBreakerExistingOrNewExistingTypedDict(TypedDict):
    existing_or_new: EventBreakerExistingOrNewExistingExistingOrNew
    existing_rule: NotRequired[str]
    should_mark_cribl_breaker: NotRequired[bool]
    r"""Add this Function name to the cribl_breaker field"""


class EventBreakerExistingOrNewExisting(BaseModel):
    existing_or_new: Annotated[
        EventBreakerExistingOrNewExistingExistingOrNew,
        pydantic.Field(alias="existingOrNew"),
    ]

    existing_rule: Annotated[Optional[str], pydantic.Field(alias="existingRule")] = None

    should_mark_cribl_breaker: Annotated[
        Optional[bool], pydantic.Field(alias="shouldMarkCriblBreaker")
    ] = None
    r"""Add this Function name to the cribl_breaker field"""

    @field_serializer("existing_or_new")
    def serialize_existing_or_new(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerExistingOrNewExistingExistingOrNew(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["existingRule", "shouldMarkCriblBreaker"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeCsvExistingOrNew(
    str, Enum, metaclass=utils.OpenEnumMeta
):
    # Use Existing
    EXISTING = "existing"
    # Create New
    NEW = "new"


class EventBreakerExistingOrNewNewRuleTypeCsvTimestampFormatTypedDict(TypedDict):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp
    length: NotRequired[float]
    format_: NotRequired[str]


class EventBreakerExistingOrNewNewRuleTypeCsvTimestampFormat(BaseModel):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp

    length: Optional[float] = None

    format_: Annotated[Optional[str], pydantic.Field(alias="format")] = None

    @field_serializer("type")
    def serialize_type(self, value):
        if isinstance(value, str):
            try:
                return models.TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["length", "format"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeCsvTypedDict(TypedDict):
    delimiter: str
    r"""Delimiter character to use to split values"""
    quote_char: str
    r"""Character used to quote literal values"""
    escape_char: str
    r"""Character used to escape the quote character in field values"""
    existing_or_new: EventBreakerExistingOrNewNewRuleTypeCsvExistingOrNew
    rule_type: NotRequired[EventBreakerTypeOptionsEventBreakerExistingOrNewNew]
    time_field: NotRequired[str]
    r"""Optional timestamp field name in extracted events"""
    max_event_bytes: NotRequired[float]
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""
    timestamp_anchor_regex: NotRequired[str]
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""
    timestamp: NotRequired[
        EventBreakerExistingOrNewNewRuleTypeCsvTimestampFormatTypedDict
    ]
    timestamp_timezone: NotRequired[str]
    r"""Timezone to assign to timestamps without timezone info"""
    timestamp_earliest: NotRequired[str]
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""
    timestamp_latest: NotRequired[str]
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""
    should_mark_cribl_breaker: NotRequired[bool]
    r"""Add this Function name to the cribl_breaker field"""


class EventBreakerExistingOrNewNewRuleTypeCsv(BaseModel):
    delimiter: str
    r"""Delimiter character to use to split values"""

    quote_char: Annotated[str, pydantic.Field(alias="quoteChar")]
    r"""Character used to quote literal values"""

    escape_char: Annotated[str, pydantic.Field(alias="escapeChar")]
    r"""Character used to escape the quote character in field values"""

    existing_or_new: Annotated[
        EventBreakerExistingOrNewNewRuleTypeCsvExistingOrNew,
        pydantic.Field(alias="existingOrNew"),
    ]

    rule_type: Annotated[
        Optional[EventBreakerTypeOptionsEventBreakerExistingOrNewNew],
        pydantic.Field(alias="ruleType"),
    ] = None

    time_field: Annotated[Optional[str], pydantic.Field(alias="timeField")] = None
    r"""Optional timestamp field name in extracted events"""

    max_event_bytes: Annotated[
        Optional[float], pydantic.Field(alias="maxEventBytes")
    ] = None
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""

    timestamp_anchor_regex: Annotated[
        Optional[str], pydantic.Field(alias="timestampAnchorRegex")
    ] = None
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""

    timestamp: Optional[EventBreakerExistingOrNewNewRuleTypeCsvTimestampFormat] = None

    timestamp_timezone: Annotated[
        Optional[str], pydantic.Field(alias="timestampTimezone")
    ] = None
    r"""Timezone to assign to timestamps without timezone info"""

    timestamp_earliest: Annotated[
        Optional[str], pydantic.Field(alias="timestampEarliest")
    ] = None
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""

    timestamp_latest: Annotated[
        Optional[str], pydantic.Field(alias="timestampLatest")
    ] = None
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""

    should_mark_cribl_breaker: Annotated[
        Optional[bool], pydantic.Field(alias="shouldMarkCriblBreaker")
    ] = None
    r"""Add this Function name to the cribl_breaker field"""

    @field_serializer("rule_type")
    def serialize_rule_type(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerTypeOptionsEventBreakerExistingOrNewNew(value)
            except ValueError:
                return value
        return value

    @field_serializer("existing_or_new")
    def serialize_existing_or_new(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerExistingOrNewNewRuleTypeCsvExistingOrNew(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "ruleType",
                "timeField",
                "maxEventBytes",
                "timestampAnchorRegex",
                "timestamp",
                "timestampTimezone",
                "timestampEarliest",
                "timestampLatest",
                "shouldMarkCriblBreaker",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeHeaderExistingOrNew(
    str, Enum, metaclass=utils.OpenEnumMeta
):
    # Use Existing
    EXISTING = "existing"
    # Create New
    NEW = "new"


class EventBreakerExistingOrNewNewRuleTypeHeaderTimestampFormatTypedDict(TypedDict):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp
    length: NotRequired[float]
    format_: NotRequired[str]


class EventBreakerExistingOrNewNewRuleTypeHeaderTimestampFormat(BaseModel):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp

    length: Optional[float] = None

    format_: Annotated[Optional[str], pydantic.Field(alias="format")] = None

    @field_serializer("type")
    def serialize_type(self, value):
        if isinstance(value, str):
            try:
                return models.TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["length", "format"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeHeaderTypedDict(TypedDict):
    delimiter_regex: str
    r"""Field delimiter regex"""
    fields_line_regex: str
    r"""Regex with one capturing group that captures all fields (and delimiters) to be broken by field delimiter"""
    header_line_regex: str
    r"""Regex matching a file header line"""
    existing_or_new: EventBreakerExistingOrNewNewRuleTypeHeaderExistingOrNew
    rule_type: NotRequired[EventBreakerTypeOptionsEventBreakerExistingOrNewNew]
    null_field_val: NotRequired[str]
    r"""Representation of a null value. Null fields are not added to events."""
    clean_fields: NotRequired[bool]
    r"""Clean field names by replacing non [a-zA-Z0-9] characters with _"""
    max_event_bytes: NotRequired[float]
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""
    timestamp_anchor_regex: NotRequired[str]
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""
    timestamp: NotRequired[
        EventBreakerExistingOrNewNewRuleTypeHeaderTimestampFormatTypedDict
    ]
    timestamp_timezone: NotRequired[str]
    r"""Timezone to assign to timestamps without timezone info"""
    timestamp_earliest: NotRequired[str]
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""
    timestamp_latest: NotRequired[str]
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""
    should_mark_cribl_breaker: NotRequired[bool]
    r"""Add this Function name to the cribl_breaker field"""


class EventBreakerExistingOrNewNewRuleTypeHeader(BaseModel):
    delimiter_regex: Annotated[str, pydantic.Field(alias="delimiterRegex")]
    r"""Field delimiter regex"""

    fields_line_regex: Annotated[str, pydantic.Field(alias="fieldsLineRegex")]
    r"""Regex with one capturing group that captures all fields (and delimiters) to be broken by field delimiter"""

    header_line_regex: Annotated[str, pydantic.Field(alias="headerLineRegex")]
    r"""Regex matching a file header line"""

    existing_or_new: Annotated[
        EventBreakerExistingOrNewNewRuleTypeHeaderExistingOrNew,
        pydantic.Field(alias="existingOrNew"),
    ]

    rule_type: Annotated[
        Optional[EventBreakerTypeOptionsEventBreakerExistingOrNewNew],
        pydantic.Field(alias="ruleType"),
    ] = None

    null_field_val: Annotated[Optional[str], pydantic.Field(alias="nullFieldVal")] = (
        None
    )
    r"""Representation of a null value. Null fields are not added to events."""

    clean_fields: Annotated[Optional[bool], pydantic.Field(alias="cleanFields")] = None
    r"""Clean field names by replacing non [a-zA-Z0-9] characters with _"""

    max_event_bytes: Annotated[
        Optional[float], pydantic.Field(alias="maxEventBytes")
    ] = None
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""

    timestamp_anchor_regex: Annotated[
        Optional[str], pydantic.Field(alias="timestampAnchorRegex")
    ] = None
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""

    timestamp: Optional[EventBreakerExistingOrNewNewRuleTypeHeaderTimestampFormat] = (
        None
    )

    timestamp_timezone: Annotated[
        Optional[str], pydantic.Field(alias="timestampTimezone")
    ] = None
    r"""Timezone to assign to timestamps without timezone info"""

    timestamp_earliest: Annotated[
        Optional[str], pydantic.Field(alias="timestampEarliest")
    ] = None
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""

    timestamp_latest: Annotated[
        Optional[str], pydantic.Field(alias="timestampLatest")
    ] = None
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""

    should_mark_cribl_breaker: Annotated[
        Optional[bool], pydantic.Field(alias="shouldMarkCriblBreaker")
    ] = None
    r"""Add this Function name to the cribl_breaker field"""

    @field_serializer("rule_type")
    def serialize_rule_type(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerTypeOptionsEventBreakerExistingOrNewNew(value)
            except ValueError:
                return value
        return value

    @field_serializer("existing_or_new")
    def serialize_existing_or_new(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerExistingOrNewNewRuleTypeHeaderExistingOrNew(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "ruleType",
                "nullFieldVal",
                "cleanFields",
                "maxEventBytes",
                "timestampAnchorRegex",
                "timestamp",
                "timestampTimezone",
                "timestampEarliest",
                "timestampLatest",
                "shouldMarkCriblBreaker",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseExistingOrNew(
    str, Enum, metaclass=utils.OpenEnumMeta
):
    # Use Existing
    EXISTING = "existing"
    # Create New
    NEW = "new"


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseTimestampFormatTypedDict(
    TypedDict
):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp
    length: NotRequired[float]
    format_: NotRequired[str]


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseTimestampFormat(
    BaseModel
):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp

    length: Optional[float] = None

    format_: Annotated[Optional[str], pydantic.Field(alias="format")] = None

    @field_serializer("type")
    def serialize_type(self, value):
        if isinstance(value, str):
            try:
                return models.TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["length", "format"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseTypedDict(
    TypedDict
):
    existing_or_new: (
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseExistingOrNew
    )
    json_extract_all: NotRequired[bool]
    r"""Automatically extract fields from JSON events. When disabled, only _raw and _time are defined on extracted events."""
    rule_type: NotRequired[EventBreakerTypeOptionsEventBreakerExistingOrNewNew]
    json_array_field: NotRequired[str]
    r"""The path to an array in a JSON event with records to extract, such as Records or level1.level2.events. Leave blank if result itself is an array, such as [{...},{...}]"""
    parent_fields_to_copy: NotRequired[List[str]]
    r"""Top-level fields to copy to the output events. Nested fields are not supported. 'Array field' is always excluded. If 'Array field' points to a nested array, the entire top-level object will be excluded. Supports * wildcards. Enclose field names containing special characters in single or double quotes."""
    max_event_bytes: NotRequired[float]
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""
    timestamp_anchor_regex: NotRequired[str]
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""
    timestamp: NotRequired[
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseTimestampFormatTypedDict
    ]
    timestamp_timezone: NotRequired[str]
    r"""Timezone to assign to timestamps without timezone info"""
    timestamp_earliest: NotRequired[str]
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""
    timestamp_latest: NotRequired[str]
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""
    should_mark_cribl_breaker: NotRequired[bool]
    r"""Add this Function name to the cribl_breaker field"""


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalse(BaseModel):
    existing_or_new: Annotated[
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseExistingOrNew,
        pydantic.Field(alias="existingOrNew"),
    ]

    json_extract_all: Annotated[
        Optional[bool], pydantic.Field(alias="jsonExtractAll")
    ] = None
    r"""Automatically extract fields from JSON events. When disabled, only _raw and _time are defined on extracted events."""

    rule_type: Annotated[
        Optional[EventBreakerTypeOptionsEventBreakerExistingOrNewNew],
        pydantic.Field(alias="ruleType"),
    ] = None

    json_array_field: Annotated[
        Optional[str], pydantic.Field(alias="jsonArrayField")
    ] = None
    r"""The path to an array in a JSON event with records to extract, such as Records or level1.level2.events. Leave blank if result itself is an array, such as [{...},{...}]"""

    parent_fields_to_copy: Annotated[
        Optional[List[str]], pydantic.Field(alias="parentFieldsToCopy")
    ] = None
    r"""Top-level fields to copy to the output events. Nested fields are not supported. 'Array field' is always excluded. If 'Array field' points to a nested array, the entire top-level object will be excluded. Supports * wildcards. Enclose field names containing special characters in single or double quotes."""

    max_event_bytes: Annotated[
        Optional[float], pydantic.Field(alias="maxEventBytes")
    ] = None
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""

    timestamp_anchor_regex: Annotated[
        Optional[str], pydantic.Field(alias="timestampAnchorRegex")
    ] = None
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""

    timestamp: Optional[
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseTimestampFormat
    ] = None

    timestamp_timezone: Annotated[
        Optional[str], pydantic.Field(alias="timestampTimezone")
    ] = None
    r"""Timezone to assign to timestamps without timezone info"""

    timestamp_earliest: Annotated[
        Optional[str], pydantic.Field(alias="timestampEarliest")
    ] = None
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""

    timestamp_latest: Annotated[
        Optional[str], pydantic.Field(alias="timestampLatest")
    ] = None
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""

    should_mark_cribl_breaker: Annotated[
        Optional[bool], pydantic.Field(alias="shouldMarkCriblBreaker")
    ] = None
    r"""Add this Function name to the cribl_breaker field"""

    @field_serializer("rule_type")
    def serialize_rule_type(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerTypeOptionsEventBreakerExistingOrNewNew(value)
            except ValueError:
                return value
        return value

    @field_serializer("existing_or_new")
    def serialize_existing_or_new(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseExistingOrNew(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "jsonExtractAll",
                "ruleType",
                "jsonArrayField",
                "parentFieldsToCopy",
                "maxEventBytes",
                "timestampAnchorRegex",
                "timestamp",
                "timestampTimezone",
                "timestampEarliest",
                "timestampLatest",
                "shouldMarkCriblBreaker",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueExistingOrNew(
    str, Enum, metaclass=utils.OpenEnumMeta
):
    # Use Existing
    EXISTING = "existing"
    # Create New
    NEW = "new"


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueTimestampFormatTypedDict(
    TypedDict
):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp
    length: NotRequired[float]
    format_: NotRequired[str]


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueTimestampFormat(
    BaseModel
):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp

    length: Optional[float] = None

    format_: Annotated[Optional[str], pydantic.Field(alias="format")] = None

    @field_serializer("type")
    def serialize_type(self, value):
        if isinstance(value, str):
            try:
                return models.TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["length", "format"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueTypedDict(
    TypedDict
):
    existing_or_new: (
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueExistingOrNew
    )
    json_extract_all: NotRequired[bool]
    r"""Automatically extract fields from JSON events. When disabled, only _raw and _time are defined on extracted events."""
    json_time_field: NotRequired[str]
    r"""Optional path to timestamp field in extracted events, such as eventTime or level1.level2.eventTime."""
    rule_type: NotRequired[EventBreakerTypeOptionsEventBreakerExistingOrNewNew]
    json_array_field: NotRequired[str]
    r"""The path to an array in a JSON event with records to extract, such as Records or level1.level2.events. Leave blank if result itself is an array, such as [{...},{...}]"""
    parent_fields_to_copy: NotRequired[List[str]]
    r"""Top-level fields to copy to the output events. Nested fields are not supported. 'Array field' is always excluded. If 'Array field' points to a nested array, the entire top-level object will be excluded. Supports * wildcards. Enclose field names containing special characters in single or double quotes."""
    max_event_bytes: NotRequired[float]
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""
    timestamp_anchor_regex: NotRequired[str]
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""
    timestamp: NotRequired[
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueTimestampFormatTypedDict
    ]
    timestamp_timezone: NotRequired[str]
    r"""Timezone to assign to timestamps without timezone info"""
    timestamp_earliest: NotRequired[str]
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""
    timestamp_latest: NotRequired[str]
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""
    should_mark_cribl_breaker: NotRequired[bool]
    r"""Add this Function name to the cribl_breaker field"""


class EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrue(BaseModel):
    existing_or_new: Annotated[
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueExistingOrNew,
        pydantic.Field(alias="existingOrNew"),
    ]

    json_extract_all: Annotated[
        Optional[bool], pydantic.Field(alias="jsonExtractAll")
    ] = None
    r"""Automatically extract fields from JSON events. When disabled, only _raw and _time are defined on extracted events."""

    json_time_field: Annotated[Optional[str], pydantic.Field(alias="jsonTimeField")] = (
        None
    )
    r"""Optional path to timestamp field in extracted events, such as eventTime or level1.level2.eventTime."""

    rule_type: Annotated[
        Optional[EventBreakerTypeOptionsEventBreakerExistingOrNewNew],
        pydantic.Field(alias="ruleType"),
    ] = None

    json_array_field: Annotated[
        Optional[str], pydantic.Field(alias="jsonArrayField")
    ] = None
    r"""The path to an array in a JSON event with records to extract, such as Records or level1.level2.events. Leave blank if result itself is an array, such as [{...},{...}]"""

    parent_fields_to_copy: Annotated[
        Optional[List[str]], pydantic.Field(alias="parentFieldsToCopy")
    ] = None
    r"""Top-level fields to copy to the output events. Nested fields are not supported. 'Array field' is always excluded. If 'Array field' points to a nested array, the entire top-level object will be excluded. Supports * wildcards. Enclose field names containing special characters in single or double quotes."""

    max_event_bytes: Annotated[
        Optional[float], pydantic.Field(alias="maxEventBytes")
    ] = None
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""

    timestamp_anchor_regex: Annotated[
        Optional[str], pydantic.Field(alias="timestampAnchorRegex")
    ] = None
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""

    timestamp: Optional[
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueTimestampFormat
    ] = None

    timestamp_timezone: Annotated[
        Optional[str], pydantic.Field(alias="timestampTimezone")
    ] = None
    r"""Timezone to assign to timestamps without timezone info"""

    timestamp_earliest: Annotated[
        Optional[str], pydantic.Field(alias="timestampEarliest")
    ] = None
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""

    timestamp_latest: Annotated[
        Optional[str], pydantic.Field(alias="timestampLatest")
    ] = None
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""

    should_mark_cribl_breaker: Annotated[
        Optional[bool], pydantic.Field(alias="shouldMarkCriblBreaker")
    ] = None
    r"""Add this Function name to the cribl_breaker field"""

    @field_serializer("rule_type")
    def serialize_rule_type(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerTypeOptionsEventBreakerExistingOrNewNew(value)
            except ValueError:
                return value
        return value

    @field_serializer("existing_or_new")
    def serialize_existing_or_new(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueExistingOrNew(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "jsonExtractAll",
                "jsonTimeField",
                "ruleType",
                "jsonArrayField",
                "parentFieldsToCopy",
                "maxEventBytes",
                "timestampAnchorRegex",
                "timestamp",
                "timestampTimezone",
                "timestampEarliest",
                "timestampLatest",
                "shouldMarkCriblBreaker",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


EventBreakerExistingOrNewNewRuleTypeJSONArrayTypedDict = TypeAliasType(
    "EventBreakerExistingOrNewNewRuleTypeJSONArrayTypedDict",
    Union[
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseTypedDict,
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueTypedDict,
    ],
)


EventBreakerExistingOrNewNewRuleTypeJSONArray = TypeAliasType(
    "EventBreakerExistingOrNewNewRuleTypeJSONArray",
    Union[
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalse,
        EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrue,
    ],
)


class EventBreakerExistingOrNewNewRuleTypeJSONExistingOrNew(
    str, Enum, metaclass=utils.OpenEnumMeta
):
    # Use Existing
    EXISTING = "existing"
    # Create New
    NEW = "new"


class EventBreakerExistingOrNewNewRuleTypeJSONTimestampFormatTypedDict(TypedDict):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp
    length: NotRequired[float]
    format_: NotRequired[str]


class EventBreakerExistingOrNewNewRuleTypeJSONTimestampFormat(BaseModel):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp

    length: Optional[float] = None

    format_: Annotated[Optional[str], pydantic.Field(alias="format")] = None

    @field_serializer("type")
    def serialize_type(self, value):
        if isinstance(value, str):
            try:
                return models.TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["length", "format"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeJSONTypedDict(TypedDict):
    existing_or_new: EventBreakerExistingOrNewNewRuleTypeJSONExistingOrNew
    rule_type: NotRequired[EventBreakerTypeOptionsEventBreakerExistingOrNewNew]
    max_event_bytes: NotRequired[float]
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""
    timestamp_anchor_regex: NotRequired[str]
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""
    timestamp: NotRequired[
        EventBreakerExistingOrNewNewRuleTypeJSONTimestampFormatTypedDict
    ]
    timestamp_timezone: NotRequired[str]
    r"""Timezone to assign to timestamps without timezone info"""
    timestamp_earliest: NotRequired[str]
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""
    timestamp_latest: NotRequired[str]
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""
    should_mark_cribl_breaker: NotRequired[bool]
    r"""Add this Function name to the cribl_breaker field"""


class EventBreakerExistingOrNewNewRuleTypeJSON(BaseModel):
    existing_or_new: Annotated[
        EventBreakerExistingOrNewNewRuleTypeJSONExistingOrNew,
        pydantic.Field(alias="existingOrNew"),
    ]

    rule_type: Annotated[
        Optional[EventBreakerTypeOptionsEventBreakerExistingOrNewNew],
        pydantic.Field(alias="ruleType"),
    ] = None

    max_event_bytes: Annotated[
        Optional[float], pydantic.Field(alias="maxEventBytes")
    ] = None
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""

    timestamp_anchor_regex: Annotated[
        Optional[str], pydantic.Field(alias="timestampAnchorRegex")
    ] = None
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""

    timestamp: Optional[EventBreakerExistingOrNewNewRuleTypeJSONTimestampFormat] = None

    timestamp_timezone: Annotated[
        Optional[str], pydantic.Field(alias="timestampTimezone")
    ] = None
    r"""Timezone to assign to timestamps without timezone info"""

    timestamp_earliest: Annotated[
        Optional[str], pydantic.Field(alias="timestampEarliest")
    ] = None
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""

    timestamp_latest: Annotated[
        Optional[str], pydantic.Field(alias="timestampLatest")
    ] = None
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""

    should_mark_cribl_breaker: Annotated[
        Optional[bool], pydantic.Field(alias="shouldMarkCriblBreaker")
    ] = None
    r"""Add this Function name to the cribl_breaker field"""

    @field_serializer("rule_type")
    def serialize_rule_type(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerTypeOptionsEventBreakerExistingOrNewNew(value)
            except ValueError:
                return value
        return value

    @field_serializer("existing_or_new")
    def serialize_existing_or_new(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerExistingOrNewNewRuleTypeJSONExistingOrNew(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "ruleType",
                "maxEventBytes",
                "timestampAnchorRegex",
                "timestamp",
                "timestampTimezone",
                "timestampEarliest",
                "timestampLatest",
                "shouldMarkCriblBreaker",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeRegexExistingOrNew(
    str, Enum, metaclass=utils.OpenEnumMeta
):
    # Use Existing
    EXISTING = "existing"
    # Create New
    NEW = "new"


class EventBreakerExistingOrNewNewRuleTypeRegexTimestampFormatTypedDict(TypedDict):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp
    length: NotRequired[float]
    format_: NotRequired[str]


class EventBreakerExistingOrNewNewRuleTypeRegexTimestampFormat(BaseModel):
    type: TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp

    length: Optional[float] = None

    format_: Annotated[Optional[str], pydantic.Field(alias="format")] = None

    @field_serializer("type")
    def serialize_type(self, value):
        if isinstance(value, str):
            try:
                return models.TimestampTypeOptionsEventBreakerExistingOrNewNewTimestamp(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["length", "format"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class EventBreakerExistingOrNewNewRuleTypeRegexTypedDict(TypedDict):
    event_breaker_regex: str
    r"""The regex used to break the stream into events at the beginning of the match. Matched content will be consumed, unless you use a lookahead regex such as (?=pattern) to keep it. Do NOT use capturing groups in the pattern."""
    existing_or_new: EventBreakerExistingOrNewNewRuleTypeRegexExistingOrNew
    rule_type: NotRequired[EventBreakerTypeOptionsEventBreakerExistingOrNewNew]
    max_event_bytes: NotRequired[float]
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""
    timestamp_anchor_regex: NotRequired[str]
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""
    timestamp: NotRequired[
        EventBreakerExistingOrNewNewRuleTypeRegexTimestampFormatTypedDict
    ]
    timestamp_timezone: NotRequired[str]
    r"""Timezone to assign to timestamps without timezone info"""
    timestamp_earliest: NotRequired[str]
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""
    timestamp_latest: NotRequired[str]
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""
    should_mark_cribl_breaker: NotRequired[bool]
    r"""Add this Function name to the cribl_breaker field"""


class EventBreakerExistingOrNewNewRuleTypeRegex(BaseModel):
    event_breaker_regex: Annotated[str, pydantic.Field(alias="eventBreakerRegex")]
    r"""The regex used to break the stream into events at the beginning of the match. Matched content will be consumed, unless you use a lookahead regex such as (?=pattern) to keep it. Do NOT use capturing groups in the pattern."""

    existing_or_new: Annotated[
        EventBreakerExistingOrNewNewRuleTypeRegexExistingOrNew,
        pydantic.Field(alias="existingOrNew"),
    ]

    rule_type: Annotated[
        Optional[EventBreakerTypeOptionsEventBreakerExistingOrNewNew],
        pydantic.Field(alias="ruleType"),
    ] = None

    max_event_bytes: Annotated[
        Optional[float], pydantic.Field(alias="maxEventBytes")
    ] = None
    r"""The maximum number of bytes that an event can be before being flushed to the Pipelines"""

    timestamp_anchor_regex: Annotated[
        Optional[str], pydantic.Field(alias="timestampAnchorRegex")
    ] = None
    r"""Regex to match before attempting timestamp extraction. Use $ (end of string anchor) to not perform extraction."""

    timestamp: Optional[EventBreakerExistingOrNewNewRuleTypeRegexTimestampFormat] = None

    timestamp_timezone: Annotated[
        Optional[str], pydantic.Field(alias="timestampTimezone")
    ] = None
    r"""Timezone to assign to timestamps without timezone info"""

    timestamp_earliest: Annotated[
        Optional[str], pydantic.Field(alias="timestampEarliest")
    ] = None
    r"""The earliest timestamp value allowed relative to now, such as -42years. Parsed values prior to this date will be set to current time."""

    timestamp_latest: Annotated[
        Optional[str], pydantic.Field(alias="timestampLatest")
    ] = None
    r"""The latest timestamp value allowed relative to now, such as +42days. Parsed values after this date will be set to current time."""

    should_mark_cribl_breaker: Annotated[
        Optional[bool], pydantic.Field(alias="shouldMarkCriblBreaker")
    ] = None
    r"""Add this Function name to the cribl_breaker field"""

    @field_serializer("rule_type")
    def serialize_rule_type(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerTypeOptionsEventBreakerExistingOrNewNew(value)
            except ValueError:
                return value
        return value

    @field_serializer("existing_or_new")
    def serialize_existing_or_new(self, value):
        if isinstance(value, str):
            try:
                return models.EventBreakerExistingOrNewNewRuleTypeRegexExistingOrNew(
                    value
                )
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "ruleType",
                "maxEventBytes",
                "timestampAnchorRegex",
                "timestamp",
                "timestampTimezone",
                "timestampEarliest",
                "timestampLatest",
                "shouldMarkCriblBreaker",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


EventBreakerExistingOrNewNewTypedDict = TypeAliasType(
    "EventBreakerExistingOrNewNewTypedDict",
    Union[
        EventBreakerExistingOrNewNewRuleTypeJSONTypedDict,
        EventBreakerExistingOrNewNewRuleTypeRegexTypedDict,
        EventBreakerExistingOrNewNewRuleTypeCsvTypedDict,
        EventBreakerExistingOrNewNewRuleTypeHeaderTypedDict,
        EventBreakerExistingOrNewNewRuleTypeJSONArrayTypedDict,
    ],
)


EventBreakerExistingOrNewNew = Annotated[
    Union[
        Annotated[EventBreakerExistingOrNewNewRuleTypeRegex, Tag("regex")],
        Annotated[EventBreakerExistingOrNewNewRuleTypeJSON, Tag("json")],
        Annotated[EventBreakerExistingOrNewNewRuleTypeJSONArray, Tag("json_array")],
        Annotated[EventBreakerExistingOrNewNewRuleTypeHeader, Tag("header")],
        Annotated[EventBreakerExistingOrNewNewRuleTypeCsv, Tag("csv")],
    ],
    Discriminator(lambda m: get_discriminator(m, "rule_type", "ruleType")),
]


PipelineFunctionEventBreakerConfTypedDict = TypeAliasType(
    "PipelineFunctionEventBreakerConfTypedDict",
    Union[
        EventBreakerExistingOrNewExistingTypedDict,
        EventBreakerExistingOrNewNewTypedDict,
    ],
)


PipelineFunctionEventBreakerConf = Annotated[
    Union[
        Annotated[EventBreakerExistingOrNewNew, Tag("new")],
        Annotated[EventBreakerExistingOrNewExisting, Tag("existing")],
    ],
    Discriminator(lambda m: get_discriminator(m, "existing_or_new", "existingOrNew")),
]


class PipelineFunctionEventBreakerTypedDict(TypedDict):
    id: PipelineFunctionEventBreakerID
    r"""Function ID"""
    conf: PipelineFunctionEventBreakerConfTypedDict
    filter_: NotRequired[str]
    r"""Filter that selects data to be fed through this Function"""
    description: NotRequired[str]
    r"""Simple description of this step"""
    disabled: NotRequired[bool]
    r"""If true, data will not be pushed through this function"""
    final: NotRequired[bool]
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""
    group_id: NotRequired[str]
    r"""Group ID"""


class PipelineFunctionEventBreaker(BaseModel):
    id: PipelineFunctionEventBreakerID
    r"""Function ID"""

    conf: PipelineFunctionEventBreakerConf

    filter_: Annotated[Optional[str], pydantic.Field(alias="filter")] = None
    r"""Filter that selects data to be fed through this Function"""

    description: Optional[str] = None
    r"""Simple description of this step"""

    disabled: Optional[bool] = None
    r"""If true, data will not be pushed through this function"""

    final: Optional[bool] = None
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""

    group_id: Annotated[Optional[str], pydantic.Field(alias="groupId")] = None
    r"""Group ID"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["filter", "description", "disabled", "final", "groupId"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


try:
    EventBreakerExistingOrNewExisting.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeCsvTimestampFormat.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeCsv.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeHeaderTimestampFormat.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeHeader.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalseTimestampFormat.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllFalse.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrueTimestampFormat.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeJSONArrayJSONExtractAllTrue.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeJSONTimestampFormat.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeJSON.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeRegexTimestampFormat.model_rebuild()
except NameError:
    pass
try:
    EventBreakerExistingOrNewNewRuleTypeRegex.model_rebuild()
except NameError:
    pass
try:
    PipelineFunctionEventBreaker.model_rebuild()
except NameError:
    pass
