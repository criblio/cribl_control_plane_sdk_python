// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package operations

import (
	"encoding/json"
	"errors"
	"fmt"
	"mockserver/internal/sdk/models/components"
	"mockserver/internal/sdk/utils"
)

type TypeZscalerHec string

const (
	TypeZscalerHecZscalerHec TypeZscalerHec = "zscaler_hec"
)

func (e TypeZscalerHec) ToPointer() *TypeZscalerHec {
	return &e
}
func (e *TypeZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "zscaler_hec":
		*e = TypeZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeZscalerHec: %v", v)
	}
}

type ConnectionZscalerHec struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionZscalerHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionZscalerHec) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeZscalerHec - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeZscalerHec string

const (
	ModeZscalerHecSmart  ModeZscalerHec = "smart"
	ModeZscalerHecAlways ModeZscalerHec = "always"
)

func (e ModeZscalerHec) ToPointer() *ModeZscalerHec {
	return &e
}
func (e *ModeZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeZscalerHec: %v", v)
	}
}

// CompressionZscalerHec - Codec to use to compress the persisted data
type CompressionZscalerHec string

const (
	CompressionZscalerHecNone CompressionZscalerHec = "none"
	CompressionZscalerHecGzip CompressionZscalerHec = "gzip"
)

func (e CompressionZscalerHec) ToPointer() *CompressionZscalerHec {
	return &e
}
func (e *CompressionZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionZscalerHec: %v", v)
	}
}

type PqZscalerHec struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeZscalerHec `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionZscalerHec `default:"none" json:"compress"`
}

func (p PqZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqZscalerHec) GetMode() *ModeZscalerHec {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqZscalerHec) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqZscalerHec) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqZscalerHec) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqZscalerHec) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqZscalerHec) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqZscalerHec) GetCompress() *CompressionZscalerHec {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodZscalerHec - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodZscalerHec string

const (
	AuthenticationMethodZscalerHecManual AuthenticationMethodZscalerHec = "manual"
	AuthenticationMethodZscalerHecSecret AuthenticationMethodZscalerHec = "secret"
)

func (e AuthenticationMethodZscalerHec) ToPointer() *AuthenticationMethodZscalerHec {
	return &e
}
func (e *AuthenticationMethodZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodZscalerHec: %v", v)
	}
}

type AuthTokenMetadatumZscalerHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *AuthTokenMetadatumZscalerHec) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *AuthTokenMetadatumZscalerHec) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokenZscalerHec struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthenticationMethodZscalerHec `default:"manual" json:"authType"`
	TokenSecret any                             `json:"tokenSecret,omitempty"`
	Token       any                             `json:"token"`
	Enabled     *bool                           `default:"true" json:"enabled"`
	Description *string                         `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokenMetadatumZscalerHec `json:"metadata,omitempty"`
}

func (a AuthTokenZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *AuthTokenZscalerHec) GetAuthType() *AuthenticationMethodZscalerHec {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *AuthTokenZscalerHec) GetTokenSecret() any {
	if o == nil {
		return nil
	}
	return o.TokenSecret
}

func (o *AuthTokenZscalerHec) GetToken() any {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *AuthTokenZscalerHec) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *AuthTokenZscalerHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokenZscalerHec) GetAllowedIndexesAtToken() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexesAtToken
}

func (o *AuthTokenZscalerHec) GetMetadata() []AuthTokenMetadatumZscalerHec {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type MinimumTLSVersionZscalerHec string

const (
	MinimumTLSVersionZscalerHecTlSv1  MinimumTLSVersionZscalerHec = "TLSv1"
	MinimumTLSVersionZscalerHecTlSv11 MinimumTLSVersionZscalerHec = "TLSv1.1"
	MinimumTLSVersionZscalerHecTlSv12 MinimumTLSVersionZscalerHec = "TLSv1.2"
	MinimumTLSVersionZscalerHecTlSv13 MinimumTLSVersionZscalerHec = "TLSv1.3"
)

func (e MinimumTLSVersionZscalerHec) ToPointer() *MinimumTLSVersionZscalerHec {
	return &e
}
func (e *MinimumTLSVersionZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionZscalerHec: %v", v)
	}
}

type MaximumTLSVersionZscalerHec string

const (
	MaximumTLSVersionZscalerHecTlSv1  MaximumTLSVersionZscalerHec = "TLSv1"
	MaximumTLSVersionZscalerHecTlSv11 MaximumTLSVersionZscalerHec = "TLSv1.1"
	MaximumTLSVersionZscalerHecTlSv12 MaximumTLSVersionZscalerHec = "TLSv1.2"
	MaximumTLSVersionZscalerHecTlSv13 MaximumTLSVersionZscalerHec = "TLSv1.3"
)

func (e MaximumTLSVersionZscalerHec) ToPointer() *MaximumTLSVersionZscalerHec {
	return &e
}
func (e *MaximumTLSVersionZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionZscalerHec: %v", v)
	}
}

type TLSSettingsServerSideZscalerHec struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                        `default:"false" json:"requestCert"`
	RejectUnauthorized any                          `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                          `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionZscalerHec `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionZscalerHec `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideZscalerHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideZscalerHec) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideZscalerHec) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideZscalerHec) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideZscalerHec) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideZscalerHec) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideZscalerHec) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideZscalerHec) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideZscalerHec) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideZscalerHec) GetMinVersion() *MinimumTLSVersionZscalerHec {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideZscalerHec) GetMaxVersion() *MaximumTLSVersionZscalerHec {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumZscalerHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumZscalerHec) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumZscalerHec) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputZscalerHec struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     *TypeZscalerHec `json:"type,omitempty"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionZscalerHec `json:"connections,omitempty"`
	Pq          *PqZscalerHec          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenZscalerHec            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideZscalerHec `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Zscaler HTTP Event Collector API requests. This input supports the /event endpoint.
	HecAPI *string `default:"/services/collector" json:"hecAPI"`
	// Fields to add to every event. May be overridden by fields added at the token or request level.
	Metadata []MetadatumZscalerHec `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// Whether to enable Zscaler HEC acknowledgements
	HecAcks *bool `default:"false" json:"hecAcks"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Enable to emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool   `default:"false" json:"emitTokenMetrics"`
	Description      *string `json:"description,omitempty"`
}

func (i InputZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputZscalerHec) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputZscalerHec) GetType() *TypeZscalerHec {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputZscalerHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputZscalerHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputZscalerHec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputZscalerHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputZscalerHec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputZscalerHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputZscalerHec) GetConnections() []ConnectionZscalerHec {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputZscalerHec) GetPq() *PqZscalerHec {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputZscalerHec) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputZscalerHec) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputZscalerHec) GetAuthTokens() []AuthTokenZscalerHec {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputZscalerHec) GetTLS() *TLSSettingsServerSideZscalerHec {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputZscalerHec) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputZscalerHec) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputZscalerHec) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputZscalerHec) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputZscalerHec) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputZscalerHec) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputZscalerHec) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputZscalerHec) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputZscalerHec) GetEnableHealthCheck() any {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputZscalerHec) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputZscalerHec) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputZscalerHec) GetHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.HecAPI
}

func (o *InputZscalerHec) GetMetadata() []MetadatumZscalerHec {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputZscalerHec) GetAllowedIndexes() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexes
}

func (o *InputZscalerHec) GetHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.HecAcks
}

func (o *InputZscalerHec) GetAccessControlAllowOrigin() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowOrigin
}

func (o *InputZscalerHec) GetAccessControlAllowHeaders() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowHeaders
}

func (o *InputZscalerHec) GetEmitTokenMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EmitTokenMetrics
}

func (o *InputZscalerHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateInputTypeSecurityLake string

const (
	CreateInputTypeSecurityLakeSecurityLake CreateInputTypeSecurityLake = "security_lake"
)

func (e CreateInputTypeSecurityLake) ToPointer() *CreateInputTypeSecurityLake {
	return &e
}
func (e *CreateInputTypeSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = CreateInputTypeSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSecurityLake: %v", v)
	}
}

type ConnectionSecurityLake struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSecurityLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSecurityLake) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeSecurityLake - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSecurityLake string

const (
	ModeSecurityLakeSmart  ModeSecurityLake = "smart"
	ModeSecurityLakeAlways ModeSecurityLake = "always"
)

func (e ModeSecurityLake) ToPointer() *ModeSecurityLake {
	return &e
}
func (e *ModeSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeSecurityLake: %v", v)
	}
}

// CompressionSecurityLake - Codec to use to compress the persisted data
type CompressionSecurityLake string

const (
	CompressionSecurityLakeNone CompressionSecurityLake = "none"
	CompressionSecurityLakeGzip CompressionSecurityLake = "gzip"
)

func (e CompressionSecurityLake) ToPointer() *CompressionSecurityLake {
	return &e
}
func (e *CompressionSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSecurityLake: %v", v)
	}
}

type PqSecurityLake struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSecurityLake `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSecurityLake `default:"none" json:"compress"`
}

func (p PqSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSecurityLake) GetMode() *ModeSecurityLake {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSecurityLake) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSecurityLake) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSecurityLake) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSecurityLake) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSecurityLake) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSecurityLake) GetCompress() *CompressionSecurityLake {
	if o == nil {
		return nil
	}
	return o.Compress
}

// CreateInputAuthenticationMethodSecurityLake - AWS authentication method. Choose Auto to use IAM roles.
type CreateInputAuthenticationMethodSecurityLake string

const (
	CreateInputAuthenticationMethodSecurityLakeAuto   CreateInputAuthenticationMethodSecurityLake = "auto"
	CreateInputAuthenticationMethodSecurityLakeManual CreateInputAuthenticationMethodSecurityLake = "manual"
	CreateInputAuthenticationMethodSecurityLakeSecret CreateInputAuthenticationMethodSecurityLake = "secret"
)

func (e CreateInputAuthenticationMethodSecurityLake) ToPointer() *CreateInputAuthenticationMethodSecurityLake {
	return &e
}
func (e *CreateInputAuthenticationMethodSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = CreateInputAuthenticationMethodSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAuthenticationMethodSecurityLake: %v", v)
	}
}

// CreateInputSignatureVersionSecurityLake - Signature version to use for signing S3 requests
type CreateInputSignatureVersionSecurityLake string

const (
	CreateInputSignatureVersionSecurityLakeV2 CreateInputSignatureVersionSecurityLake = "v2"
	CreateInputSignatureVersionSecurityLakeV4 CreateInputSignatureVersionSecurityLake = "v4"
)

func (e CreateInputSignatureVersionSecurityLake) ToPointer() *CreateInputSignatureVersionSecurityLake {
	return &e
}
func (e *CreateInputSignatureVersionSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = CreateInputSignatureVersionSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputSignatureVersionSecurityLake: %v", v)
	}
}

type PreprocessSecurityLake struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessSecurityLake) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessSecurityLake) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessSecurityLake) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type MetadatumSecurityLake struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSecurityLake) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSecurityLake) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CheckpointingSecurityLake struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CheckpointingSecurityLake) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CheckpointingSecurityLake) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type TagAfterProcessingSecurityLake string

const (
	TagAfterProcessingSecurityLakeFalse TagAfterProcessingSecurityLake = "false"
	TagAfterProcessingSecurityLakeTrue  TagAfterProcessingSecurityLake = "true"
)

func (e TagAfterProcessingSecurityLake) ToPointer() *TagAfterProcessingSecurityLake {
	return &e
}
func (e *TagAfterProcessingSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "false":
		fallthrough
	case "true":
		*e = TagAfterProcessingSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TagAfterProcessingSecurityLake: %v", v)
	}
}

type InputSecurityLake struct {
	// Unique ID for this input
	ID       string                      `json:"id"`
	Type     CreateInputTypeSecurityLake `json:"type"`
	Disabled *bool                       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSecurityLake `json:"connections,omitempty"`
	Pq          *PqSecurityLake          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *CreateInputAuthenticationMethodSecurityLake `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                      `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *CreateInputSignatureVersionSecurityLake `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                   `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessSecurityLake `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumSecurityLake `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                   `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingSecurityLake `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                         `json:"awsSecret,omitempty"`
	TagAfterProcessing *TagAfterProcessingSecurityLake `json:"tagAfterProcessing,omitempty"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitempty"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue *string `json:"processedTagValue,omitempty"`
}

func (i InputSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSecurityLake) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSecurityLake) GetType() CreateInputTypeSecurityLake {
	if o == nil {
		return CreateInputTypeSecurityLake("")
	}
	return o.Type
}

func (o *InputSecurityLake) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSecurityLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSecurityLake) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSecurityLake) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSecurityLake) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSecurityLake) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSecurityLake) GetConnections() []ConnectionSecurityLake {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSecurityLake) GetPq() *PqSecurityLake {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSecurityLake) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputSecurityLake) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputSecurityLake) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputSecurityLake) GetAwsAuthenticationMethod() *CreateInputAuthenticationMethodSecurityLake {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputSecurityLake) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputSecurityLake) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputSecurityLake) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSecurityLake) GetSignatureVersion() *CreateInputSignatureVersionSecurityLake {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputSecurityLake) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputSecurityLake) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSecurityLake) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSecurityLake) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSecurityLake) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputSecurityLake) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputSecurityLake) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputSecurityLake) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputSecurityLake) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputSecurityLake) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputSecurityLake) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputSecurityLake) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputSecurityLake) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputSecurityLake) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputSecurityLake) GetPreprocess() *PreprocessSecurityLake {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputSecurityLake) GetMetadata() []MetadatumSecurityLake {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSecurityLake) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputSecurityLake) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputSecurityLake) GetCheckpointing() *CheckpointingSecurityLake {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputSecurityLake) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputSecurityLake) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputSecurityLake) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSecurityLake) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputSecurityLake) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputSecurityLake) GetTagAfterProcessing() *TagAfterProcessingSecurityLake {
	if o == nil {
		return nil
	}
	return o.TagAfterProcessing
}

func (o *InputSecurityLake) GetProcessedTagKey() *string {
	if o == nil {
		return nil
	}
	return o.ProcessedTagKey
}

func (o *InputSecurityLake) GetProcessedTagValue() *string {
	if o == nil {
		return nil
	}
	return o.ProcessedTagValue
}

type CreateInputTypeNetflow string

const (
	CreateInputTypeNetflowNetflow CreateInputTypeNetflow = "netflow"
)

func (e CreateInputTypeNetflow) ToPointer() *CreateInputTypeNetflow {
	return &e
}
func (e *CreateInputTypeNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "netflow":
		*e = CreateInputTypeNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeNetflow: %v", v)
	}
}

type ConnectionNetflow struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionNetflow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionNetflow) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeNetflow - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeNetflow string

const (
	ModeNetflowSmart  ModeNetflow = "smart"
	ModeNetflowAlways ModeNetflow = "always"
)

func (e ModeNetflow) ToPointer() *ModeNetflow {
	return &e
}
func (e *ModeNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeNetflow: %v", v)
	}
}

// CompressionNetflow - Codec to use to compress the persisted data
type CompressionNetflow string

const (
	CompressionNetflowNone CompressionNetflow = "none"
	CompressionNetflowGzip CompressionNetflow = "gzip"
)

func (e CompressionNetflow) ToPointer() *CompressionNetflow {
	return &e
}
func (e *CompressionNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionNetflow: %v", v)
	}
}

type PqNetflow struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeNetflow `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionNetflow `default:"none" json:"compress"`
}

func (p PqNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqNetflow) GetMode() *ModeNetflow {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqNetflow) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqNetflow) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqNetflow) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqNetflow) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqNetflow) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqNetflow) GetCompress() *CompressionNetflow {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumNetflow struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumNetflow) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumNetflow) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputNetflow struct {
	// Unique ID for this input
	ID       string                  `json:"id"`
	Type     *CreateInputTypeNetflow `json:"type,omitempty"`
	Disabled *bool                   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionNetflow `json:"connections,omitempty"`
	Pq          *PqNetflow          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64 `default:"2055" json:"port"`
	// Allow forwarding of events to a NetFlow destination. Enabling this feature will generate an extra event containing __netflowRaw which can be routed to a NetFlow destination. Note that these events will not count against ingest quota.
	EnablePassThrough *bool `default:"false" json:"enablePassThrough"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Specifies how many minutes NetFlow v9 templates are cached before being discarded if not refreshed. Adjust based on your network's template update frequency to optimize performance and memory usage.
	TemplateCacheMinutes *float64 `default:"30" json:"templateCacheMinutes"`
	// Accept messages in Netflow V5 format.
	V5Enabled *bool `default:"true" json:"v5Enabled"`
	// Accept messages in Netflow V9 format.
	V9Enabled *bool `default:"true" json:"v9Enabled"`
	// Accept messages in IPFIX format.
	IpfixEnabled *bool `default:"false" json:"ipfixEnabled"`
	// Fields to add to events from this input
	Metadata    []MetadatumNetflow `json:"metadata,omitempty"`
	Description *string            `json:"description,omitempty"`
}

func (i InputNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputNetflow) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputNetflow) GetType() *CreateInputTypeNetflow {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputNetflow) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputNetflow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputNetflow) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputNetflow) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputNetflow) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputNetflow) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputNetflow) GetConnections() []ConnectionNetflow {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputNetflow) GetPq() *PqNetflow {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputNetflow) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputNetflow) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputNetflow) GetEnablePassThrough() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePassThrough
}

func (o *InputNetflow) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputNetflow) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputNetflow) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputNetflow) GetTemplateCacheMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TemplateCacheMinutes
}

func (o *InputNetflow) GetV5Enabled() *bool {
	if o == nil {
		return nil
	}
	return o.V5Enabled
}

func (o *InputNetflow) GetV9Enabled() *bool {
	if o == nil {
		return nil
	}
	return o.V9Enabled
}

func (o *InputNetflow) GetIpfixEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.IpfixEnabled
}

func (o *InputNetflow) GetMetadata() []MetadatumNetflow {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputNetflow) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeWiz string

const (
	TypeWizWiz TypeWiz = "wiz"
)

func (e TypeWiz) ToPointer() *TypeWiz {
	return &e
}
func (e *TypeWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wiz":
		*e = TypeWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWiz: %v", v)
	}
}

type ConnectionWiz struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionWiz) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionWiz) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeWiz - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWiz string

const (
	ModeWizSmart  ModeWiz = "smart"
	ModeWizAlways ModeWiz = "always"
)

func (e ModeWiz) ToPointer() *ModeWiz {
	return &e
}
func (e *ModeWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeWiz: %v", v)
	}
}

// CompressionWiz - Codec to use to compress the persisted data
type CompressionWiz string

const (
	CompressionWizNone CompressionWiz = "none"
	CompressionWizGzip CompressionWiz = "gzip"
)

func (e CompressionWiz) ToPointer() *CompressionWiz {
	return &e
}
func (e *CompressionWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionWiz: %v", v)
	}
}

type PqWiz struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWiz `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionWiz `default:"none" json:"compress"`
}

func (p PqWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqWiz) GetMode() *ModeWiz {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqWiz) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqWiz) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqWiz) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqWiz) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqWiz) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqWiz) GetCompress() *CompressionWiz {
	if o == nil {
		return nil
	}
	return o.Compress
}

type ContentConfigWiz struct {
	// The name of the Wiz query
	ContentType        string  `json:"contentType"`
	ContentDescription *string `json:"contentDescription,omitempty"`
	Enabled            *bool   `default:"false" json:"enabled"`
}

func (c ContentConfigWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContentConfigWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ContentConfigWiz) GetContentType() string {
	if o == nil {
		return ""
	}
	return o.ContentType
}

func (o *ContentConfigWiz) GetContentDescription() *string {
	if o == nil {
		return nil
	}
	return o.ContentDescription
}

func (o *ContentConfigWiz) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

type MetadatumWiz struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumWiz) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumWiz) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// RetryTypeWiz - The algorithm to use when performing HTTP retries
type RetryTypeWiz string

const (
	RetryTypeWizNone    RetryTypeWiz = "none"
	RetryTypeWizBackoff RetryTypeWiz = "backoff"
	RetryTypeWizStatic  RetryTypeWiz = "static"
)

func (e RetryTypeWiz) ToPointer() *RetryTypeWiz {
	return &e
}
func (e *RetryTypeWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeWiz: %v", v)
	}
}

type RetryRulesWiz struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeWiz `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesWiz) GetType() *RetryTypeWiz {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesWiz) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesWiz) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesWiz) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesWiz) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesWiz) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesWiz) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesWiz) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationMethodWiz - Enter client secret directly, or select a stored secret
type AuthenticationMethodWiz string

const (
	AuthenticationMethodWizManual AuthenticationMethodWiz = "manual"
	AuthenticationMethodWizSecret AuthenticationMethodWiz = "secret"
)

func (e AuthenticationMethodWiz) ToPointer() *AuthenticationMethodWiz {
	return &e
}
func (e *AuthenticationMethodWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodWiz: %v", v)
	}
}

type InputWiz struct {
	// Unique ID for this input
	ID       string   `json:"id"`
	Type     *TypeWiz `json:"type,omitempty"`
	Disabled *bool    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWiz `json:"connections,omitempty"`
	Pq          *PqWiz          `json:"pq,omitempty"`
	// The Wiz GraphQL API endpoint. Example: https://api.us1.app.wiz.io/graphql
	Endpoint *string `default:"https://api.<region>.app.wiz.io/graphql" json:"endpoint"`
	// The authentication URL to generate an OAuth token
	AuthURL string `json:"authUrl"`
	// The audience to use when requesting an OAuth token for a custom auth URL. When not specified, `wiz-api` will be used.
	AuthAudienceOverride *string `json:"authAudienceOverride,omitempty"`
	// The client ID of the Wiz application
	ClientID      string             `json:"clientId"`
	ContentConfig []ContentConfigWiz `json:"contentConfig"`
	// HTTP request inactivity timeout. Use 0 to disable.
	RequestTimeout *float64 `default:"300" json:"requestTimeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata   []MetadatumWiz `json:"metadata,omitempty"`
	RetryRules *RetryRulesWiz `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodWiz `default:"manual" json:"authType"`
	Description *string                  `json:"description,omitempty"`
	// The client secret of the Wiz application
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (i InputWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWiz) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputWiz) GetType() *TypeWiz {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputWiz) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWiz) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWiz) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWiz) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWiz) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWiz) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWiz) GetConnections() []ConnectionWiz {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWiz) GetPq() *PqWiz {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWiz) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputWiz) GetAuthURL() string {
	if o == nil {
		return ""
	}
	return o.AuthURL
}

func (o *InputWiz) GetAuthAudienceOverride() *string {
	if o == nil {
		return nil
	}
	return o.AuthAudienceOverride
}

func (o *InputWiz) GetClientID() string {
	if o == nil {
		return ""
	}
	return o.ClientID
}

func (o *InputWiz) GetContentConfig() []ContentConfigWiz {
	if o == nil {
		return []ContentConfigWiz{}
	}
	return o.ContentConfig
}

func (o *InputWiz) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputWiz) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputWiz) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputWiz) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputWiz) GetIgnoreGroupJobsLimit() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreGroupJobsLimit
}

func (o *InputWiz) GetMetadata() []MetadatumWiz {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWiz) GetRetryRules() *RetryRulesWiz {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputWiz) GetAuthType() *AuthenticationMethodWiz {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputWiz) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWiz) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputWiz) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

type InputJournalFilesType string

const (
	InputJournalFilesTypeJournalFiles InputJournalFilesType = "journal_files"
)

func (e InputJournalFilesType) ToPointer() *InputJournalFilesType {
	return &e
}
func (e *InputJournalFilesType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "journal_files":
		*e = InputJournalFilesType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesType: %v", v)
	}
}

type InputJournalFilesConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputJournalFilesConnection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputJournalFilesConnection) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputJournalFilesMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputJournalFilesMode string

const (
	InputJournalFilesModeSmart  InputJournalFilesMode = "smart"
	InputJournalFilesModeAlways InputJournalFilesMode = "always"
)

func (e InputJournalFilesMode) ToPointer() *InputJournalFilesMode {
	return &e
}
func (e *InputJournalFilesMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputJournalFilesMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesMode: %v", v)
	}
}

// InputJournalFilesCompression - Codec to use to compress the persisted data
type InputJournalFilesCompression string

const (
	InputJournalFilesCompressionNone InputJournalFilesCompression = "none"
	InputJournalFilesCompressionGzip InputJournalFilesCompression = "gzip"
)

func (e InputJournalFilesCompression) ToPointer() *InputJournalFilesCompression {
	return &e
}
func (e *InputJournalFilesCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputJournalFilesCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesCompression: %v", v)
	}
}

type InputJournalFilesPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputJournalFilesMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputJournalFilesCompression `default:"none" json:"compress"`
}

func (i InputJournalFilesPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputJournalFilesPq) GetMode() *InputJournalFilesMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputJournalFilesPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputJournalFilesPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputJournalFilesPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputJournalFilesPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputJournalFilesPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputJournalFilesPq) GetCompress() *InputJournalFilesCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type CreateInputRule struct {
	// JavaScript expression applied to Journal objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *CreateInputRule) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *CreateInputRule) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputJournalFilesMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputJournalFilesMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputJournalFilesMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputJournalFiles struct {
	// Unique ID for this input
	ID       string                 `json:"id"`
	Type     *InputJournalFilesType `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputJournalFilesConnection `json:"connections,omitempty"`
	Pq          *InputJournalFilesPq          `json:"pq,omitempty"`
	// Directory path to search for journals. Environment variables will be resolved, e.g. $CRIBL_EDGE_FS_ROOT/var/log/journal/$MACHINE_ID.
	Path string `json:"path"`
	// Time, in seconds, between scanning for journals.
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered journals are matched against this wildcard list.
	Journals []string `json:"journals"`
	// Add rules to decide which journal objects to allow. Events are generated if no rules are given or if all the rules' expressions evaluate to true.
	Rules []CreateInputRule `json:"rules,omitempty"`
	// Skip log messages that are not part of the current boot session.
	CurrentBoot *bool `default:"false" json:"currentBoot"`
	// The maximum log message age, in duration form (e.g,: 60s, 4h, 3d, 1w).  Default of no value will apply no max age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputJournalFilesMetadatum `json:"metadata,omitempty"`
	Description *string                      `json:"description,omitempty"`
}

func (i InputJournalFiles) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFiles) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputJournalFiles) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputJournalFiles) GetType() *InputJournalFilesType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputJournalFiles) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputJournalFiles) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputJournalFiles) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputJournalFiles) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputJournalFiles) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputJournalFiles) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputJournalFiles) GetConnections() []InputJournalFilesConnection {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputJournalFiles) GetPq() *InputJournalFilesPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputJournalFiles) GetPath() string {
	if o == nil {
		return ""
	}
	return o.Path
}

func (o *InputJournalFiles) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputJournalFiles) GetJournals() []string {
	if o == nil {
		return []string{}
	}
	return o.Journals
}

func (o *InputJournalFiles) GetRules() []CreateInputRule {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputJournalFiles) GetCurrentBoot() *bool {
	if o == nil {
		return nil
	}
	return o.CurrentBoot
}

func (o *InputJournalFiles) GetMaxAgeDur() *string {
	if o == nil {
		return nil
	}
	return o.MaxAgeDur
}

func (o *InputJournalFiles) GetMetadata() []InputJournalFilesMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputJournalFiles) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeRawUDP string

const (
	TypeRawUDPRawUDP TypeRawUDP = "raw_udp"
)

func (e TypeRawUDP) ToPointer() *TypeRawUDP {
	return &e
}
func (e *TypeRawUDP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "raw_udp":
		*e = TypeRawUDP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeRawUDP: %v", v)
	}
}

type ConnectionRawUDP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionRawUDP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionRawUDP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeRawUDP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeRawUDP string

const (
	ModeRawUDPSmart  ModeRawUDP = "smart"
	ModeRawUDPAlways ModeRawUDP = "always"
)

func (e ModeRawUDP) ToPointer() *ModeRawUDP {
	return &e
}
func (e *ModeRawUDP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeRawUDP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeRawUDP: %v", v)
	}
}

// CompressionRawUDP - Codec to use to compress the persisted data
type CompressionRawUDP string

const (
	CompressionRawUDPNone CompressionRawUDP = "none"
	CompressionRawUDPGzip CompressionRawUDP = "gzip"
)

func (e CompressionRawUDP) ToPointer() *CompressionRawUDP {
	return &e
}
func (e *CompressionRawUDP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionRawUDP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionRawUDP: %v", v)
	}
}

type PqRawUDP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeRawUDP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionRawUDP `default:"none" json:"compress"`
}

func (p PqRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqRawUDP) GetMode() *ModeRawUDP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqRawUDP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqRawUDP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqRawUDP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqRawUDP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqRawUDP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqRawUDP) GetCompress() *CompressionRawUDP {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumRawUDP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumRawUDP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumRawUDP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputRawUDP struct {
	// Unique ID for this input
	ID       string      `json:"id"`
	Type     *TypeRawUDP `json:"type,omitempty"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionRawUDP `json:"connections,omitempty"`
	Pq          *PqRawUDP          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// If true, each UDP packet is assumed to contain a single message. If false, each UDP packet is assumed to contain multiple messages, separated by newlines.
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// If true, a __rawBytes field will be added to each event containing the raw bytes of the datagram.
	IngestRawBytes *bool `default:"false" json:"ingestRawBytes"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumRawUDP `json:"metadata,omitempty"`
	Description *string           `json:"description,omitempty"`
}

func (i InputRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputRawUDP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputRawUDP) GetType() *TypeRawUDP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputRawUDP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputRawUDP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputRawUDP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputRawUDP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputRawUDP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputRawUDP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputRawUDP) GetConnections() []ConnectionRawUDP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputRawUDP) GetPq() *PqRawUDP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputRawUDP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputRawUDP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputRawUDP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputRawUDP) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputRawUDP) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputRawUDP) GetIngestRawBytes() *bool {
	if o == nil {
		return nil
	}
	return o.IngestRawBytes
}

func (o *InputRawUDP) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputRawUDP) GetMetadata() []MetadatumRawUDP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputRawUDP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeWinEventLogs string

const (
	TypeWinEventLogsWinEventLogs TypeWinEventLogs = "win_event_logs"
)

func (e TypeWinEventLogs) ToPointer() *TypeWinEventLogs {
	return &e
}
func (e *TypeWinEventLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "win_event_logs":
		*e = TypeWinEventLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWinEventLogs: %v", v)
	}
}

type ConnectionWinEventLogs struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionWinEventLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionWinEventLogs) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeWinEventLogs - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWinEventLogs string

const (
	ModeWinEventLogsSmart  ModeWinEventLogs = "smart"
	ModeWinEventLogsAlways ModeWinEventLogs = "always"
)

func (e ModeWinEventLogs) ToPointer() *ModeWinEventLogs {
	return &e
}
func (e *ModeWinEventLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeWinEventLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeWinEventLogs: %v", v)
	}
}

// CompressionWinEventLogs - Codec to use to compress the persisted data
type CompressionWinEventLogs string

const (
	CompressionWinEventLogsNone CompressionWinEventLogs = "none"
	CompressionWinEventLogsGzip CompressionWinEventLogs = "gzip"
)

func (e CompressionWinEventLogs) ToPointer() *CompressionWinEventLogs {
	return &e
}
func (e *CompressionWinEventLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionWinEventLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionWinEventLogs: %v", v)
	}
}

type PqWinEventLogs struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWinEventLogs `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionWinEventLogs `default:"none" json:"compress"`
}

func (p PqWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqWinEventLogs) GetMode() *ModeWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqWinEventLogs) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqWinEventLogs) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqWinEventLogs) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqWinEventLogs) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqWinEventLogs) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqWinEventLogs) GetCompress() *CompressionWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ReadMode - Read all stored and future event logs, or only future events
type ReadMode string

const (
	ReadModeOldest ReadMode = "oldest"
	ReadModeNewest ReadMode = "newest"
)

func (e ReadMode) ToPointer() *ReadMode {
	return &e
}
func (e *ReadMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "oldest":
		fallthrough
	case "newest":
		*e = ReadMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ReadMode: %v", v)
	}
}

// EventFormat - Format of individual events
type EventFormat string

const (
	EventFormatJSON EventFormat = "json"
	EventFormatXML  EventFormat = "xml"
)

func (e EventFormat) ToPointer() *EventFormat {
	return &e
}
func (e *EventFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "xml":
		*e = EventFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for EventFormat: %v", v)
	}
}

type MetadatumWinEventLogs struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumWinEventLogs) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumWinEventLogs) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputWinEventLogs struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     TypeWinEventLogs `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWinEventLogs `json:"connections,omitempty"`
	Pq          *PqWinEventLogs          `json:"pq,omitempty"`
	// Enter the event logs to collect. Run "Get-WinEvent -ListLog *" in PowerShell to see the available logs.
	LogNames []string `json:"logNames"`
	// Read all stored and future event logs, or only future events
	ReadMode *ReadMode `default:"oldest" json:"readMode"`
	// Format of individual events
	EventFormat *EventFormat `default:"json" json:"eventFormat"`
	// Enable to use built-in tools (PowerShell for JSON, wevtutil for XML) to collect event logs instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-event-logs/#advanced-settings)
	DisableNativeModule *bool `default:"false" json:"disableNativeModule"`
	// Time, in seconds, between checking for new entries (Applicable for pre-4.8.0 nodes that use Windows Tools)
	Interval *float64 `default:"10" json:"interval"`
	// The maximum number of events to read in one polling interval. A batch size higher than 500 can cause delays when pulling from multiple event logs. (Applicable for pre-4.8.0 nodes that use Windows Tools)
	BatchSize *float64 `default:"500" json:"batchSize"`
	// Fields to add to events from this input
	Metadata []MetadatumWinEventLogs `json:"metadata,omitempty"`
	// The maximum number of bytes in an event before it is flushed to the pipelines
	MaxEventBytes *float64 `default:"51200" json:"maxEventBytes"`
	Description   *string  `json:"description,omitempty"`
}

func (i InputWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWinEventLogs) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputWinEventLogs) GetType() TypeWinEventLogs {
	if o == nil {
		return TypeWinEventLogs("")
	}
	return o.Type
}

func (o *InputWinEventLogs) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWinEventLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWinEventLogs) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWinEventLogs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWinEventLogs) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWinEventLogs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWinEventLogs) GetConnections() []ConnectionWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWinEventLogs) GetPq() *PqWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWinEventLogs) GetLogNames() []string {
	if o == nil {
		return []string{}
	}
	return o.LogNames
}

func (o *InputWinEventLogs) GetReadMode() *ReadMode {
	if o == nil {
		return nil
	}
	return o.ReadMode
}

func (o *InputWinEventLogs) GetEventFormat() *EventFormat {
	if o == nil {
		return nil
	}
	return o.EventFormat
}

func (o *InputWinEventLogs) GetDisableNativeModule() *bool {
	if o == nil {
		return nil
	}
	return o.DisableNativeModule
}

func (o *InputWinEventLogs) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputWinEventLogs) GetBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.BatchSize
}

func (o *InputWinEventLogs) GetMetadata() []MetadatumWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWinEventLogs) GetMaxEventBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxEventBytes
}

func (o *InputWinEventLogs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeWef string

const (
	TypeWefWef TypeWef = "wef"
)

func (e TypeWef) ToPointer() *TypeWef {
	return &e
}
func (e *TypeWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wef":
		*e = TypeWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWef: %v", v)
	}
}

type ConnectionWef struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionWef) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionWef) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeWef - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWef string

const (
	ModeWefSmart  ModeWef = "smart"
	ModeWefAlways ModeWef = "always"
)

func (e ModeWef) ToPointer() *ModeWef {
	return &e
}
func (e *ModeWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeWef: %v", v)
	}
}

// CompressionWef - Codec to use to compress the persisted data
type CompressionWef string

const (
	CompressionWefNone CompressionWef = "none"
	CompressionWefGzip CompressionWef = "gzip"
)

func (e CompressionWef) ToPointer() *CompressionWef {
	return &e
}
func (e *CompressionWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionWef: %v", v)
	}
}

type PqWef struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWef `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionWef `default:"none" json:"compress"`
}

func (p PqWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqWef) GetMode() *ModeWef {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqWef) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqWef) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqWef) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqWef) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqWef) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqWef) GetCompress() *CompressionWef {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthMethodAuthenticationMethod - How to authenticate incoming client connections
type AuthMethodAuthenticationMethod string

const (
	AuthMethodAuthenticationMethodClientCert AuthMethodAuthenticationMethod = "clientCert"
	AuthMethodAuthenticationMethodKerberos   AuthMethodAuthenticationMethod = "kerberos"
)

func (e AuthMethodAuthenticationMethod) ToPointer() *AuthMethodAuthenticationMethod {
	return &e
}
func (e *AuthMethodAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "clientCert":
		fallthrough
	case "kerberos":
		*e = AuthMethodAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthMethodAuthenticationMethod: %v", v)
	}
}

type MinimumTLSVersionWef string

const (
	MinimumTLSVersionWefTlSv1  MinimumTLSVersionWef = "TLSv1"
	MinimumTLSVersionWefTlSv11 MinimumTLSVersionWef = "TLSv1.1"
	MinimumTLSVersionWefTlSv12 MinimumTLSVersionWef = "TLSv1.2"
	MinimumTLSVersionWefTlSv13 MinimumTLSVersionWef = "TLSv1.3"
)

func (e MinimumTLSVersionWef) ToPointer() *MinimumTLSVersionWef {
	return &e
}
func (e *MinimumTLSVersionWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionWef: %v", v)
	}
}

type MaximumTLSVersionWef string

const (
	MaximumTLSVersionWefTlSv1  MaximumTLSVersionWef = "TLSv1"
	MaximumTLSVersionWefTlSv11 MaximumTLSVersionWef = "TLSv1.1"
	MaximumTLSVersionWefTlSv12 MaximumTLSVersionWef = "TLSv1.2"
	MaximumTLSVersionWefTlSv13 MaximumTLSVersionWef = "TLSv1.3"
)

func (e MaximumTLSVersionWef) ToPointer() *MaximumTLSVersionWef {
	return &e
}
func (e *MaximumTLSVersionWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionWef: %v", v)
	}
}

type MTLSSettings struct {
	// Enable TLS
	Disabled *bool `default:"false" json:"disabled"`
	// Required for WEF certificate authentication
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Required for WEF certificate authentication
	RequestCert *bool `default:"true" json:"requestCert"`
	// Name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
	// Server path containing CA certificates (in PEM format) to use. Can reference $ENV_VARS. If multiple certificates are present in a .pem, each must directly certify the one preceding it.
	CaPath string `json:"caPath"`
	// Regex matching allowable common names in peer certificates' subject attribute
	CommonNameRegex *string               `default:"/.*/" json:"commonNameRegex"`
	MinVersion      *MinimumTLSVersionWef `json:"minVersion,omitempty"`
	MaxVersion      *MaximumTLSVersionWef `json:"maxVersion,omitempty"`
	// Enable OCSP check of certificate
	OcspCheck *bool `default:"false" json:"ocspCheck"`
	Keytab    any   `json:"keytab,omitempty"`
	Principal any   `json:"principal,omitempty"`
	// If enabled, checks will fail on any OCSP error. Otherwise, checks will fail only when a certificate is revoked, ignoring other errors.
	OcspCheckFailClose *bool `default:"false" json:"ocspCheckFailClose"`
}

func (m MTLSSettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MTLSSettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *MTLSSettings) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *MTLSSettings) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *MTLSSettings) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *MTLSSettings) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *MTLSSettings) GetPrivKeyPath() string {
	if o == nil {
		return ""
	}
	return o.PrivKeyPath
}

func (o *MTLSSettings) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *MTLSSettings) GetCertPath() string {
	if o == nil {
		return ""
	}
	return o.CertPath
}

func (o *MTLSSettings) GetCaPath() string {
	if o == nil {
		return ""
	}
	return o.CaPath
}

func (o *MTLSSettings) GetCommonNameRegex() *string {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *MTLSSettings) GetMinVersion() *MinimumTLSVersionWef {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *MTLSSettings) GetMaxVersion() *MaximumTLSVersionWef {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

func (o *MTLSSettings) GetOcspCheck() *bool {
	if o == nil {
		return nil
	}
	return o.OcspCheck
}

func (o *MTLSSettings) GetKeytab() any {
	if o == nil {
		return nil
	}
	return o.Keytab
}

func (o *MTLSSettings) GetPrincipal() any {
	if o == nil {
		return nil
	}
	return o.Principal
}

func (o *MTLSSettings) GetOcspCheckFailClose() *bool {
	if o == nil {
		return nil
	}
	return o.OcspCheckFailClose
}

// CreateInputFormat - Content format in which the endpoint should deliver events
type CreateInputFormat string

const (
	CreateInputFormatRaw          CreateInputFormat = "Raw"
	CreateInputFormatRenderedText CreateInputFormat = "RenderedText"
)

func (e CreateInputFormat) ToPointer() *CreateInputFormat {
	return &e
}
func (e *CreateInputFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Raw":
		fallthrough
	case "RenderedText":
		*e = CreateInputFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputFormat: %v", v)
	}
}

type QueryBuilderMode string

const (
	QueryBuilderModeSimple QueryBuilderMode = "simple"
	QueryBuilderModeXML    QueryBuilderMode = "xml"
)

func (e QueryBuilderMode) ToPointer() *QueryBuilderMode {
	return &e
}
func (e *QueryBuilderMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "simple":
		fallthrough
	case "xml":
		*e = QueryBuilderMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for QueryBuilderMode: %v", v)
	}
}

type SubscriptionMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *SubscriptionMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SubscriptionMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type Subscription struct {
	SubscriptionName string `json:"subscriptionName"`
	// Version UUID for this subscription. If any subscription parameters are modified, this value will change.
	Version *string `json:"version,omitempty"`
	// Content format in which the endpoint should deliver events
	ContentFormat *CreateInputFormat `default:"Raw" json:"contentFormat"`
	// Maximum time (in seconds) between endpoint checkins before considering it unavailable
	HeartbeatInterval *float64 `default:"60" json:"heartbeatInterval"`
	// Interval (in seconds) over which the endpoint should collect events before sending them to Stream
	BatchTimeout *float64 `default:"60" json:"batchTimeout"`
	// Newly subscribed endpoints will send previously existing events. Disable to receive new events only.
	ReadExistingEvents *bool `default:"false" json:"readExistingEvents"`
	// Keep track of which events have been received, resuming from that point after a re-subscription. This setting takes precedence over 'Read existing events'. See [Cribl Docs](https://docs.cribl.io/stream/sources-wef/#subscriptions) for more details.
	SendBookmarks *bool `default:"true" json:"sendBookmarks"`
	// Receive compressed events from the source
	Compress *bool `default:"true" json:"compress"`
	// The DNS names of the endpoints that should forward these events. You may use wildcards, such as *.mydomain.com
	Targets []string `json:"targets"`
	// The RFC-3066 locale the Windows clients should use when sending events. Defaults to "en-US".
	Locale        *string           `default:"en-US" json:"locale"`
	QuerySelector *QueryBuilderMode `default:"simple" json:"querySelector"`
	// Fields to add to events ingested under this subscription
	Metadata []SubscriptionMetadatum `json:"metadata,omitempty"`
}

func (s Subscription) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Subscription) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Subscription) GetSubscriptionName() string {
	if o == nil {
		return ""
	}
	return o.SubscriptionName
}

func (o *Subscription) GetVersion() *string {
	if o == nil {
		return nil
	}
	return o.Version
}

func (o *Subscription) GetContentFormat() *CreateInputFormat {
	if o == nil {
		return nil
	}
	return o.ContentFormat
}

func (o *Subscription) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *Subscription) GetBatchTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.BatchTimeout
}

func (o *Subscription) GetReadExistingEvents() *bool {
	if o == nil {
		return nil
	}
	return o.ReadExistingEvents
}

func (o *Subscription) GetSendBookmarks() *bool {
	if o == nil {
		return nil
	}
	return o.SendBookmarks
}

func (o *Subscription) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *Subscription) GetTargets() []string {
	if o == nil {
		return []string{}
	}
	return o.Targets
}

func (o *Subscription) GetLocale() *string {
	if o == nil {
		return nil
	}
	return o.Locale
}

func (o *Subscription) GetQuerySelector() *QueryBuilderMode {
	if o == nil {
		return nil
	}
	return o.QuerySelector
}

func (o *Subscription) GetMetadata() []SubscriptionMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type MetadatumWef struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumWef) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumWef) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputWef struct {
	// Unique ID for this input
	ID       string   `json:"id"`
	Type     *TypeWef `json:"type,omitempty"`
	Disabled *bool    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWef `json:"connections,omitempty"`
	Pq          *PqWef          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64 `default:"5986" json:"port"`
	// How to authenticate incoming client connections
	AuthMethod *AuthMethodAuthenticationMethod `default:"clientCert" json:"authMethod"`
	TLS        *MTLSSettings                   `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Preserve the client’s original IP address in the __srcIpPort field when connecting through an HTTP proxy that supports the X-Forwarded-For header. This does not apply to TCP-layer Proxy Protocol v1/v2.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"90" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// SHA1 fingerprint expected by the client, if it does not match the first certificate in the configured CA chain
	CaFingerprint *string `json:"caFingerprint,omitempty"`
	// Path to the keytab file containing the service principal credentials. @{product} will use `/etc/krb5.keytab` if not provided.
	Keytab *string `json:"keytab,omitempty"`
	// Kerberos principal used for authentication, typically in the form HTTP/<hostname>@<REALM>
	Principal *string `json:"principal,omitempty"`
	// Allow events to be ingested even if their MachineID does not match the client certificate CN
	AllowMachineIDMismatch *bool `default:"false" json:"allowMachineIdMismatch"`
	// Subscriptions to events on forwarding endpoints
	Subscriptions []Subscription `json:"subscriptions"`
	// Fields to add to events from this input
	Metadata    []MetadatumWef `json:"metadata,omitempty"`
	Description *string        `json:"description,omitempty"`
	// Log a warning if the client certificate authority (CA) fingerprint does not match the expected value. A mismatch prevents Cribl from receiving events from the Windows Event Forwarder.
	LogFingerprintMismatch *bool `default:"false" json:"logFingerprintMismatch"`
}

func (i InputWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWef) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputWef) GetType() *TypeWef {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputWef) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWef) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWef) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWef) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWef) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWef) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWef) GetConnections() []ConnectionWef {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWef) GetPq() *PqWef {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWef) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputWef) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputWef) GetAuthMethod() *AuthMethodAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthMethod
}

func (o *InputWef) GetTLS() *MTLSSettings {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputWef) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputWef) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputWef) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputWef) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputWef) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputWef) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputWef) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputWef) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputWef) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputWef) GetCaFingerprint() *string {
	if o == nil {
		return nil
	}
	return o.CaFingerprint
}

func (o *InputWef) GetKeytab() *string {
	if o == nil {
		return nil
	}
	return o.Keytab
}

func (o *InputWef) GetPrincipal() *string {
	if o == nil {
		return nil
	}
	return o.Principal
}

func (o *InputWef) GetAllowMachineIDMismatch() *bool {
	if o == nil {
		return nil
	}
	return o.AllowMachineIDMismatch
}

func (o *InputWef) GetSubscriptions() []Subscription {
	if o == nil {
		return []Subscription{}
	}
	return o.Subscriptions
}

func (o *InputWef) GetMetadata() []MetadatumWef {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWef) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWef) GetLogFingerprintMismatch() *bool {
	if o == nil {
		return nil
	}
	return o.LogFingerprintMismatch
}

type TypeTCP string

const (
	TypeTCPTCP TypeTCP = "tcp"
)

func (e TypeTCP) ToPointer() *TypeTCP {
	return &e
}
func (e *TypeTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcp":
		*e = TypeTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeTCP: %v", v)
	}
}

type ConnectionTCP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionTCP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeTCP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeTCP string

const (
	ModeTCPSmart  ModeTCP = "smart"
	ModeTCPAlways ModeTCP = "always"
)

func (e ModeTCP) ToPointer() *ModeTCP {
	return &e
}
func (e *ModeTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeTCP: %v", v)
	}
}

// CompressionTCP - Codec to use to compress the persisted data
type CompressionTCP string

const (
	CompressionTCPNone CompressionTCP = "none"
	CompressionTCPGzip CompressionTCP = "gzip"
)

func (e CompressionTCP) ToPointer() *CompressionTCP {
	return &e
}
func (e *CompressionTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionTCP: %v", v)
	}
}

type PqTCP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeTCP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionTCP `default:"none" json:"compress"`
}

func (p PqTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqTCP) GetMode() *ModeTCP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqTCP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqTCP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqTCP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqTCP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqTCP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqTCP) GetCompress() *CompressionTCP {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionTCP string

const (
	MinimumTLSVersionTCPTlSv1  MinimumTLSVersionTCP = "TLSv1"
	MinimumTLSVersionTCPTlSv11 MinimumTLSVersionTCP = "TLSv1.1"
	MinimumTLSVersionTCPTlSv12 MinimumTLSVersionTCP = "TLSv1.2"
	MinimumTLSVersionTCPTlSv13 MinimumTLSVersionTCP = "TLSv1.3"
)

func (e MinimumTLSVersionTCP) ToPointer() *MinimumTLSVersionTCP {
	return &e
}
func (e *MinimumTLSVersionTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionTCP: %v", v)
	}
}

type MaximumTLSVersionTCP string

const (
	MaximumTLSVersionTCPTlSv1  MaximumTLSVersionTCP = "TLSv1"
	MaximumTLSVersionTCPTlSv11 MaximumTLSVersionTCP = "TLSv1.1"
	MaximumTLSVersionTCPTlSv12 MaximumTLSVersionTCP = "TLSv1.2"
	MaximumTLSVersionTCPTlSv13 MaximumTLSVersionTCP = "TLSv1.3"
)

func (e MaximumTLSVersionTCP) ToPointer() *MaximumTLSVersionTCP {
	return &e
}
func (e *MaximumTLSVersionTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionTCP: %v", v)
	}
}

type TLSSettingsServerSideTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                 `default:"false" json:"requestCert"`
	RejectUnauthorized any                   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                   `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionTCP `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionTCP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideTCP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideTCP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideTCP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideTCP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideTCP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideTCP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideTCP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideTCP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideTCP) GetMinVersion() *MinimumTLSVersionTCP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideTCP) GetMaxVersion() *MaximumTLSVersionTCP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumTCP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumTCP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumTCP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PreprocessTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessTCP) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessTCP) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

// AuthenticationMethodTCP - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodTCP string

const (
	AuthenticationMethodTCPManual AuthenticationMethodTCP = "manual"
	AuthenticationMethodTCPSecret AuthenticationMethodTCP = "secret"
)

func (e AuthenticationMethodTCP) ToPointer() *AuthenticationMethodTCP {
	return &e
}
func (e *AuthenticationMethodTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodTCP: %v", v)
	}
}

type InputTCP struct {
	// Unique ID for this input
	ID       string   `json:"id"`
	Type     *TypeTCP `json:"type,omitempty"`
	Disabled *bool    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionTCP `json:"connections,omitempty"`
	Pq          *PqTCP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                   `json:"port"`
	TLS  *TLSSettingsServerSideTCP `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumTCP `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Client will pass the header record with every new connection. The header can contain an authToken, and an object with a list of fields and values to add to every event. These fields can be used to simplify Event Breaker selection, routing, etc. Header has this format, and must be followed by a newline: { "authToken" : "myToken", "fields": { "field1": "value1", "field2": "value2" } }
	EnableHeader *bool          `default:"false" json:"enableHeader"`
	Preprocess   *PreprocessTCP `json:"preprocess,omitempty"`
	Description  *string        `json:"description,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *AuthenticationMethodTCP `default:"manual" json:"authType"`
}

func (i InputTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputTCP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputTCP) GetType() *TypeTCP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputTCP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputTCP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputTCP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputTCP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputTCP) GetConnections() []ConnectionTCP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputTCP) GetPq() *PqTCP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputTCP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputTCP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputTCP) GetTLS() *TLSSettingsServerSideTCP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputTCP) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputTCP) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputTCP) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputTCP) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputTCP) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputTCP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputTCP) GetMetadata() []MetadatumTCP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputTCP) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputTCP) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputTCP) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *InputTCP) GetPreprocess() *PreprocessTCP {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputTCP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputTCP) GetAuthType() *AuthenticationMethodTCP {
	if o == nil {
		return nil
	}
	return o.AuthType
}

type InputSyslogType2 string

const (
	InputSyslogType2Syslog InputSyslogType2 = "syslog"
)

func (e InputSyslogType2) ToPointer() *InputSyslogType2 {
	return &e
}
func (e *InputSyslogType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType2: %v", v)
	}
}

type InputSyslogConnection2 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSyslogConnection2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogConnection2) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSyslogMode2 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSyslogMode2 string

const (
	InputSyslogMode2Smart  InputSyslogMode2 = "smart"
	InputSyslogMode2Always InputSyslogMode2 = "always"
)

func (e InputSyslogMode2) ToPointer() *InputSyslogMode2 {
	return &e
}
func (e *InputSyslogMode2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSyslogMode2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMode2: %v", v)
	}
}

// InputSyslogCompression2 - Codec to use to compress the persisted data
type InputSyslogCompression2 string

const (
	InputSyslogCompression2None InputSyslogCompression2 = "none"
	InputSyslogCompression2Gzip InputSyslogCompression2 = "gzip"
)

func (e InputSyslogCompression2) ToPointer() *InputSyslogCompression2 {
	return &e
}
func (e *InputSyslogCompression2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSyslogCompression2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogCompression2: %v", v)
	}
}

type InputSyslogPq2 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSyslogMode2 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSyslogCompression2 `default:"none" json:"compress"`
}

func (i InputSyslogPq2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPq2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogPq2) GetMode() *InputSyslogMode2 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSyslogPq2) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogPq2) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSyslogPq2) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSyslogPq2) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSyslogPq2) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSyslogPq2) GetCompress() *InputSyslogCompression2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputSyslogMinimumTLSVersion2 string

const (
	InputSyslogMinimumTLSVersion2TlSv1  InputSyslogMinimumTLSVersion2 = "TLSv1"
	InputSyslogMinimumTLSVersion2TlSv11 InputSyslogMinimumTLSVersion2 = "TLSv1.1"
	InputSyslogMinimumTLSVersion2TlSv12 InputSyslogMinimumTLSVersion2 = "TLSv1.2"
	InputSyslogMinimumTLSVersion2TlSv13 InputSyslogMinimumTLSVersion2 = "TLSv1.3"
)

func (e InputSyslogMinimumTLSVersion2) ToPointer() *InputSyslogMinimumTLSVersion2 {
	return &e
}
func (e *InputSyslogMinimumTLSVersion2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMinimumTLSVersion2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMinimumTLSVersion2: %v", v)
	}
}

type InputSyslogMaximumTLSVersion2 string

const (
	InputSyslogMaximumTLSVersion2TlSv1  InputSyslogMaximumTLSVersion2 = "TLSv1"
	InputSyslogMaximumTLSVersion2TlSv11 InputSyslogMaximumTLSVersion2 = "TLSv1.1"
	InputSyslogMaximumTLSVersion2TlSv12 InputSyslogMaximumTLSVersion2 = "TLSv1.2"
	InputSyslogMaximumTLSVersion2TlSv13 InputSyslogMaximumTLSVersion2 = "TLSv1.3"
)

func (e InputSyslogMaximumTLSVersion2) ToPointer() *InputSyslogMaximumTLSVersion2 {
	return &e
}
func (e *InputSyslogMaximumTLSVersion2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMaximumTLSVersion2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMaximumTLSVersion2: %v", v)
	}
}

type InputSyslogTLSSettingsServerSide2 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                          `default:"false" json:"requestCert"`
	RejectUnauthorized any                            `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                            `json:"commonNameRegex,omitempty"`
	MinVersion         *InputSyslogMinimumTLSVersion2 `json:"minVersion,omitempty"`
	MaxVersion         *InputSyslogMaximumTLSVersion2 `json:"maxVersion,omitempty"`
}

func (i InputSyslogTLSSettingsServerSide2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogTLSSettingsServerSide2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogTLSSettingsServerSide2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogTLSSettingsServerSide2) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputSyslogTLSSettingsServerSide2) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputSyslogTLSSettingsServerSide2) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputSyslogTLSSettingsServerSide2) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputSyslogTLSSettingsServerSide2) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputSyslogTLSSettingsServerSide2) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputSyslogTLSSettingsServerSide2) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSyslogTLSSettingsServerSide2) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputSyslogTLSSettingsServerSide2) GetMinVersion() *InputSyslogMinimumTLSVersion2 {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputSyslogTLSSettingsServerSide2) GetMaxVersion() *InputSyslogMaximumTLSVersion2 {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputSyslogMetadatum2 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSyslogMetadatum2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSyslogMetadatum2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSyslogSyslog2 struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     InputSyslogType2 `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSyslogConnection2 `json:"connections,omitempty"`
	Pq          *InputSyslogPq2          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitempty"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort float64 `json:"tcpPort"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `default:"local" json:"timestampTimezone"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitempty"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `default:"false" json:"octetCounting"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `default:"true" json:"inferFraming"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `default:"true" json:"strictlyInferOctetCounting"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `default:"false" json:"allowNonStandardAppName"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                           `default:"0" json:"socketMaxLifespan"`
	TLS               *InputSyslogTLSSettingsServerSide2 `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputSyslogMetadatum2 `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
	// When enabled, parses PROXY protocol headers during the TLS handshake. Disable if compatibility issues arise.
	EnableEnhancedProxyHeaderParsing *bool `json:"enableEnhancedProxyHeaderParsing,omitempty"`
}

func (i InputSyslogSyslog2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogSyslog2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogSyslog2) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSyslogSyslog2) GetType() InputSyslogType2 {
	if o == nil {
		return InputSyslogType2("")
	}
	return o.Type
}

func (o *InputSyslogSyslog2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogSyslog2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogSyslog2) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSyslogSyslog2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSyslogSyslog2) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSyslogSyslog2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSyslogSyslog2) GetConnections() []InputSyslogConnection2 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSyslogSyslog2) GetPq() *InputSyslogPq2 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSyslogSyslog2) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSyslogSyslog2) GetUDPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPPort
}

func (o *InputSyslogSyslog2) GetTCPPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.TCPPort
}

func (o *InputSyslogSyslog2) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogSyslog2) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSyslogSyslog2) GetTimestampTimezone() *string {
	if o == nil {
		return nil
	}
	return o.TimestampTimezone
}

func (o *InputSyslogSyslog2) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputSyslogSyslog2) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSyslogSyslog2) GetKeepFieldsList() []string {
	if o == nil {
		return nil
	}
	return o.KeepFieldsList
}

func (o *InputSyslogSyslog2) GetOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.OctetCounting
}

func (o *InputSyslogSyslog2) GetInferFraming() *bool {
	if o == nil {
		return nil
	}
	return o.InferFraming
}

func (o *InputSyslogSyslog2) GetStrictlyInferOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.StrictlyInferOctetCounting
}

func (o *InputSyslogSyslog2) GetAllowNonStandardAppName() *bool {
	if o == nil {
		return nil
	}
	return o.AllowNonStandardAppName
}

func (o *InputSyslogSyslog2) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSyslogSyslog2) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSyslogSyslog2) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSyslogSyslog2) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSyslogSyslog2) GetTLS() *InputSyslogTLSSettingsServerSide2 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSyslogSyslog2) GetMetadata() []InputSyslogMetadatum2 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSyslogSyslog2) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSyslogSyslog2) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputSyslogSyslog2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSyslogSyslog2) GetEnableEnhancedProxyHeaderParsing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableEnhancedProxyHeaderParsing
}

type InputSyslogType1 string

const (
	InputSyslogType1Syslog InputSyslogType1 = "syslog"
)

func (e InputSyslogType1) ToPointer() *InputSyslogType1 {
	return &e
}
func (e *InputSyslogType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType1: %v", v)
	}
}

type InputSyslogConnection1 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSyslogConnection1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogConnection1) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSyslogMode1 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSyslogMode1 string

const (
	InputSyslogMode1Smart  InputSyslogMode1 = "smart"
	InputSyslogMode1Always InputSyslogMode1 = "always"
)

func (e InputSyslogMode1) ToPointer() *InputSyslogMode1 {
	return &e
}
func (e *InputSyslogMode1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSyslogMode1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMode1: %v", v)
	}
}

// InputSyslogCompression1 - Codec to use to compress the persisted data
type InputSyslogCompression1 string

const (
	InputSyslogCompression1None InputSyslogCompression1 = "none"
	InputSyslogCompression1Gzip InputSyslogCompression1 = "gzip"
)

func (e InputSyslogCompression1) ToPointer() *InputSyslogCompression1 {
	return &e
}
func (e *InputSyslogCompression1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSyslogCompression1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogCompression1: %v", v)
	}
}

type InputSyslogPq1 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSyslogMode1 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSyslogCompression1 `default:"none" json:"compress"`
}

func (i InputSyslogPq1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPq1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogPq1) GetMode() *InputSyslogMode1 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSyslogPq1) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogPq1) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSyslogPq1) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSyslogPq1) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSyslogPq1) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSyslogPq1) GetCompress() *InputSyslogCompression1 {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputSyslogMinimumTLSVersion1 string

const (
	InputSyslogMinimumTLSVersion1TlSv1  InputSyslogMinimumTLSVersion1 = "TLSv1"
	InputSyslogMinimumTLSVersion1TlSv11 InputSyslogMinimumTLSVersion1 = "TLSv1.1"
	InputSyslogMinimumTLSVersion1TlSv12 InputSyslogMinimumTLSVersion1 = "TLSv1.2"
	InputSyslogMinimumTLSVersion1TlSv13 InputSyslogMinimumTLSVersion1 = "TLSv1.3"
)

func (e InputSyslogMinimumTLSVersion1) ToPointer() *InputSyslogMinimumTLSVersion1 {
	return &e
}
func (e *InputSyslogMinimumTLSVersion1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMinimumTLSVersion1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMinimumTLSVersion1: %v", v)
	}
}

type InputSyslogMaximumTLSVersion1 string

const (
	InputSyslogMaximumTLSVersion1TlSv1  InputSyslogMaximumTLSVersion1 = "TLSv1"
	InputSyslogMaximumTLSVersion1TlSv11 InputSyslogMaximumTLSVersion1 = "TLSv1.1"
	InputSyslogMaximumTLSVersion1TlSv12 InputSyslogMaximumTLSVersion1 = "TLSv1.2"
	InputSyslogMaximumTLSVersion1TlSv13 InputSyslogMaximumTLSVersion1 = "TLSv1.3"
)

func (e InputSyslogMaximumTLSVersion1) ToPointer() *InputSyslogMaximumTLSVersion1 {
	return &e
}
func (e *InputSyslogMaximumTLSVersion1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMaximumTLSVersion1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMaximumTLSVersion1: %v", v)
	}
}

type InputSyslogTLSSettingsServerSide1 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                          `default:"false" json:"requestCert"`
	RejectUnauthorized any                            `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                            `json:"commonNameRegex,omitempty"`
	MinVersion         *InputSyslogMinimumTLSVersion1 `json:"minVersion,omitempty"`
	MaxVersion         *InputSyslogMaximumTLSVersion1 `json:"maxVersion,omitempty"`
}

func (i InputSyslogTLSSettingsServerSide1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogTLSSettingsServerSide1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogTLSSettingsServerSide1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogTLSSettingsServerSide1) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputSyslogTLSSettingsServerSide1) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputSyslogTLSSettingsServerSide1) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputSyslogTLSSettingsServerSide1) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputSyslogTLSSettingsServerSide1) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputSyslogTLSSettingsServerSide1) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputSyslogTLSSettingsServerSide1) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSyslogTLSSettingsServerSide1) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputSyslogTLSSettingsServerSide1) GetMinVersion() *InputSyslogMinimumTLSVersion1 {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputSyslogTLSSettingsServerSide1) GetMaxVersion() *InputSyslogMaximumTLSVersion1 {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputSyslogMetadatum1 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSyslogMetadatum1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSyslogMetadatum1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSyslogSyslog1 struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     InputSyslogType1 `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSyslogConnection1 `json:"connections,omitempty"`
	Pq          *InputSyslogPq1          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort float64 `json:"udpPort"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitempty"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `default:"local" json:"timestampTimezone"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitempty"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `default:"false" json:"octetCounting"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `default:"true" json:"inferFraming"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `default:"true" json:"strictlyInferOctetCounting"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `default:"false" json:"allowNonStandardAppName"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                           `default:"0" json:"socketMaxLifespan"`
	TLS               *InputSyslogTLSSettingsServerSide1 `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputSyslogMetadatum1 `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
	// When enabled, parses PROXY protocol headers during the TLS handshake. Disable if compatibility issues arise.
	EnableEnhancedProxyHeaderParsing *bool `json:"enableEnhancedProxyHeaderParsing,omitempty"`
}

func (i InputSyslogSyslog1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogSyslog1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogSyslog1) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSyslogSyslog1) GetType() InputSyslogType1 {
	if o == nil {
		return InputSyslogType1("")
	}
	return o.Type
}

func (o *InputSyslogSyslog1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogSyslog1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogSyslog1) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSyslogSyslog1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSyslogSyslog1) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSyslogSyslog1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSyslogSyslog1) GetConnections() []InputSyslogConnection1 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSyslogSyslog1) GetPq() *InputSyslogPq1 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSyslogSyslog1) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSyslogSyslog1) GetUDPPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.UDPPort
}

func (o *InputSyslogSyslog1) GetTCPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.TCPPort
}

func (o *InputSyslogSyslog1) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogSyslog1) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSyslogSyslog1) GetTimestampTimezone() *string {
	if o == nil {
		return nil
	}
	return o.TimestampTimezone
}

func (o *InputSyslogSyslog1) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputSyslogSyslog1) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSyslogSyslog1) GetKeepFieldsList() []string {
	if o == nil {
		return nil
	}
	return o.KeepFieldsList
}

func (o *InputSyslogSyslog1) GetOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.OctetCounting
}

func (o *InputSyslogSyslog1) GetInferFraming() *bool {
	if o == nil {
		return nil
	}
	return o.InferFraming
}

func (o *InputSyslogSyslog1) GetStrictlyInferOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.StrictlyInferOctetCounting
}

func (o *InputSyslogSyslog1) GetAllowNonStandardAppName() *bool {
	if o == nil {
		return nil
	}
	return o.AllowNonStandardAppName
}

func (o *InputSyslogSyslog1) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSyslogSyslog1) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSyslogSyslog1) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSyslogSyslog1) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSyslogSyslog1) GetTLS() *InputSyslogTLSSettingsServerSide1 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSyslogSyslog1) GetMetadata() []InputSyslogMetadatum1 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSyslogSyslog1) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSyslogSyslog1) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputSyslogSyslog1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSyslogSyslog1) GetEnableEnhancedProxyHeaderParsing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableEnhancedProxyHeaderParsing
}

type InputSyslogType string

const (
	InputSyslogTypeInputSyslogSyslog1 InputSyslogType = "InputSyslog_Syslog_1"
	InputSyslogTypeInputSyslogSyslog2 InputSyslogType = "InputSyslog_Syslog_2"
)

type InputSyslog struct {
	InputSyslogSyslog1 *InputSyslogSyslog1 `queryParam:"inline"`
	InputSyslogSyslog2 *InputSyslogSyslog2 `queryParam:"inline"`

	Type InputSyslogType
}

func CreateInputSyslogInputSyslogSyslog1(inputSyslogSyslog1 InputSyslogSyslog1) InputSyslog {
	typ := InputSyslogTypeInputSyslogSyslog1

	return InputSyslog{
		InputSyslogSyslog1: &inputSyslogSyslog1,
		Type:               typ,
	}
}

func CreateInputSyslogInputSyslogSyslog2(inputSyslogSyslog2 InputSyslogSyslog2) InputSyslog {
	typ := InputSyslogTypeInputSyslogSyslog2

	return InputSyslog{
		InputSyslogSyslog2: &inputSyslogSyslog2,
		Type:               typ,
	}
}

func (u *InputSyslog) UnmarshalJSON(data []byte) error {

	var inputSyslogSyslog1 InputSyslogSyslog1 = InputSyslogSyslog1{}
	if err := utils.UnmarshalJSON(data, &inputSyslogSyslog1, "", true, true); err == nil {
		u.InputSyslogSyslog1 = &inputSyslogSyslog1
		u.Type = InputSyslogTypeInputSyslogSyslog1
		return nil
	}

	var inputSyslogSyslog2 InputSyslogSyslog2 = InputSyslogSyslog2{}
	if err := utils.UnmarshalJSON(data, &inputSyslogSyslog2, "", true, true); err == nil {
		u.InputSyslogSyslog2 = &inputSyslogSyslog2
		u.Type = InputSyslogTypeInputSyslogSyslog2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputSyslog", string(data))
}

func (u InputSyslog) MarshalJSON() ([]byte, error) {
	if u.InputSyslogSyslog1 != nil {
		return utils.MarshalJSON(u.InputSyslogSyslog1, "", true)
	}

	if u.InputSyslogSyslog2 != nil {
		return utils.MarshalJSON(u.InputSyslogSyslog2, "", true)
	}

	return nil, errors.New("could not marshal union type InputSyslog: all fields are null")
}

type CreateInputTypeSqs string

const (
	CreateInputTypeSqsSqs CreateInputTypeSqs = "sqs"
)

func (e CreateInputTypeSqs) ToPointer() *CreateInputTypeSqs {
	return &e
}
func (e *CreateInputTypeSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sqs":
		*e = CreateInputTypeSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSqs: %v", v)
	}
}

type ConnectionSqs struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSqs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSqs) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeSqs - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeSqs string

const (
	CreateInputModeSqsSmart  CreateInputModeSqs = "smart"
	CreateInputModeSqsAlways CreateInputModeSqs = "always"
)

func (e CreateInputModeSqs) ToPointer() *CreateInputModeSqs {
	return &e
}
func (e *CreateInputModeSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeSqs: %v", v)
	}
}

// PqCompressionSqs - Codec to use to compress the persisted data
type PqCompressionSqs string

const (
	PqCompressionSqsNone PqCompressionSqs = "none"
	PqCompressionSqsGzip PqCompressionSqs = "gzip"
)

func (e PqCompressionSqs) ToPointer() *PqCompressionSqs {
	return &e
}
func (e *PqCompressionSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionSqs: %v", v)
	}
}

type PqSqs struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeSqs `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionSqs `default:"none" json:"compress"`
}

func (p PqSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSqs) GetMode() *CreateInputModeSqs {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSqs) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSqs) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSqs) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSqs) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSqs) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSqs) GetCompress() *PqCompressionSqs {
	if o == nil {
		return nil
	}
	return o.Compress
}

// CreateInputQueueType - The queue type used (or created)
type CreateInputQueueType string

const (
	CreateInputQueueTypeStandard CreateInputQueueType = "standard"
	CreateInputQueueTypeFifo     CreateInputQueueType = "fifo"
)

func (e CreateInputQueueType) ToPointer() *CreateInputQueueType {
	return &e
}
func (e *CreateInputQueueType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "standard":
		fallthrough
	case "fifo":
		*e = CreateInputQueueType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputQueueType: %v", v)
	}
}

// CreateInputAuthenticationMethodSqs - AWS authentication method. Choose Auto to use IAM roles.
type CreateInputAuthenticationMethodSqs string

const (
	CreateInputAuthenticationMethodSqsAuto   CreateInputAuthenticationMethodSqs = "auto"
	CreateInputAuthenticationMethodSqsManual CreateInputAuthenticationMethodSqs = "manual"
	CreateInputAuthenticationMethodSqsSecret CreateInputAuthenticationMethodSqs = "secret"
)

func (e CreateInputAuthenticationMethodSqs) ToPointer() *CreateInputAuthenticationMethodSqs {
	return &e
}
func (e *CreateInputAuthenticationMethodSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = CreateInputAuthenticationMethodSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAuthenticationMethodSqs: %v", v)
	}
}

// CreateInputSignatureVersionSqs - Signature version to use for signing SQS requests
type CreateInputSignatureVersionSqs string

const (
	CreateInputSignatureVersionSqsV2 CreateInputSignatureVersionSqs = "v2"
	CreateInputSignatureVersionSqsV4 CreateInputSignatureVersionSqs = "v4"
)

func (e CreateInputSignatureVersionSqs) ToPointer() *CreateInputSignatureVersionSqs {
	return &e
}
func (e *CreateInputSignatureVersionSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = CreateInputSignatureVersionSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputSignatureVersionSqs: %v", v)
	}
}

type MetadatumSqs struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSqs) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSqs) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSqs struct {
	// Unique ID for this input
	ID       string              `json:"id"`
	Type     *CreateInputTypeSqs `json:"type,omitempty"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSqs `json:"connections,omitempty"`
	Pq          *PqSqs          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read events from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can only be evaluated at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// The queue type used (or created)
	QueueType *CreateInputQueueType `default:"standard" json:"queueType"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// Create queue if it does not exist
	CreateQueue *bool `default:"false" json:"createQueue"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *CreateInputAuthenticationMethodSqs `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                             `json:"awsSecretKey,omitempty"`
	// AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SQS requests
	SignatureVersion *CreateInputSignatureVersionSqs `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access SQS
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"10" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// Fields to add to events from this input
	Metadata []MetadatumSqs `json:"metadata,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	Description *string  `json:"description,omitempty"`
	AwsAPIKey   *string  `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"3" json:"numReceivers"`
}

func (i InputSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSqs) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSqs) GetType() *CreateInputTypeSqs {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSqs) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSqs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSqs) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSqs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSqs) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSqs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSqs) GetConnections() []ConnectionSqs {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSqs) GetPq() *PqSqs {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSqs) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputSqs) GetQueueType() *CreateInputQueueType {
	if o == nil {
		return nil
	}
	return o.QueueType
}

func (o *InputSqs) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputSqs) GetCreateQueue() *bool {
	if o == nil {
		return nil
	}
	return o.CreateQueue
}

func (o *InputSqs) GetAwsAuthenticationMethod() *CreateInputAuthenticationMethodSqs {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputSqs) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputSqs) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputSqs) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSqs) GetSignatureVersion() *CreateInputSignatureVersionSqs {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputSqs) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputSqs) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSqs) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputSqs) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputSqs) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputSqs) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputSqs) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputSqs) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputSqs) GetMetadata() []MetadatumSqs {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSqs) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputSqs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSqs) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputSqs) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputSqs) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

type TypeModelDrivenTelemetry string

const (
	TypeModelDrivenTelemetryModelDrivenTelemetry TypeModelDrivenTelemetry = "model_driven_telemetry"
)

func (e TypeModelDrivenTelemetry) ToPointer() *TypeModelDrivenTelemetry {
	return &e
}
func (e *TypeModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "model_driven_telemetry":
		*e = TypeModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeModelDrivenTelemetry: %v", v)
	}
}

type ConnectionModelDrivenTelemetry struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionModelDrivenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionModelDrivenTelemetry) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeModelDrivenTelemetry - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeModelDrivenTelemetry string

const (
	ModeModelDrivenTelemetrySmart  ModeModelDrivenTelemetry = "smart"
	ModeModelDrivenTelemetryAlways ModeModelDrivenTelemetry = "always"
)

func (e ModeModelDrivenTelemetry) ToPointer() *ModeModelDrivenTelemetry {
	return &e
}
func (e *ModeModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeModelDrivenTelemetry: %v", v)
	}
}

// CompressionModelDrivenTelemetry - Codec to use to compress the persisted data
type CompressionModelDrivenTelemetry string

const (
	CompressionModelDrivenTelemetryNone CompressionModelDrivenTelemetry = "none"
	CompressionModelDrivenTelemetryGzip CompressionModelDrivenTelemetry = "gzip"
)

func (e CompressionModelDrivenTelemetry) ToPointer() *CompressionModelDrivenTelemetry {
	return &e
}
func (e *CompressionModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionModelDrivenTelemetry: %v", v)
	}
}

type PqModelDrivenTelemetry struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeModelDrivenTelemetry `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionModelDrivenTelemetry `default:"none" json:"compress"`
}

func (p PqModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqModelDrivenTelemetry) GetMode() *ModeModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqModelDrivenTelemetry) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqModelDrivenTelemetry) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqModelDrivenTelemetry) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqModelDrivenTelemetry) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqModelDrivenTelemetry) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqModelDrivenTelemetry) GetCompress() *CompressionModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionModelDrivenTelemetry string

const (
	MinimumTLSVersionModelDrivenTelemetryTlSv1  MinimumTLSVersionModelDrivenTelemetry = "TLSv1"
	MinimumTLSVersionModelDrivenTelemetryTlSv11 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.1"
	MinimumTLSVersionModelDrivenTelemetryTlSv12 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.2"
	MinimumTLSVersionModelDrivenTelemetryTlSv13 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.3"
)

func (e MinimumTLSVersionModelDrivenTelemetry) ToPointer() *MinimumTLSVersionModelDrivenTelemetry {
	return &e
}
func (e *MinimumTLSVersionModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionModelDrivenTelemetry: %v", v)
	}
}

type MaximumTLSVersionModelDrivenTelemetry string

const (
	MaximumTLSVersionModelDrivenTelemetryTlSv1  MaximumTLSVersionModelDrivenTelemetry = "TLSv1"
	MaximumTLSVersionModelDrivenTelemetryTlSv11 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.1"
	MaximumTLSVersionModelDrivenTelemetryTlSv12 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.2"
	MaximumTLSVersionModelDrivenTelemetryTlSv13 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.3"
)

func (e MaximumTLSVersionModelDrivenTelemetry) ToPointer() *MaximumTLSVersionModelDrivenTelemetry {
	return &e
}
func (e *MaximumTLSVersionModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionModelDrivenTelemetry: %v", v)
	}
}

type TLSSettingsServerSideModelDrivenTelemetry struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                                  `default:"false" json:"requestCert"`
	RejectUnauthorized any                                    `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                                    `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionModelDrivenTelemetry `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionModelDrivenTelemetry `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetMinVersion() *MinimumTLSVersionModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetMaxVersion() *MaximumTLSVersionModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumModelDrivenTelemetry struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumModelDrivenTelemetry) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumModelDrivenTelemetry) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputModelDrivenTelemetry struct {
	// Unique ID for this input
	ID       string                    `json:"id"`
	Type     *TypeModelDrivenTelemetry `json:"type,omitempty"`
	Disabled *bool                     `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionModelDrivenTelemetry `json:"connections,omitempty"`
	Pq          *PqModelDrivenTelemetry          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64                                   `default:"57000" json:"port"`
	TLS  *TLSSettingsServerSideModelDrivenTelemetry `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumModelDrivenTelemetry `json:"metadata,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// Time in milliseconds to allow the server to shutdown gracefully before forcing shutdown. Defaults to 5000.
	ShutdownTimeoutMs *float64 `default:"5000" json:"shutdownTimeoutMs"`
	Description       *string  `json:"description,omitempty"`
}

func (i InputModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputModelDrivenTelemetry) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputModelDrivenTelemetry) GetType() *TypeModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputModelDrivenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputModelDrivenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputModelDrivenTelemetry) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputModelDrivenTelemetry) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputModelDrivenTelemetry) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputModelDrivenTelemetry) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputModelDrivenTelemetry) GetConnections() []ConnectionModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputModelDrivenTelemetry) GetPq() *PqModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputModelDrivenTelemetry) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputModelDrivenTelemetry) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputModelDrivenTelemetry) GetTLS() *TLSSettingsServerSideModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputModelDrivenTelemetry) GetMetadata() []MetadatumModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputModelDrivenTelemetry) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputModelDrivenTelemetry) GetShutdownTimeoutMs() *float64 {
	if o == nil {
		return nil
	}
	return o.ShutdownTimeoutMs
}

func (o *InputModelDrivenTelemetry) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateInputTypeOpenTelemetry string

const (
	CreateInputTypeOpenTelemetryOpenTelemetry CreateInputTypeOpenTelemetry = "open_telemetry"
)

func (e CreateInputTypeOpenTelemetry) ToPointer() *CreateInputTypeOpenTelemetry {
	return &e
}
func (e *CreateInputTypeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "open_telemetry":
		*e = CreateInputTypeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeOpenTelemetry: %v", v)
	}
}

type ConnectionOpenTelemetry struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionOpenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionOpenTelemetry) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeOpenTelemetry - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeOpenTelemetry string

const (
	CreateInputModeOpenTelemetrySmart  CreateInputModeOpenTelemetry = "smart"
	CreateInputModeOpenTelemetryAlways CreateInputModeOpenTelemetry = "always"
)

func (e CreateInputModeOpenTelemetry) ToPointer() *CreateInputModeOpenTelemetry {
	return &e
}
func (e *CreateInputModeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeOpenTelemetry: %v", v)
	}
}

// PqCompressionOpenTelemetry - Codec to use to compress the persisted data
type PqCompressionOpenTelemetry string

const (
	PqCompressionOpenTelemetryNone PqCompressionOpenTelemetry = "none"
	PqCompressionOpenTelemetryGzip PqCompressionOpenTelemetry = "gzip"
)

func (e PqCompressionOpenTelemetry) ToPointer() *PqCompressionOpenTelemetry {
	return &e
}
func (e *PqCompressionOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionOpenTelemetry: %v", v)
	}
}

type PqOpenTelemetry struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeOpenTelemetry `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionOpenTelemetry `default:"none" json:"compress"`
}

func (p PqOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqOpenTelemetry) GetMode() *CreateInputModeOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqOpenTelemetry) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqOpenTelemetry) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqOpenTelemetry) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqOpenTelemetry) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqOpenTelemetry) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqOpenTelemetry) GetCompress() *PqCompressionOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Compress
}

type CreateInputMinimumTLSVersionOpenTelemetry string

const (
	CreateInputMinimumTLSVersionOpenTelemetryTlSv1  CreateInputMinimumTLSVersionOpenTelemetry = "TLSv1"
	CreateInputMinimumTLSVersionOpenTelemetryTlSv11 CreateInputMinimumTLSVersionOpenTelemetry = "TLSv1.1"
	CreateInputMinimumTLSVersionOpenTelemetryTlSv12 CreateInputMinimumTLSVersionOpenTelemetry = "TLSv1.2"
	CreateInputMinimumTLSVersionOpenTelemetryTlSv13 CreateInputMinimumTLSVersionOpenTelemetry = "TLSv1.3"
)

func (e CreateInputMinimumTLSVersionOpenTelemetry) ToPointer() *CreateInputMinimumTLSVersionOpenTelemetry {
	return &e
}
func (e *CreateInputMinimumTLSVersionOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMinimumTLSVersionOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMinimumTLSVersionOpenTelemetry: %v", v)
	}
}

type CreateInputMaximumTLSVersionOpenTelemetry string

const (
	CreateInputMaximumTLSVersionOpenTelemetryTlSv1  CreateInputMaximumTLSVersionOpenTelemetry = "TLSv1"
	CreateInputMaximumTLSVersionOpenTelemetryTlSv11 CreateInputMaximumTLSVersionOpenTelemetry = "TLSv1.1"
	CreateInputMaximumTLSVersionOpenTelemetryTlSv12 CreateInputMaximumTLSVersionOpenTelemetry = "TLSv1.2"
	CreateInputMaximumTLSVersionOpenTelemetryTlSv13 CreateInputMaximumTLSVersionOpenTelemetry = "TLSv1.3"
)

func (e CreateInputMaximumTLSVersionOpenTelemetry) ToPointer() *CreateInputMaximumTLSVersionOpenTelemetry {
	return &e
}
func (e *CreateInputMaximumTLSVersionOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMaximumTLSVersionOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMaximumTLSVersionOpenTelemetry: %v", v)
	}
}

type TLSSettingsServerSideOpenTelemetry struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                                      `default:"false" json:"requestCert"`
	RejectUnauthorized any                                        `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                                        `json:"commonNameRegex,omitempty"`
	MinVersion         *CreateInputMinimumTLSVersionOpenTelemetry `json:"minVersion,omitempty"`
	MaxVersion         *CreateInputMaximumTLSVersionOpenTelemetry `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideOpenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideOpenTelemetry) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideOpenTelemetry) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideOpenTelemetry) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideOpenTelemetry) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideOpenTelemetry) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideOpenTelemetry) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideOpenTelemetry) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideOpenTelemetry) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideOpenTelemetry) GetMinVersion() *CreateInputMinimumTLSVersionOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideOpenTelemetry) GetMaxVersion() *CreateInputMaximumTLSVersionOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// CreateInputProtocolOpenTelemetry - Select whether to leverage gRPC or HTTP for OpenTelemetry
type CreateInputProtocolOpenTelemetry string

const (
	CreateInputProtocolOpenTelemetryGrpc CreateInputProtocolOpenTelemetry = "grpc"
	CreateInputProtocolOpenTelemetryHTTP CreateInputProtocolOpenTelemetry = "http"
)

func (e CreateInputProtocolOpenTelemetry) ToPointer() *CreateInputProtocolOpenTelemetry {
	return &e
}
func (e *CreateInputProtocolOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "http":
		*e = CreateInputProtocolOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputProtocolOpenTelemetry: %v", v)
	}
}

// CreateInputOTLPVersion - The version of OTLP Protobuf definitions to use when interpreting received data
type CreateInputOTLPVersion string

const (
	CreateInputOTLPVersionZeroDot10Dot0 CreateInputOTLPVersion = "0.10.0"
	CreateInputOTLPVersionOneDot3Dot1   CreateInputOTLPVersion = "1.3.1"
)

func (e CreateInputOTLPVersion) ToPointer() *CreateInputOTLPVersion {
	return &e
}
func (e *CreateInputOTLPVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "0.10.0":
		fallthrough
	case "1.3.1":
		*e = CreateInputOTLPVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputOTLPVersion: %v", v)
	}
}

// CreateInputAuthenticationTypeOpenTelemetry - OpenTelemetry authentication type
type CreateInputAuthenticationTypeOpenTelemetry string

const (
	CreateInputAuthenticationTypeOpenTelemetryNone              CreateInputAuthenticationTypeOpenTelemetry = "none"
	CreateInputAuthenticationTypeOpenTelemetryBasic             CreateInputAuthenticationTypeOpenTelemetry = "basic"
	CreateInputAuthenticationTypeOpenTelemetryCredentialsSecret CreateInputAuthenticationTypeOpenTelemetry = "credentialsSecret"
	CreateInputAuthenticationTypeOpenTelemetryToken             CreateInputAuthenticationTypeOpenTelemetry = "token"
	CreateInputAuthenticationTypeOpenTelemetryTextSecret        CreateInputAuthenticationTypeOpenTelemetry = "textSecret"
	CreateInputAuthenticationTypeOpenTelemetryOauth             CreateInputAuthenticationTypeOpenTelemetry = "oauth"
)

func (e CreateInputAuthenticationTypeOpenTelemetry) ToPointer() *CreateInputAuthenticationTypeOpenTelemetry {
	return &e
}
func (e *CreateInputAuthenticationTypeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = CreateInputAuthenticationTypeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAuthenticationTypeOpenTelemetry: %v", v)
	}
}

type CreateInputMetadatumOpenTelemetry struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *CreateInputMetadatumOpenTelemetry) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *CreateInputMetadatumOpenTelemetry) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CreateInputOauthParamOpenTelemetry struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *CreateInputOauthParamOpenTelemetry) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *CreateInputOauthParamOpenTelemetry) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CreateInputOauthHeaderOpenTelemetry struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *CreateInputOauthHeaderOpenTelemetry) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *CreateInputOauthHeaderOpenTelemetry) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputOpenTelemetry struct {
	// Unique ID for this input
	ID       string                        `json:"id"`
	Type     *CreateInputTypeOpenTelemetry `json:"type,omitempty"`
	Disabled *bool                         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOpenTelemetry `json:"connections,omitempty"`
	Pq          *PqOpenTelemetry          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64                            `default:"4317" json:"port"`
	TLS  *TLSSettingsServerSideOpenTelemetry `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket  *int64 `default:"0" json:"maxRequestsPerSocket"`
	EnableProxyHeader     any    `json:"enableProxyHeader,omitempty"`
	CaptureHeaders        any    `json:"captureHeaders,omitempty"`
	ActivityLogSampleRate any    `json:"activityLogSampleRate,omitempty"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"15" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Select whether to leverage gRPC or HTTP for OpenTelemetry
	Protocol *CreateInputProtocolOpenTelemetry `default:"grpc" json:"protocol"`
	// Enable to extract each incoming span to a separate event
	ExtractSpans *bool `default:"false" json:"extractSpans"`
	// Enable to extract each incoming Gauge or IntGauge metric to multiple events, one per data point
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// The version of OTLP Protobuf definitions to use when interpreting received data
	OtlpVersion *CreateInputOTLPVersion `default:"0.10.0" json:"otlpVersion"`
	// OpenTelemetry authentication type
	AuthType *CreateInputAuthenticationTypeOpenTelemetry `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata []CreateInputMetadatumOpenTelemetry `json:"metadata,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	Description  *string  `json:"description,omitempty"`
	Username     *string  `json:"username,omitempty"`
	Password     *string  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []CreateInputOauthParamOpenTelemetry `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []CreateInputOauthHeaderOpenTelemetry `json:"oauthHeaders,omitempty"`
	// Enable to extract each incoming log record to a separate event
	ExtractLogs *bool `default:"false" json:"extractLogs"`
}

func (i InputOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOpenTelemetry) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputOpenTelemetry) GetType() *CreateInputTypeOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOpenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOpenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOpenTelemetry) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOpenTelemetry) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOpenTelemetry) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOpenTelemetry) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOpenTelemetry) GetConnections() []ConnectionOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOpenTelemetry) GetPq() *PqOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOpenTelemetry) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputOpenTelemetry) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputOpenTelemetry) GetTLS() *TLSSettingsServerSideOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputOpenTelemetry) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputOpenTelemetry) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputOpenTelemetry) GetEnableProxyHeader() any {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputOpenTelemetry) GetCaptureHeaders() any {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputOpenTelemetry) GetActivityLogSampleRate() any {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputOpenTelemetry) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputOpenTelemetry) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputOpenTelemetry) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputOpenTelemetry) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputOpenTelemetry) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputOpenTelemetry) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputOpenTelemetry) GetProtocol() *CreateInputProtocolOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *InputOpenTelemetry) GetExtractSpans() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractSpans
}

func (o *InputOpenTelemetry) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputOpenTelemetry) GetOtlpVersion() *CreateInputOTLPVersion {
	if o == nil {
		return nil
	}
	return o.OtlpVersion
}

func (o *InputOpenTelemetry) GetAuthType() *CreateInputAuthenticationTypeOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOpenTelemetry) GetMetadata() []CreateInputMetadatumOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOpenTelemetry) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputOpenTelemetry) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOpenTelemetry) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputOpenTelemetry) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputOpenTelemetry) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputOpenTelemetry) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputOpenTelemetry) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOpenTelemetry) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputOpenTelemetry) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputOpenTelemetry) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputOpenTelemetry) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputOpenTelemetry) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputOpenTelemetry) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputOpenTelemetry) GetOauthParams() []CreateInputOauthParamOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputOpenTelemetry) GetOauthHeaders() []CreateInputOauthHeaderOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputOpenTelemetry) GetExtractLogs() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractLogs
}

type CreateInputTypeSnmp string

const (
	CreateInputTypeSnmpSnmp CreateInputTypeSnmp = "snmp"
)

func (e CreateInputTypeSnmp) ToPointer() *CreateInputTypeSnmp {
	return &e
}
func (e *CreateInputTypeSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snmp":
		*e = CreateInputTypeSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSnmp: %v", v)
	}
}

type ConnectionSnmp struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSnmp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSnmp) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeSnmp - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSnmp string

const (
	ModeSnmpSmart  ModeSnmp = "smart"
	ModeSnmpAlways ModeSnmp = "always"
)

func (e ModeSnmp) ToPointer() *ModeSnmp {
	return &e
}
func (e *ModeSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeSnmp: %v", v)
	}
}

// CompressionSnmp - Codec to use to compress the persisted data
type CompressionSnmp string

const (
	CompressionSnmpNone CompressionSnmp = "none"
	CompressionSnmpGzip CompressionSnmp = "gzip"
)

func (e CompressionSnmp) ToPointer() *CompressionSnmp {
	return &e
}
func (e *CompressionSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSnmp: %v", v)
	}
}

type PqSnmp struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSnmp `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSnmp `default:"none" json:"compress"`
}

func (p PqSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSnmp) GetMode() *ModeSnmp {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSnmp) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSnmp) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSnmp) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSnmp) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSnmp) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSnmp) GetCompress() *CompressionSnmp {
	if o == nil {
		return nil
	}
	return o.Compress
}

type AuthenticationProtocol string

const (
	AuthenticationProtocolNone   AuthenticationProtocol = "none"
	AuthenticationProtocolMd5    AuthenticationProtocol = "md5"
	AuthenticationProtocolSha    AuthenticationProtocol = "sha"
	AuthenticationProtocolSha224 AuthenticationProtocol = "sha224"
	AuthenticationProtocolSha256 AuthenticationProtocol = "sha256"
	AuthenticationProtocolSha384 AuthenticationProtocol = "sha384"
	AuthenticationProtocolSha512 AuthenticationProtocol = "sha512"
)

func (e AuthenticationProtocol) ToPointer() *AuthenticationProtocol {
	return &e
}
func (e *AuthenticationProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "md5":
		fallthrough
	case "sha":
		fallthrough
	case "sha224":
		fallthrough
	case "sha256":
		fallthrough
	case "sha384":
		fallthrough
	case "sha512":
		*e = AuthenticationProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationProtocol: %v", v)
	}
}

type V3User struct {
	Name         string                  `json:"name"`
	AuthProtocol *AuthenticationProtocol `default:"none" json:"authProtocol"`
	AuthKey      any                     `json:"authKey,omitempty"`
	PrivProtocol *string                 `default:"none" json:"privProtocol"`
}

func (v V3User) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(v, "", false)
}

func (v *V3User) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &v, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *V3User) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *V3User) GetAuthProtocol() *AuthenticationProtocol {
	if o == nil {
		return nil
	}
	return o.AuthProtocol
}

func (o *V3User) GetAuthKey() any {
	if o == nil {
		return nil
	}
	return o.AuthKey
}

func (o *V3User) GetPrivProtocol() *string {
	if o == nil {
		return nil
	}
	return o.PrivProtocol
}

// SNMPv3Authentication - Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
type SNMPv3Authentication struct {
	V3AuthEnabled *bool `default:"false" json:"v3AuthEnabled"`
	// Pass through traps that don't match any of the configured users. @{product} will not attempt to decrypt these traps.
	AllowUnmatchedTrap *bool `default:"false" json:"allowUnmatchedTrap"`
	// User credentials for receiving v3 traps
	V3Users []V3User `json:"v3Users,omitempty"`
}

func (s SNMPv3Authentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SNMPv3Authentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SNMPv3Authentication) GetV3AuthEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.V3AuthEnabled
}

func (o *SNMPv3Authentication) GetAllowUnmatchedTrap() *bool {
	if o == nil {
		return nil
	}
	return o.AllowUnmatchedTrap
}

func (o *SNMPv3Authentication) GetV3Users() []V3User {
	if o == nil {
		return nil
	}
	return o.V3Users
}

type MetadatumSnmp struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSnmp) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSnmp) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSnmp struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     *CreateInputTypeSnmp `json:"type,omitempty"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSnmp `json:"connections,omitempty"`
	Pq          *PqSnmp          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// UDP port to receive SNMP traps on. Defaults to 162.
	Port *float64 `default:"162" json:"port"`
	// Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
	SnmpV3Auth *SNMPv3Authentication `json:"snmpV3Auth,omitempty"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Fields to add to events from this input
	Metadata []MetadatumSnmp `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// If enabled, parses varbinds as an array of objects that include OID, value, and type
	VarbindsWithTypes *bool `default:"false" json:"varbindsWithTypes"`
	// If enabled, the parser will attempt to parse varbind octet strings as UTF-8, first, otherwise will fallback to other methods
	BestEffortParsing *bool   `default:"false" json:"bestEffortParsing"`
	Description       *string `json:"description,omitempty"`
}

func (i InputSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSnmp) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSnmp) GetType() *CreateInputTypeSnmp {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSnmp) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSnmp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSnmp) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSnmp) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSnmp) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSnmp) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSnmp) GetConnections() []ConnectionSnmp {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSnmp) GetPq() *PqSnmp {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSnmp) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSnmp) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputSnmp) GetSnmpV3Auth() *SNMPv3Authentication {
	if o == nil {
		return nil
	}
	return o.SnmpV3Auth
}

func (o *InputSnmp) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSnmp) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSnmp) GetMetadata() []MetadatumSnmp {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSnmp) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSnmp) GetVarbindsWithTypes() *bool {
	if o == nil {
		return nil
	}
	return o.VarbindsWithTypes
}

func (o *InputSnmp) GetBestEffortParsing() *bool {
	if o == nil {
		return nil
	}
	return o.BestEffortParsing
}

func (o *InputSnmp) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeS3Inventory string

const (
	TypeS3InventoryS3Inventory TypeS3Inventory = "s3_inventory"
)

func (e TypeS3Inventory) ToPointer() *TypeS3Inventory {
	return &e
}
func (e *TypeS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3_inventory":
		*e = TypeS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeS3Inventory: %v", v)
	}
}

type ConnectionS3Inventory struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionS3Inventory) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionS3Inventory) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeS3Inventory - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeS3Inventory string

const (
	ModeS3InventorySmart  ModeS3Inventory = "smart"
	ModeS3InventoryAlways ModeS3Inventory = "always"
)

func (e ModeS3Inventory) ToPointer() *ModeS3Inventory {
	return &e
}
func (e *ModeS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeS3Inventory: %v", v)
	}
}

// CompressionS3Inventory - Codec to use to compress the persisted data
type CompressionS3Inventory string

const (
	CompressionS3InventoryNone CompressionS3Inventory = "none"
	CompressionS3InventoryGzip CompressionS3Inventory = "gzip"
)

func (e CompressionS3Inventory) ToPointer() *CompressionS3Inventory {
	return &e
}
func (e *CompressionS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionS3Inventory: %v", v)
	}
}

type PqS3Inventory struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeS3Inventory `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionS3Inventory `default:"none" json:"compress"`
}

func (p PqS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqS3Inventory) GetMode() *ModeS3Inventory {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqS3Inventory) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqS3Inventory) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqS3Inventory) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqS3Inventory) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqS3Inventory) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqS3Inventory) GetCompress() *CompressionS3Inventory {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodS3Inventory - AWS authentication method. Choose Auto to use IAM roles.
type AuthenticationMethodS3Inventory string

const (
	AuthenticationMethodS3InventoryAuto   AuthenticationMethodS3Inventory = "auto"
	AuthenticationMethodS3InventoryManual AuthenticationMethodS3Inventory = "manual"
	AuthenticationMethodS3InventorySecret AuthenticationMethodS3Inventory = "secret"
)

func (e AuthenticationMethodS3Inventory) ToPointer() *AuthenticationMethodS3Inventory {
	return &e
}
func (e *AuthenticationMethodS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodS3Inventory: %v", v)
	}
}

// SignatureVersionS3Inventory - Signature version to use for signing S3 requests
type SignatureVersionS3Inventory string

const (
	SignatureVersionS3InventoryV2 SignatureVersionS3Inventory = "v2"
	SignatureVersionS3InventoryV4 SignatureVersionS3Inventory = "v4"
)

func (e SignatureVersionS3Inventory) ToPointer() *SignatureVersionS3Inventory {
	return &e
}
func (e *SignatureVersionS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersionS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersionS3Inventory: %v", v)
	}
}

type PreprocessS3Inventory struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessS3Inventory) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessS3Inventory) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessS3Inventory) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type MetadatumS3Inventory struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumS3Inventory) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumS3Inventory) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CheckpointingS3Inventory struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CheckpointingS3Inventory) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CheckpointingS3Inventory) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type TagAfterProcessingS3Inventory string

const (
	TagAfterProcessingS3InventoryFalse TagAfterProcessingS3Inventory = "false"
	TagAfterProcessingS3InventoryTrue  TagAfterProcessingS3Inventory = "true"
)

func (e TagAfterProcessingS3Inventory) ToPointer() *TagAfterProcessingS3Inventory {
	return &e
}
func (e *TagAfterProcessingS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "false":
		fallthrough
	case "true":
		*e = TagAfterProcessingS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TagAfterProcessingS3Inventory: %v", v)
	}
}

type InputS3Inventory struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     TypeS3Inventory `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionS3Inventory `json:"connections,omitempty"`
	Pq          *PqS3Inventory          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethodS3Inventory `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                          `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *SignatureVersionS3Inventory `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                  `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessS3Inventory `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumS3Inventory `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                  `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingS3Inventory `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Filename suffix of the manifest checksum file. If a filename matching this suffix is received        in the queue, the matching manifest file will be downloaded and validated against its value. Defaults to "checksum"
	ChecksumSuffix *string `default:"checksum" json:"checksumSuffix"`
	// Maximum download size (KB) of each manifest or checksum file. Manifest files larger than this size will not be read.        Defaults to 4096.
	MaxManifestSizeKB *int64 `default:"4096" json:"maxManifestSizeKB"`
	// If set to Yes, each inventory file in the manifest will be validated against its checksum. Defaults to false
	ValidateInventoryFiles *bool   `default:"false" json:"validateInventoryFiles"`
	Description            *string `json:"description,omitempty"`
	AwsAPIKey              *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                        `json:"awsSecret,omitempty"`
	TagAfterProcessing *TagAfterProcessingS3Inventory `json:"tagAfterProcessing,omitempty"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitempty"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue *string `json:"processedTagValue,omitempty"`
}

func (i InputS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputS3Inventory) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputS3Inventory) GetType() TypeS3Inventory {
	if o == nil {
		return TypeS3Inventory("")
	}
	return o.Type
}

func (o *InputS3Inventory) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputS3Inventory) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputS3Inventory) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputS3Inventory) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputS3Inventory) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputS3Inventory) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputS3Inventory) GetConnections() []ConnectionS3Inventory {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputS3Inventory) GetPq() *PqS3Inventory {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputS3Inventory) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputS3Inventory) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputS3Inventory) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputS3Inventory) GetAwsAuthenticationMethod() *AuthenticationMethodS3Inventory {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputS3Inventory) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputS3Inventory) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputS3Inventory) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputS3Inventory) GetSignatureVersion() *SignatureVersionS3Inventory {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputS3Inventory) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputS3Inventory) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputS3Inventory) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputS3Inventory) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputS3Inventory) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputS3Inventory) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputS3Inventory) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputS3Inventory) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputS3Inventory) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputS3Inventory) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputS3Inventory) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputS3Inventory) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputS3Inventory) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputS3Inventory) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputS3Inventory) GetPreprocess() *PreprocessS3Inventory {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputS3Inventory) GetMetadata() []MetadatumS3Inventory {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputS3Inventory) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputS3Inventory) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputS3Inventory) GetCheckpointing() *CheckpointingS3Inventory {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputS3Inventory) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputS3Inventory) GetChecksumSuffix() *string {
	if o == nil {
		return nil
	}
	return o.ChecksumSuffix
}

func (o *InputS3Inventory) GetMaxManifestSizeKB() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxManifestSizeKB
}

func (o *InputS3Inventory) GetValidateInventoryFiles() *bool {
	if o == nil {
		return nil
	}
	return o.ValidateInventoryFiles
}

func (o *InputS3Inventory) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputS3Inventory) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputS3Inventory) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputS3Inventory) GetTagAfterProcessing() *TagAfterProcessingS3Inventory {
	if o == nil {
		return nil
	}
	return o.TagAfterProcessing
}

func (o *InputS3Inventory) GetProcessedTagKey() *string {
	if o == nil {
		return nil
	}
	return o.ProcessedTagKey
}

func (o *InputS3Inventory) GetProcessedTagValue() *string {
	if o == nil {
		return nil
	}
	return o.ProcessedTagValue
}

type CreateInputTypeS3 string

const (
	CreateInputTypeS3S3 CreateInputTypeS3 = "s3"
)

func (e CreateInputTypeS3) ToPointer() *CreateInputTypeS3 {
	return &e
}
func (e *CreateInputTypeS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3":
		*e = CreateInputTypeS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeS3: %v", v)
	}
}

type ConnectionS3 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionS3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionS3) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeS3 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeS3 string

const (
	ModeS3Smart  ModeS3 = "smart"
	ModeS3Always ModeS3 = "always"
)

func (e ModeS3) ToPointer() *ModeS3 {
	return &e
}
func (e *ModeS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeS3: %v", v)
	}
}

// PqCompressionS3 - Codec to use to compress the persisted data
type PqCompressionS3 string

const (
	PqCompressionS3None PqCompressionS3 = "none"
	PqCompressionS3Gzip PqCompressionS3 = "gzip"
)

func (e PqCompressionS3) ToPointer() *PqCompressionS3 {
	return &e
}
func (e *PqCompressionS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionS3: %v", v)
	}
}

type PqS3 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeS3 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionS3 `default:"none" json:"compress"`
}

func (p PqS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqS3) GetMode() *ModeS3 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqS3) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqS3) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqS3) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqS3) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqS3) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqS3) GetCompress() *PqCompressionS3 {
	if o == nil {
		return nil
	}
	return o.Compress
}

// CreateInputAuthenticationMethodS3 - AWS authentication method. Choose Auto to use IAM roles.
type CreateInputAuthenticationMethodS3 string

const (
	CreateInputAuthenticationMethodS3Auto   CreateInputAuthenticationMethodS3 = "auto"
	CreateInputAuthenticationMethodS3Manual CreateInputAuthenticationMethodS3 = "manual"
	CreateInputAuthenticationMethodS3Secret CreateInputAuthenticationMethodS3 = "secret"
)

func (e CreateInputAuthenticationMethodS3) ToPointer() *CreateInputAuthenticationMethodS3 {
	return &e
}
func (e *CreateInputAuthenticationMethodS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = CreateInputAuthenticationMethodS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAuthenticationMethodS3: %v", v)
	}
}

// CreateInputSignatureVersionS3 - Signature version to use for signing S3 requests
type CreateInputSignatureVersionS3 string

const (
	CreateInputSignatureVersionS3V2 CreateInputSignatureVersionS3 = "v2"
	CreateInputSignatureVersionS3V4 CreateInputSignatureVersionS3 = "v4"
)

func (e CreateInputSignatureVersionS3) ToPointer() *CreateInputSignatureVersionS3 {
	return &e
}
func (e *CreateInputSignatureVersionS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = CreateInputSignatureVersionS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputSignatureVersionS3: %v", v)
	}
}

type PreprocessS3 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessS3) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessS3) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessS3) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type MetadatumS3 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumS3) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumS3) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CheckpointingS3 struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CheckpointingS3) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CheckpointingS3) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputS3 struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     CreateInputTypeS3 `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionS3 `json:"connections,omitempty"`
	Pq          *PqS3          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *CreateInputAuthenticationMethodS3 `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                            `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *CreateInputSignatureVersionS3 `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool         `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessS3 `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumS3 `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64         `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingS3 `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding *string `json:"encoding,omitempty"`
	// Add a tag to processed S3 objects. Requires s3:GetObjectTagging and s3:PutObjectTagging AWS permissions.
	TagAfterProcessing *bool   `default:"false" json:"tagAfterProcessing"`
	Description        *string `json:"description,omitempty"`
	AwsAPIKey          *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitempty"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue *string `json:"processedTagValue,omitempty"`
}

func (i InputS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputS3) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputS3) GetType() CreateInputTypeS3 {
	if o == nil {
		return CreateInputTypeS3("")
	}
	return o.Type
}

func (o *InputS3) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputS3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputS3) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputS3) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputS3) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputS3) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputS3) GetConnections() []ConnectionS3 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputS3) GetPq() *PqS3 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputS3) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputS3) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputS3) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputS3) GetAwsAuthenticationMethod() *CreateInputAuthenticationMethodS3 {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputS3) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputS3) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputS3) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputS3) GetSignatureVersion() *CreateInputSignatureVersionS3 {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputS3) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputS3) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputS3) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputS3) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputS3) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputS3) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputS3) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputS3) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputS3) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputS3) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputS3) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputS3) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputS3) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputS3) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputS3) GetPreprocess() *PreprocessS3 {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputS3) GetMetadata() []MetadatumS3 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputS3) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputS3) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputS3) GetCheckpointing() *CheckpointingS3 {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputS3) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputS3) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputS3) GetTagAfterProcessing() *bool {
	if o == nil {
		return nil
	}
	return o.TagAfterProcessing
}

func (o *InputS3) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputS3) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputS3) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputS3) GetProcessedTagKey() *string {
	if o == nil {
		return nil
	}
	return o.ProcessedTagKey
}

func (o *InputS3) GetProcessedTagValue() *string {
	if o == nil {
		return nil
	}
	return o.ProcessedTagValue
}

type TypeMetrics string

const (
	TypeMetricsMetrics TypeMetrics = "metrics"
)

func (e TypeMetrics) ToPointer() *TypeMetrics {
	return &e
}
func (e *TypeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "metrics":
		*e = TypeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeMetrics: %v", v)
	}
}

type ConnectionMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionMetrics) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeMetrics string

const (
	ModeMetricsSmart  ModeMetrics = "smart"
	ModeMetricsAlways ModeMetrics = "always"
)

func (e ModeMetrics) ToPointer() *ModeMetrics {
	return &e
}
func (e *ModeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeMetrics: %v", v)
	}
}

// CompressionMetrics - Codec to use to compress the persisted data
type CompressionMetrics string

const (
	CompressionMetricsNone CompressionMetrics = "none"
	CompressionMetricsGzip CompressionMetrics = "gzip"
)

func (e CompressionMetrics) ToPointer() *CompressionMetrics {
	return &e
}
func (e *CompressionMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionMetrics: %v", v)
	}
}

type PqMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionMetrics `default:"none" json:"compress"`
}

func (p PqMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqMetrics) GetMode() *ModeMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqMetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqMetrics) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqMetrics) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqMetrics) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqMetrics) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqMetrics) GetCompress() *CompressionMetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionMetrics string

const (
	MinimumTLSVersionMetricsTlSv1  MinimumTLSVersionMetrics = "TLSv1"
	MinimumTLSVersionMetricsTlSv11 MinimumTLSVersionMetrics = "TLSv1.1"
	MinimumTLSVersionMetricsTlSv12 MinimumTLSVersionMetrics = "TLSv1.2"
	MinimumTLSVersionMetricsTlSv13 MinimumTLSVersionMetrics = "TLSv1.3"
)

func (e MinimumTLSVersionMetrics) ToPointer() *MinimumTLSVersionMetrics {
	return &e
}
func (e *MinimumTLSVersionMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionMetrics: %v", v)
	}
}

type MaximumTLSVersionMetrics string

const (
	MaximumTLSVersionMetricsTlSv1  MaximumTLSVersionMetrics = "TLSv1"
	MaximumTLSVersionMetricsTlSv11 MaximumTLSVersionMetrics = "TLSv1.1"
	MaximumTLSVersionMetricsTlSv12 MaximumTLSVersionMetrics = "TLSv1.2"
	MaximumTLSVersionMetricsTlSv13 MaximumTLSVersionMetrics = "TLSv1.3"
)

func (e MaximumTLSVersionMetrics) ToPointer() *MaximumTLSVersionMetrics {
	return &e
}
func (e *MaximumTLSVersionMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionMetrics: %v", v)
	}
}

type TLSSettingsServerSideMetrics struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                     `default:"false" json:"requestCert"`
	RejectUnauthorized any                       `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                       `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionMetrics `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionMetrics `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideMetrics) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideMetrics) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideMetrics) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideMetrics) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideMetrics) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideMetrics) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideMetrics) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideMetrics) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideMetrics) GetMinVersion() *MinimumTLSVersionMetrics {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideMetrics) GetMaxVersion() *MaximumTLSVersionMetrics {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumMetrics) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumMetrics) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputMetrics struct {
	// Unique ID for this input
	ID       string      `json:"id"`
	Type     TypeMetrics `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionMetrics `json:"connections,omitempty"`
	Pq          *PqMetrics          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitempty"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitempty"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool                         `default:"false" json:"enableProxyHeader"`
	TLS               *TLSSettingsServerSideMetrics `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumMetrics `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	Description        *string  `json:"description,omitempty"`
}

func (i InputMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputMetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputMetrics) GetType() TypeMetrics {
	if o == nil {
		return TypeMetrics("")
	}
	return o.Type
}

func (o *InputMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputMetrics) GetConnections() []ConnectionMetrics {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputMetrics) GetPq() *PqMetrics {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputMetrics) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputMetrics) GetUDPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPPort
}

func (o *InputMetrics) GetTCPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.TCPPort
}

func (o *InputMetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputMetrics) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputMetrics) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputMetrics) GetTLS() *TLSSettingsServerSideMetrics {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputMetrics) GetMetadata() []MetadatumMetrics {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputMetrics) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateInputTypeKinesis string

const (
	CreateInputTypeKinesisKinesis CreateInputTypeKinesis = "kinesis"
)

func (e CreateInputTypeKinesis) ToPointer() *CreateInputTypeKinesis {
	return &e
}
func (e *CreateInputTypeKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kinesis":
		*e = CreateInputTypeKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeKinesis: %v", v)
	}
}

type ConnectionKinesis struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionKinesis) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionKinesis) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeKinesis - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeKinesis string

const (
	CreateInputModeKinesisSmart  CreateInputModeKinesis = "smart"
	CreateInputModeKinesisAlways CreateInputModeKinesis = "always"
)

func (e CreateInputModeKinesis) ToPointer() *CreateInputModeKinesis {
	return &e
}
func (e *CreateInputModeKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeKinesis: %v", v)
	}
}

// PqCompressionKinesis - Codec to use to compress the persisted data
type PqCompressionKinesis string

const (
	PqCompressionKinesisNone PqCompressionKinesis = "none"
	PqCompressionKinesisGzip PqCompressionKinesis = "gzip"
)

func (e PqCompressionKinesis) ToPointer() *PqCompressionKinesis {
	return &e
}
func (e *PqCompressionKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionKinesis: %v", v)
	}
}

type PqKinesis struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeKinesis `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionKinesis `default:"none" json:"compress"`
}

func (p PqKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqKinesis) GetMode() *CreateInputModeKinesis {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqKinesis) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqKinesis) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqKinesis) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqKinesis) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqKinesis) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqKinesis) GetCompress() *PqCompressionKinesis {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ShardIteratorStart - Location at which to start reading a shard for the first time
type ShardIteratorStart string

const (
	ShardIteratorStartTrimHorizon ShardIteratorStart = "TRIM_HORIZON"
	ShardIteratorStartLatest      ShardIteratorStart = "LATEST"
)

func (e ShardIteratorStart) ToPointer() *ShardIteratorStart {
	return &e
}
func (e *ShardIteratorStart) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TRIM_HORIZON":
		fallthrough
	case "LATEST":
		*e = ShardIteratorStart(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ShardIteratorStart: %v", v)
	}
}

// CreateInputRecordDataFormat - Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
type CreateInputRecordDataFormat string

const (
	CreateInputRecordDataFormatCribl      CreateInputRecordDataFormat = "cribl"
	CreateInputRecordDataFormatNdjson     CreateInputRecordDataFormat = "ndjson"
	CreateInputRecordDataFormatCloudwatch CreateInputRecordDataFormat = "cloudwatch"
	CreateInputRecordDataFormatLine       CreateInputRecordDataFormat = "line"
)

func (e CreateInputRecordDataFormat) ToPointer() *CreateInputRecordDataFormat {
	return &e
}
func (e *CreateInputRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl":
		fallthrough
	case "ndjson":
		fallthrough
	case "cloudwatch":
		fallthrough
	case "line":
		*e = CreateInputRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputRecordDataFormat: %v", v)
	}
}

// ShardLoadBalancing - The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
type ShardLoadBalancing string

const (
	ShardLoadBalancingConsistentHashing ShardLoadBalancing = "ConsistentHashing"
	ShardLoadBalancingRoundRobin        ShardLoadBalancing = "RoundRobin"
)

func (e ShardLoadBalancing) ToPointer() *ShardLoadBalancing {
	return &e
}
func (e *ShardLoadBalancing) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ConsistentHashing":
		fallthrough
	case "RoundRobin":
		*e = ShardLoadBalancing(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ShardLoadBalancing: %v", v)
	}
}

// CreateInputAuthenticationMethodKinesis - AWS authentication method. Choose Auto to use IAM roles.
type CreateInputAuthenticationMethodKinesis string

const (
	CreateInputAuthenticationMethodKinesisAuto   CreateInputAuthenticationMethodKinesis = "auto"
	CreateInputAuthenticationMethodKinesisManual CreateInputAuthenticationMethodKinesis = "manual"
	CreateInputAuthenticationMethodKinesisSecret CreateInputAuthenticationMethodKinesis = "secret"
)

func (e CreateInputAuthenticationMethodKinesis) ToPointer() *CreateInputAuthenticationMethodKinesis {
	return &e
}
func (e *CreateInputAuthenticationMethodKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = CreateInputAuthenticationMethodKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAuthenticationMethodKinesis: %v", v)
	}
}

// CreateInputSignatureVersionKinesis - Signature version to use for signing Kinesis stream requests
type CreateInputSignatureVersionKinesis string

const (
	CreateInputSignatureVersionKinesisV2 CreateInputSignatureVersionKinesis = "v2"
	CreateInputSignatureVersionKinesisV4 CreateInputSignatureVersionKinesis = "v4"
)

func (e CreateInputSignatureVersionKinesis) ToPointer() *CreateInputSignatureVersionKinesis {
	return &e
}
func (e *CreateInputSignatureVersionKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = CreateInputSignatureVersionKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputSignatureVersionKinesis: %v", v)
	}
}

type MetadatumKinesis struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumKinesis) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumKinesis) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKinesis struct {
	// Unique ID for this input
	ID       string                  `json:"id"`
	Type     *CreateInputTypeKinesis `json:"type,omitempty"`
	Disabled *bool                   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKinesis `json:"connections,omitempty"`
	Pq          *PqKinesis          `json:"pq,omitempty"`
	// Kinesis Data Stream to read data from
	StreamName string `json:"streamName"`
	// Time interval in minutes between consecutive service calls
	ServiceInterval *float64 `default:"1" json:"serviceInterval"`
	// A JavaScript expression to be called with each shardId for the stream. If the expression evaluates to a truthy value, the shard will be processed.
	ShardExpr *string `default:"true" json:"shardExpr"`
	// Location at which to start reading a shard for the first time
	ShardIteratorType *ShardIteratorStart `default:"TRIM_HORIZON" json:"shardIteratorType"`
	// Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
	PayloadFormat *CreateInputRecordDataFormat `default:"cribl" json:"payloadFormat"`
	// Maximum number of records per getRecords call
	GetRecordsLimit *float64 `default:"5000" json:"getRecordsLimit"`
	// Maximum number of records, across all shards, to pull down at once per Worker Process
	GetRecordsLimitTotal *float64 `default:"20000" json:"getRecordsLimitTotal"`
	// The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
	LoadBalancingAlgorithm *ShardLoadBalancing `default:"ConsistentHashing" json:"loadBalancingAlgorithm"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *CreateInputAuthenticationMethodKinesis `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                 `json:"awsSecretKey,omitempty"`
	// Region where the Kinesis stream is located
	Region string `json:"region"`
	// Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Kinesis stream requests
	SignatureVersion *CreateInputSignatureVersionKinesis `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access Kinesis stream
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Verify Kinesis Producer Library (KPL) event checksums
	VerifyKPLCheckSums *bool `default:"false" json:"verifyKPLCheckSums"`
	// When resuming streaming from a stored state, Stream will read the next available record, rather than rereading the last-read record. Enabling this setting can cause data loss after a Worker Node's unexpected shutdown or restart.
	AvoidDuplicates *bool `default:"false" json:"avoidDuplicates"`
	// Fields to add to events from this input
	Metadata    []MetadatumKinesis `json:"metadata,omitempty"`
	Description *string            `json:"description,omitempty"`
	AwsAPIKey   *string            `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
}

func (i InputKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKinesis) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputKinesis) GetType() *CreateInputTypeKinesis {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputKinesis) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKinesis) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKinesis) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKinesis) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKinesis) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKinesis) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKinesis) GetConnections() []ConnectionKinesis {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKinesis) GetPq() *PqKinesis {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKinesis) GetStreamName() string {
	if o == nil {
		return ""
	}
	return o.StreamName
}

func (o *InputKinesis) GetServiceInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.ServiceInterval
}

func (o *InputKinesis) GetShardExpr() *string {
	if o == nil {
		return nil
	}
	return o.ShardExpr
}

func (o *InputKinesis) GetShardIteratorType() *ShardIteratorStart {
	if o == nil {
		return nil
	}
	return o.ShardIteratorType
}

func (o *InputKinesis) GetPayloadFormat() *CreateInputRecordDataFormat {
	if o == nil {
		return nil
	}
	return o.PayloadFormat
}

func (o *InputKinesis) GetGetRecordsLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.GetRecordsLimit
}

func (o *InputKinesis) GetGetRecordsLimitTotal() *float64 {
	if o == nil {
		return nil
	}
	return o.GetRecordsLimitTotal
}

func (o *InputKinesis) GetLoadBalancingAlgorithm() *ShardLoadBalancing {
	if o == nil {
		return nil
	}
	return o.LoadBalancingAlgorithm
}

func (o *InputKinesis) GetAwsAuthenticationMethod() *CreateInputAuthenticationMethodKinesis {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputKinesis) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputKinesis) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *InputKinesis) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputKinesis) GetSignatureVersion() *CreateInputSignatureVersionKinesis {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputKinesis) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputKinesis) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputKinesis) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputKinesis) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputKinesis) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputKinesis) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputKinesis) GetVerifyKPLCheckSums() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyKPLCheckSums
}

func (o *InputKinesis) GetAvoidDuplicates() *bool {
	if o == nil {
		return nil
	}
	return o.AvoidDuplicates
}

func (o *InputKinesis) GetMetadata() []MetadatumKinesis {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKinesis) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKinesis) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputKinesis) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

type TypeHTTPRaw string

const (
	TypeHTTPRawHTTPRaw TypeHTTPRaw = "http_raw"
)

func (e TypeHTTPRaw) ToPointer() *TypeHTTPRaw {
	return &e
}
func (e *TypeHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http_raw":
		*e = TypeHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeHTTPRaw: %v", v)
	}
}

type ConnectionHTTPRaw struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionHTTPRaw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionHTTPRaw) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeHTTPRaw - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeHTTPRaw string

const (
	ModeHTTPRawSmart  ModeHTTPRaw = "smart"
	ModeHTTPRawAlways ModeHTTPRaw = "always"
)

func (e ModeHTTPRaw) ToPointer() *ModeHTTPRaw {
	return &e
}
func (e *ModeHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeHTTPRaw: %v", v)
	}
}

// CompressionHTTPRaw - Codec to use to compress the persisted data
type CompressionHTTPRaw string

const (
	CompressionHTTPRawNone CompressionHTTPRaw = "none"
	CompressionHTTPRawGzip CompressionHTTPRaw = "gzip"
)

func (e CompressionHTTPRaw) ToPointer() *CompressionHTTPRaw {
	return &e
}
func (e *CompressionHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionHTTPRaw: %v", v)
	}
}

type PqHTTPRaw struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeHTTPRaw `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionHTTPRaw `default:"none" json:"compress"`
}

func (p PqHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqHTTPRaw) GetMode() *ModeHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqHTTPRaw) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqHTTPRaw) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqHTTPRaw) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqHTTPRaw) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqHTTPRaw) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqHTTPRaw) GetCompress() *CompressionHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionHTTPRaw string

const (
	MinimumTLSVersionHTTPRawTlSv1  MinimumTLSVersionHTTPRaw = "TLSv1"
	MinimumTLSVersionHTTPRawTlSv11 MinimumTLSVersionHTTPRaw = "TLSv1.1"
	MinimumTLSVersionHTTPRawTlSv12 MinimumTLSVersionHTTPRaw = "TLSv1.2"
	MinimumTLSVersionHTTPRawTlSv13 MinimumTLSVersionHTTPRaw = "TLSv1.3"
)

func (e MinimumTLSVersionHTTPRaw) ToPointer() *MinimumTLSVersionHTTPRaw {
	return &e
}
func (e *MinimumTLSVersionHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionHTTPRaw: %v", v)
	}
}

type MaximumTLSVersionHTTPRaw string

const (
	MaximumTLSVersionHTTPRawTlSv1  MaximumTLSVersionHTTPRaw = "TLSv1"
	MaximumTLSVersionHTTPRawTlSv11 MaximumTLSVersionHTTPRaw = "TLSv1.1"
	MaximumTLSVersionHTTPRawTlSv12 MaximumTLSVersionHTTPRaw = "TLSv1.2"
	MaximumTLSVersionHTTPRawTlSv13 MaximumTLSVersionHTTPRaw = "TLSv1.3"
)

func (e MaximumTLSVersionHTTPRaw) ToPointer() *MaximumTLSVersionHTTPRaw {
	return &e
}
func (e *MaximumTLSVersionHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionHTTPRaw: %v", v)
	}
}

type TLSSettingsServerSideHTTPRaw struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                     `default:"false" json:"requestCert"`
	RejectUnauthorized any                       `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                       `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionHTTPRaw `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionHTTPRaw `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideHTTPRaw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideHTTPRaw) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideHTTPRaw) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideHTTPRaw) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideHTTPRaw) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideHTTPRaw) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideHTTPRaw) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideHTTPRaw) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideHTTPRaw) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideHTTPRaw) GetMinVersion() *MinimumTLSVersionHTTPRaw {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideHTTPRaw) GetMaxVersion() *MaximumTLSVersionHTTPRaw {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumHTTPRaw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumHTTPRaw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumHTTPRaw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExtMetadatumHTTPRaw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *AuthTokensExtMetadatumHTTPRaw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *AuthTokensExtMetadatumHTTPRaw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExtHTTPRaw struct {
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokensExtMetadatumHTTPRaw `json:"metadata,omitempty"`
}

func (o *AuthTokensExtHTTPRaw) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *AuthTokensExtHTTPRaw) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokensExtHTTPRaw) GetMetadata() []AuthTokensExtMetadatumHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type InputHTTPRaw struct {
	// Unique ID for this input
	ID       string       `json:"id"`
	Type     *TypeHTTPRaw `json:"type,omitempty"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionHTTPRaw `json:"connections,omitempty"`
	Pq          *PqHTTPRaw          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                      `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideHTTPRaw `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata []MetadatumHTTPRaw `json:"metadata,omitempty"`
	// List of URI paths accepted by this input, wildcards are supported, e.g /api/v*/hook. Defaults to allow all.
	AllowedPaths []string `json:"allowedPaths,omitempty"`
	// List of HTTP methods accepted by this input. Wildcards are supported (such as P*, GET). Defaults to allow all.
	AllowedMethods []string `json:"allowedMethods,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []AuthTokensExtHTTPRaw `json:"authTokensExt,omitempty"`
	Description   *string                `json:"description,omitempty"`
}

func (i InputHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTPRaw) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputHTTPRaw) GetType() *TypeHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputHTTPRaw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputHTTPRaw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputHTTPRaw) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputHTTPRaw) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputHTTPRaw) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputHTTPRaw) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputHTTPRaw) GetConnections() []ConnectionHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputHTTPRaw) GetPq() *PqHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputHTTPRaw) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputHTTPRaw) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputHTTPRaw) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputHTTPRaw) GetTLS() *TLSSettingsServerSideHTTPRaw {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputHTTPRaw) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputHTTPRaw) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputHTTPRaw) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputHTTPRaw) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputHTTPRaw) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputHTTPRaw) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputHTTPRaw) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputHTTPRaw) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputHTTPRaw) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputHTTPRaw) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputHTTPRaw) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputHTTPRaw) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputHTTPRaw) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputHTTPRaw) GetMetadata() []MetadatumHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputHTTPRaw) GetAllowedPaths() []string {
	if o == nil {
		return nil
	}
	return o.AllowedPaths
}

func (o *InputHTTPRaw) GetAllowedMethods() []string {
	if o == nil {
		return nil
	}
	return o.AllowedMethods
}

func (o *InputHTTPRaw) GetAuthTokensExt() []AuthTokensExtHTTPRaw {
	if o == nil {
		return nil
	}
	return o.AuthTokensExt
}

func (o *InputHTTPRaw) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeDatagen string

const (
	TypeDatagenDatagen TypeDatagen = "datagen"
)

func (e TypeDatagen) ToPointer() *TypeDatagen {
	return &e
}
func (e *TypeDatagen) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datagen":
		*e = TypeDatagen(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatagen: %v", v)
	}
}

type ConnectionDatagen struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionDatagen) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionDatagen) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeDatagen - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeDatagen string

const (
	ModeDatagenSmart  ModeDatagen = "smart"
	ModeDatagenAlways ModeDatagen = "always"
)

func (e ModeDatagen) ToPointer() *ModeDatagen {
	return &e
}
func (e *ModeDatagen) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeDatagen(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeDatagen: %v", v)
	}
}

// CompressionDatagen - Codec to use to compress the persisted data
type CompressionDatagen string

const (
	CompressionDatagenNone CompressionDatagen = "none"
	CompressionDatagenGzip CompressionDatagen = "gzip"
)

func (e CompressionDatagen) ToPointer() *CompressionDatagen {
	return &e
}
func (e *CompressionDatagen) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionDatagen(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionDatagen: %v", v)
	}
}

type PqDatagen struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeDatagen `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionDatagen `default:"none" json:"compress"`
}

func (p PqDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqDatagen) GetMode() *ModeDatagen {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqDatagen) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqDatagen) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqDatagen) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqDatagen) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqDatagen) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqDatagen) GetCompress() *CompressionDatagen {
	if o == nil {
		return nil
	}
	return o.Compress
}

type Sample struct {
	Sample string `json:"sample"`
	// Maximum number of events to generate per second per Worker Node. Defaults to 10.
	EventsPerSec *float64 `default:"10" json:"eventsPerSec"`
}

func (s Sample) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Sample) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Sample) GetSample() string {
	if o == nil {
		return ""
	}
	return o.Sample
}

func (o *Sample) GetEventsPerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EventsPerSec
}

type MetadatumDatagen struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumDatagen) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumDatagen) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputDatagen struct {
	// Unique ID for this input
	ID       string      `json:"id"`
	Type     TypeDatagen `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionDatagen `json:"connections,omitempty"`
	Pq          *PqDatagen          `json:"pq,omitempty"`
	Samples     []Sample            `json:"samples"`
	// Fields to add to events from this input
	Metadata    []MetadatumDatagen `json:"metadata,omitempty"`
	Description *string            `json:"description,omitempty"`
}

func (i InputDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputDatagen) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputDatagen) GetType() TypeDatagen {
	if o == nil {
		return TypeDatagen("")
	}
	return o.Type
}

func (o *InputDatagen) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputDatagen) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputDatagen) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputDatagen) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputDatagen) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputDatagen) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputDatagen) GetConnections() []ConnectionDatagen {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputDatagen) GetPq() *PqDatagen {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputDatagen) GetSamples() []Sample {
	if o == nil {
		return []Sample{}
	}
	return o.Samples
}

func (o *InputDatagen) GetMetadata() []MetadatumDatagen {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputDatagen) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeDatadogAgent string

const (
	TypeDatadogAgentDatadogAgent TypeDatadogAgent = "datadog_agent"
)

func (e TypeDatadogAgent) ToPointer() *TypeDatadogAgent {
	return &e
}
func (e *TypeDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datadog_agent":
		*e = TypeDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatadogAgent: %v", v)
	}
}

type ConnectionDatadogAgent struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionDatadogAgent) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionDatadogAgent) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeDatadogAgent - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeDatadogAgent string

const (
	ModeDatadogAgentSmart  ModeDatadogAgent = "smart"
	ModeDatadogAgentAlways ModeDatadogAgent = "always"
)

func (e ModeDatadogAgent) ToPointer() *ModeDatadogAgent {
	return &e
}
func (e *ModeDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeDatadogAgent: %v", v)
	}
}

// CompressionDatadogAgent - Codec to use to compress the persisted data
type CompressionDatadogAgent string

const (
	CompressionDatadogAgentNone CompressionDatadogAgent = "none"
	CompressionDatadogAgentGzip CompressionDatadogAgent = "gzip"
)

func (e CompressionDatadogAgent) ToPointer() *CompressionDatadogAgent {
	return &e
}
func (e *CompressionDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionDatadogAgent: %v", v)
	}
}

type PqDatadogAgent struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeDatadogAgent `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionDatadogAgent `default:"none" json:"compress"`
}

func (p PqDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqDatadogAgent) GetMode() *ModeDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqDatadogAgent) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqDatadogAgent) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqDatadogAgent) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqDatadogAgent) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqDatadogAgent) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqDatadogAgent) GetCompress() *CompressionDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionDatadogAgent string

const (
	MinimumTLSVersionDatadogAgentTlSv1  MinimumTLSVersionDatadogAgent = "TLSv1"
	MinimumTLSVersionDatadogAgentTlSv11 MinimumTLSVersionDatadogAgent = "TLSv1.1"
	MinimumTLSVersionDatadogAgentTlSv12 MinimumTLSVersionDatadogAgent = "TLSv1.2"
	MinimumTLSVersionDatadogAgentTlSv13 MinimumTLSVersionDatadogAgent = "TLSv1.3"
)

func (e MinimumTLSVersionDatadogAgent) ToPointer() *MinimumTLSVersionDatadogAgent {
	return &e
}
func (e *MinimumTLSVersionDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionDatadogAgent: %v", v)
	}
}

type MaximumTLSVersionDatadogAgent string

const (
	MaximumTLSVersionDatadogAgentTlSv1  MaximumTLSVersionDatadogAgent = "TLSv1"
	MaximumTLSVersionDatadogAgentTlSv11 MaximumTLSVersionDatadogAgent = "TLSv1.1"
	MaximumTLSVersionDatadogAgentTlSv12 MaximumTLSVersionDatadogAgent = "TLSv1.2"
	MaximumTLSVersionDatadogAgentTlSv13 MaximumTLSVersionDatadogAgent = "TLSv1.3"
)

func (e MaximumTLSVersionDatadogAgent) ToPointer() *MaximumTLSVersionDatadogAgent {
	return &e
}
func (e *MaximumTLSVersionDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionDatadogAgent: %v", v)
	}
}

type TLSSettingsServerSideDatadogAgent struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                          `default:"false" json:"requestCert"`
	RejectUnauthorized any                            `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                            `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionDatadogAgent `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionDatadogAgent `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideDatadogAgent) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideDatadogAgent) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideDatadogAgent) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideDatadogAgent) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideDatadogAgent) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideDatadogAgent) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideDatadogAgent) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideDatadogAgent) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideDatadogAgent) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideDatadogAgent) GetMinVersion() *MinimumTLSVersionDatadogAgent {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideDatadogAgent) GetMaxVersion() *MaximumTLSVersionDatadogAgent {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumDatadogAgent struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumDatadogAgent) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumDatadogAgent) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type ProxyModeDatadogAgent struct {
	// Toggle to Yes to send key validation requests from Datadog Agent to the Datadog API. If toggled to No (the default), Stream handles key validation requests by always responding that the key is valid.
	Enabled *bool `default:"false" json:"enabled"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (p ProxyModeDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyModeDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ProxyModeDatadogAgent) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *ProxyModeDatadogAgent) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

type InputDatadogAgent struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     *TypeDatadogAgent `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionDatadogAgent `json:"connections,omitempty"`
	Pq          *PqDatadogAgent          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *TLSSettingsServerSideDatadogAgent `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Toggle to Yes to extract each incoming metric to multiple events, one per data point. This works well when sending metrics to a statsd-type output. If sending metrics to DatadogHQ or any destination that accepts arbitrary JSON, leave toggled to No (the default).
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Fields to add to events from this input
	Metadata    []MetadatumDatadogAgent `json:"metadata,omitempty"`
	ProxyMode   *ProxyModeDatadogAgent  `json:"proxyMode,omitempty"`
	Description *string                 `json:"description,omitempty"`
}

func (i InputDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputDatadogAgent) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputDatadogAgent) GetType() *TypeDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputDatadogAgent) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputDatadogAgent) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputDatadogAgent) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputDatadogAgent) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputDatadogAgent) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputDatadogAgent) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputDatadogAgent) GetConnections() []ConnectionDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputDatadogAgent) GetPq() *PqDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputDatadogAgent) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputDatadogAgent) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputDatadogAgent) GetTLS() *TLSSettingsServerSideDatadogAgent {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputDatadogAgent) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputDatadogAgent) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputDatadogAgent) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputDatadogAgent) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputDatadogAgent) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputDatadogAgent) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputDatadogAgent) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputDatadogAgent) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputDatadogAgent) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputDatadogAgent) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputDatadogAgent) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputDatadogAgent) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputDatadogAgent) GetMetadata() []MetadatumDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputDatadogAgent) GetProxyMode() *ProxyModeDatadogAgent {
	if o == nil {
		return nil
	}
	return o.ProxyMode
}

func (o *InputDatadogAgent) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeCrowdstrike string

const (
	TypeCrowdstrikeCrowdstrike TypeCrowdstrike = "crowdstrike"
)

func (e TypeCrowdstrike) ToPointer() *TypeCrowdstrike {
	return &e
}
func (e *TypeCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "crowdstrike":
		*e = TypeCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCrowdstrike: %v", v)
	}
}

type ConnectionCrowdstrike struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCrowdstrike) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCrowdstrike) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeCrowdstrike - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCrowdstrike string

const (
	ModeCrowdstrikeSmart  ModeCrowdstrike = "smart"
	ModeCrowdstrikeAlways ModeCrowdstrike = "always"
)

func (e ModeCrowdstrike) ToPointer() *ModeCrowdstrike {
	return &e
}
func (e *ModeCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeCrowdstrike: %v", v)
	}
}

// CompressionCrowdstrike - Codec to use to compress the persisted data
type CompressionCrowdstrike string

const (
	CompressionCrowdstrikeNone CompressionCrowdstrike = "none"
	CompressionCrowdstrikeGzip CompressionCrowdstrike = "gzip"
)

func (e CompressionCrowdstrike) ToPointer() *CompressionCrowdstrike {
	return &e
}
func (e *CompressionCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCrowdstrike: %v", v)
	}
}

type PqCrowdstrike struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCrowdstrike `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionCrowdstrike `default:"none" json:"compress"`
}

func (p PqCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCrowdstrike) GetMode() *ModeCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCrowdstrike) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCrowdstrike) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCrowdstrike) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCrowdstrike) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCrowdstrike) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCrowdstrike) GetCompress() *CompressionCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodCrowdstrike - AWS authentication method. Choose Auto to use IAM roles.
type AuthenticationMethodCrowdstrike string

const (
	AuthenticationMethodCrowdstrikeAuto   AuthenticationMethodCrowdstrike = "auto"
	AuthenticationMethodCrowdstrikeManual AuthenticationMethodCrowdstrike = "manual"
	AuthenticationMethodCrowdstrikeSecret AuthenticationMethodCrowdstrike = "secret"
)

func (e AuthenticationMethodCrowdstrike) ToPointer() *AuthenticationMethodCrowdstrike {
	return &e
}
func (e *AuthenticationMethodCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodCrowdstrike: %v", v)
	}
}

// SignatureVersionCrowdstrike - Signature version to use for signing S3 requests
type SignatureVersionCrowdstrike string

const (
	SignatureVersionCrowdstrikeV2 SignatureVersionCrowdstrike = "v2"
	SignatureVersionCrowdstrikeV4 SignatureVersionCrowdstrike = "v4"
)

func (e SignatureVersionCrowdstrike) ToPointer() *SignatureVersionCrowdstrike {
	return &e
}
func (e *SignatureVersionCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersionCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersionCrowdstrike: %v", v)
	}
}

type PreprocessCrowdstrike struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessCrowdstrike) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessCrowdstrike) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessCrowdstrike) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type MetadatumCrowdstrike struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCrowdstrike) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCrowdstrike) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CheckpointingCrowdstrike struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CheckpointingCrowdstrike) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CheckpointingCrowdstrike) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type TagAfterProcessingCrowdstrike string

const (
	TagAfterProcessingCrowdstrikeFalse TagAfterProcessingCrowdstrike = "false"
	TagAfterProcessingCrowdstrikeTrue  TagAfterProcessingCrowdstrike = "true"
)

func (e TagAfterProcessingCrowdstrike) ToPointer() *TagAfterProcessingCrowdstrike {
	return &e
}
func (e *TagAfterProcessingCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "false":
		fallthrough
	case "true":
		*e = TagAfterProcessingCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TagAfterProcessingCrowdstrike: %v", v)
	}
}

type InputCrowdstrike struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     TypeCrowdstrike `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCrowdstrike `json:"connections,omitempty"`
	Pq          *PqCrowdstrike          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethodCrowdstrike `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                          `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *SignatureVersionCrowdstrike `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"21600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access Amazon S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing Amazon SQS
	EnableSQSAssumeRole *bool                  `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessCrowdstrike `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata      []MetadatumCrowdstrike    `json:"metadata,omitempty"`
	Checkpointing *CheckpointingCrowdstrike `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret          *string                        `json:"awsSecret,omitempty"`
	TagAfterProcessing *TagAfterProcessingCrowdstrike `json:"tagAfterProcessing,omitempty"`
	// The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagKey *string `json:"processedTagKey,omitempty"`
	// The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
	ProcessedTagValue *string `json:"processedTagValue,omitempty"`
}

func (i InputCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCrowdstrike) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCrowdstrike) GetType() TypeCrowdstrike {
	if o == nil {
		return TypeCrowdstrike("")
	}
	return o.Type
}

func (o *InputCrowdstrike) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCrowdstrike) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCrowdstrike) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCrowdstrike) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCrowdstrike) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCrowdstrike) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCrowdstrike) GetConnections() []ConnectionCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCrowdstrike) GetPq() *PqCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCrowdstrike) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputCrowdstrike) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputCrowdstrike) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputCrowdstrike) GetAwsAuthenticationMethod() *AuthenticationMethodCrowdstrike {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputCrowdstrike) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputCrowdstrike) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputCrowdstrike) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputCrowdstrike) GetSignatureVersion() *SignatureVersionCrowdstrike {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputCrowdstrike) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputCrowdstrike) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputCrowdstrike) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputCrowdstrike) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputCrowdstrike) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputCrowdstrike) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputCrowdstrike) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputCrowdstrike) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputCrowdstrike) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputCrowdstrike) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputCrowdstrike) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputCrowdstrike) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputCrowdstrike) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputCrowdstrike) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputCrowdstrike) GetPreprocess() *PreprocessCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputCrowdstrike) GetMetadata() []MetadatumCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCrowdstrike) GetCheckpointing() *CheckpointingCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputCrowdstrike) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputCrowdstrike) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputCrowdstrike) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCrowdstrike) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputCrowdstrike) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputCrowdstrike) GetTagAfterProcessing() *TagAfterProcessingCrowdstrike {
	if o == nil {
		return nil
	}
	return o.TagAfterProcessing
}

func (o *InputCrowdstrike) GetProcessedTagKey() *string {
	if o == nil {
		return nil
	}
	return o.ProcessedTagKey
}

func (o *InputCrowdstrike) GetProcessedTagValue() *string {
	if o == nil {
		return nil
	}
	return o.ProcessedTagValue
}

type TypeTcpjson string

const (
	TypeTcpjsonTcpjson TypeTcpjson = "tcpjson"
)

func (e TypeTcpjson) ToPointer() *TypeTcpjson {
	return &e
}
func (e *TypeTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcpjson":
		*e = TypeTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeTcpjson: %v", v)
	}
}

type ConnectionTcpjson struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionTcpjson) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionTcpjson) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeTcpjson - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeTcpjson string

const (
	ModeTcpjsonSmart  ModeTcpjson = "smart"
	ModeTcpjsonAlways ModeTcpjson = "always"
)

func (e ModeTcpjson) ToPointer() *ModeTcpjson {
	return &e
}
func (e *ModeTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeTcpjson: %v", v)
	}
}

// CompressionTcpjson - Codec to use to compress the persisted data
type CompressionTcpjson string

const (
	CompressionTcpjsonNone CompressionTcpjson = "none"
	CompressionTcpjsonGzip CompressionTcpjson = "gzip"
)

func (e CompressionTcpjson) ToPointer() *CompressionTcpjson {
	return &e
}
func (e *CompressionTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionTcpjson: %v", v)
	}
}

type PqTcpjson struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeTcpjson `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionTcpjson `default:"none" json:"compress"`
}

func (p PqTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqTcpjson) GetMode() *ModeTcpjson {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqTcpjson) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqTcpjson) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqTcpjson) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqTcpjson) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqTcpjson) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqTcpjson) GetCompress() *CompressionTcpjson {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionTcpjson string

const (
	MinimumTLSVersionTcpjsonTlSv1  MinimumTLSVersionTcpjson = "TLSv1"
	MinimumTLSVersionTcpjsonTlSv11 MinimumTLSVersionTcpjson = "TLSv1.1"
	MinimumTLSVersionTcpjsonTlSv12 MinimumTLSVersionTcpjson = "TLSv1.2"
	MinimumTLSVersionTcpjsonTlSv13 MinimumTLSVersionTcpjson = "TLSv1.3"
)

func (e MinimumTLSVersionTcpjson) ToPointer() *MinimumTLSVersionTcpjson {
	return &e
}
func (e *MinimumTLSVersionTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionTcpjson: %v", v)
	}
}

type MaximumTLSVersionTcpjson string

const (
	MaximumTLSVersionTcpjsonTlSv1  MaximumTLSVersionTcpjson = "TLSv1"
	MaximumTLSVersionTcpjsonTlSv11 MaximumTLSVersionTcpjson = "TLSv1.1"
	MaximumTLSVersionTcpjsonTlSv12 MaximumTLSVersionTcpjson = "TLSv1.2"
	MaximumTLSVersionTcpjsonTlSv13 MaximumTLSVersionTcpjson = "TLSv1.3"
)

func (e MaximumTLSVersionTcpjson) ToPointer() *MaximumTLSVersionTcpjson {
	return &e
}
func (e *MaximumTLSVersionTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionTcpjson: %v", v)
	}
}

type TLSSettingsServerSideTcpjson struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                     `default:"false" json:"requestCert"`
	RejectUnauthorized any                       `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                       `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionTcpjson `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionTcpjson `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideTcpjson) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideTcpjson) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideTcpjson) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideTcpjson) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideTcpjson) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideTcpjson) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideTcpjson) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideTcpjson) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideTcpjson) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideTcpjson) GetMinVersion() *MinimumTLSVersionTcpjson {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideTcpjson) GetMaxVersion() *MaximumTLSVersionTcpjson {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumTcpjson struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumTcpjson) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumTcpjson) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// AuthenticationMethodTcpjson - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodTcpjson string

const (
	AuthenticationMethodTcpjsonManual AuthenticationMethodTcpjson = "manual"
	AuthenticationMethodTcpjsonSecret AuthenticationMethodTcpjson = "secret"
)

func (e AuthenticationMethodTcpjson) ToPointer() *AuthenticationMethodTcpjson {
	return &e
}
func (e *AuthenticationMethodTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodTcpjson: %v", v)
	}
}

type InputTcpjson struct {
	// Unique ID for this input
	ID       string       `json:"id"`
	Type     *TypeTcpjson `json:"type,omitempty"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionTcpjson `json:"connections,omitempty"`
	Pq          *PqTcpjson          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                       `json:"port"`
	TLS  *TLSSettingsServerSideTcpjson `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumTcpjson `json:"metadata,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool `default:"false" json:"enableLoadBalancing"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthenticationMethodTcpjson `default:"manual" json:"authType"`
	Description *string                      `json:"description,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (i InputTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputTcpjson) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputTcpjson) GetType() *TypeTcpjson {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputTcpjson) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTcpjson) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputTcpjson) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputTcpjson) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputTcpjson) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputTcpjson) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputTcpjson) GetConnections() []ConnectionTcpjson {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputTcpjson) GetPq() *PqTcpjson {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputTcpjson) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputTcpjson) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputTcpjson) GetTLS() *TLSSettingsServerSideTcpjson {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputTcpjson) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputTcpjson) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputTcpjson) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputTcpjson) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputTcpjson) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputTcpjson) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputTcpjson) GetMetadata() []MetadatumTcpjson {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputTcpjson) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputTcpjson) GetAuthType() *AuthenticationMethodTcpjson {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputTcpjson) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputTcpjson) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *InputTcpjson) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

type TypeCriblLakeHTTP string

const (
	TypeCriblLakeHTTPCriblLakeHTTP TypeCriblLakeHTTP = "cribl_lake_http"
)

func (e TypeCriblLakeHTTP) ToPointer() *TypeCriblLakeHTTP {
	return &e
}
func (e *TypeCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_lake_http":
		*e = TypeCriblLakeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblLakeHTTP: %v", v)
	}
}

type ConnectionCriblLakeHTTP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCriblLakeHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCriblLakeHTTP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeCriblLakeHTTP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCriblLakeHTTP string

const (
	ModeCriblLakeHTTPSmart  ModeCriblLakeHTTP = "smart"
	ModeCriblLakeHTTPAlways ModeCriblLakeHTTP = "always"
)

func (e ModeCriblLakeHTTP) ToPointer() *ModeCriblLakeHTTP {
	return &e
}
func (e *ModeCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeCriblLakeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeCriblLakeHTTP: %v", v)
	}
}

// CompressionCriblLakeHTTP - Codec to use to compress the persisted data
type CompressionCriblLakeHTTP string

const (
	CompressionCriblLakeHTTPNone CompressionCriblLakeHTTP = "none"
	CompressionCriblLakeHTTPGzip CompressionCriblLakeHTTP = "gzip"
)

func (e CompressionCriblLakeHTTP) ToPointer() *CompressionCriblLakeHTTP {
	return &e
}
func (e *CompressionCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionCriblLakeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCriblLakeHTTP: %v", v)
	}
}

type PqCriblLakeHTTP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCriblLakeHTTP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionCriblLakeHTTP `default:"none" json:"compress"`
}

func (p PqCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCriblLakeHTTP) GetMode() *ModeCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCriblLakeHTTP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCriblLakeHTTP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCriblLakeHTTP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCriblLakeHTTP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCriblLakeHTTP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCriblLakeHTTP) GetCompress() *CompressionCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionCriblLakeHTTP string

const (
	MinimumTLSVersionCriblLakeHTTPTlSv1  MinimumTLSVersionCriblLakeHTTP = "TLSv1"
	MinimumTLSVersionCriblLakeHTTPTlSv11 MinimumTLSVersionCriblLakeHTTP = "TLSv1.1"
	MinimumTLSVersionCriblLakeHTTPTlSv12 MinimumTLSVersionCriblLakeHTTP = "TLSv1.2"
	MinimumTLSVersionCriblLakeHTTPTlSv13 MinimumTLSVersionCriblLakeHTTP = "TLSv1.3"
)

func (e MinimumTLSVersionCriblLakeHTTP) ToPointer() *MinimumTLSVersionCriblLakeHTTP {
	return &e
}
func (e *MinimumTLSVersionCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionCriblLakeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionCriblLakeHTTP: %v", v)
	}
}

type MaximumTLSVersionCriblLakeHTTP string

const (
	MaximumTLSVersionCriblLakeHTTPTlSv1  MaximumTLSVersionCriblLakeHTTP = "TLSv1"
	MaximumTLSVersionCriblLakeHTTPTlSv11 MaximumTLSVersionCriblLakeHTTP = "TLSv1.1"
	MaximumTLSVersionCriblLakeHTTPTlSv12 MaximumTLSVersionCriblLakeHTTP = "TLSv1.2"
	MaximumTLSVersionCriblLakeHTTPTlSv13 MaximumTLSVersionCriblLakeHTTP = "TLSv1.3"
)

func (e MaximumTLSVersionCriblLakeHTTP) ToPointer() *MaximumTLSVersionCriblLakeHTTP {
	return &e
}
func (e *MaximumTLSVersionCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionCriblLakeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionCriblLakeHTTP: %v", v)
	}
}

type TLSSettingsServerSideCriblLakeHTTP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                           `default:"false" json:"requestCert"`
	RejectUnauthorized any                             `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                             `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionCriblLakeHTTP `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionCriblLakeHTTP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetMinVersion() *MinimumTLSVersionCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideCriblLakeHTTP) GetMaxVersion() *MaximumTLSVersionCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumCriblLakeHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCriblLakeHTTP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCriblLakeHTTP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblLakeHTTP struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     *TypeCriblLakeHTTP `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblLakeHTTP `json:"connections,omitempty"`
	Pq          *PqCriblLakeHTTP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideCriblLakeHTTP `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata    []MetadatumCriblLakeHTTP `json:"metadata,omitempty"`
	Description *string                  `json:"description,omitempty"`
}

func (i InputCriblLakeHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblLakeHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblLakeHTTP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCriblLakeHTTP) GetType() *TypeCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCriblLakeHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblLakeHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblLakeHTTP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblLakeHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblLakeHTTP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblLakeHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblLakeHTTP) GetConnections() []ConnectionCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblLakeHTTP) GetPq() *PqCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblLakeHTTP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputCriblLakeHTTP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputCriblLakeHTTP) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputCriblLakeHTTP) GetTLS() *TLSSettingsServerSideCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputCriblLakeHTTP) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputCriblLakeHTTP) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputCriblLakeHTTP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputCriblLakeHTTP) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputCriblLakeHTTP) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputCriblLakeHTTP) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputCriblLakeHTTP) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputCriblLakeHTTP) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputCriblLakeHTTP) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputCriblLakeHTTP) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputCriblLakeHTTP) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputCriblLakeHTTP) GetMetadata() []MetadatumCriblLakeHTTP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblLakeHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeCriblHTTP string

const (
	TypeCriblHTTPCriblHTTP TypeCriblHTTP = "cribl_http"
)

func (e TypeCriblHTTP) ToPointer() *TypeCriblHTTP {
	return &e
}
func (e *TypeCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_http":
		*e = TypeCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblHTTP: %v", v)
	}
}

type ConnectionCriblHTTP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCriblHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCriblHTTP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeCriblHTTP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCriblHTTP string

const (
	ModeCriblHTTPSmart  ModeCriblHTTP = "smart"
	ModeCriblHTTPAlways ModeCriblHTTP = "always"
)

func (e ModeCriblHTTP) ToPointer() *ModeCriblHTTP {
	return &e
}
func (e *ModeCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeCriblHTTP: %v", v)
	}
}

// CompressionCriblHTTP - Codec to use to compress the persisted data
type CompressionCriblHTTP string

const (
	CompressionCriblHTTPNone CompressionCriblHTTP = "none"
	CompressionCriblHTTPGzip CompressionCriblHTTP = "gzip"
)

func (e CompressionCriblHTTP) ToPointer() *CompressionCriblHTTP {
	return &e
}
func (e *CompressionCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCriblHTTP: %v", v)
	}
}

type PqCriblHTTP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCriblHTTP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionCriblHTTP `default:"none" json:"compress"`
}

func (p PqCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCriblHTTP) GetMode() *ModeCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCriblHTTP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCriblHTTP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCriblHTTP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCriblHTTP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCriblHTTP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCriblHTTP) GetCompress() *CompressionCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionCriblHTTP string

const (
	MinimumTLSVersionCriblHTTPTlSv1  MinimumTLSVersionCriblHTTP = "TLSv1"
	MinimumTLSVersionCriblHTTPTlSv11 MinimumTLSVersionCriblHTTP = "TLSv1.1"
	MinimumTLSVersionCriblHTTPTlSv12 MinimumTLSVersionCriblHTTP = "TLSv1.2"
	MinimumTLSVersionCriblHTTPTlSv13 MinimumTLSVersionCriblHTTP = "TLSv1.3"
)

func (e MinimumTLSVersionCriblHTTP) ToPointer() *MinimumTLSVersionCriblHTTP {
	return &e
}
func (e *MinimumTLSVersionCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionCriblHTTP: %v", v)
	}
}

type MaximumTLSVersionCriblHTTP string

const (
	MaximumTLSVersionCriblHTTPTlSv1  MaximumTLSVersionCriblHTTP = "TLSv1"
	MaximumTLSVersionCriblHTTPTlSv11 MaximumTLSVersionCriblHTTP = "TLSv1.1"
	MaximumTLSVersionCriblHTTPTlSv12 MaximumTLSVersionCriblHTTP = "TLSv1.2"
	MaximumTLSVersionCriblHTTPTlSv13 MaximumTLSVersionCriblHTTP = "TLSv1.3"
)

func (e MaximumTLSVersionCriblHTTP) ToPointer() *MaximumTLSVersionCriblHTTP {
	return &e
}
func (e *MaximumTLSVersionCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionCriblHTTP: %v", v)
	}
}

type TLSSettingsServerSideCriblHTTP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                       `default:"false" json:"requestCert"`
	RejectUnauthorized any                         `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                         `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionCriblHTTP `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionCriblHTTP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideCriblHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideCriblHTTP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideCriblHTTP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideCriblHTTP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideCriblHTTP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideCriblHTTP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideCriblHTTP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideCriblHTTP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideCriblHTTP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideCriblHTTP) GetMinVersion() *MinimumTLSVersionCriblHTTP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideCriblHTTP) GetMaxVersion() *MaximumTLSVersionCriblHTTP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumCriblHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCriblHTTP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCriblHTTP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblHTTP struct {
	// Unique ID for this input
	ID       string         `json:"id"`
	Type     *TypeCriblHTTP `json:"type,omitempty"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblHTTP `json:"connections,omitempty"`
	Pq          *PqCriblHTTP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                        `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideCriblHTTP `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata    []MetadatumCriblHTTP `json:"metadata,omitempty"`
	Description *string              `json:"description,omitempty"`
}

func (i InputCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblHTTP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCriblHTTP) GetType() *TypeCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCriblHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblHTTP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblHTTP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblHTTP) GetConnections() []ConnectionCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblHTTP) GetPq() *PqCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblHTTP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputCriblHTTP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputCriblHTTP) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputCriblHTTP) GetTLS() *TLSSettingsServerSideCriblHTTP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputCriblHTTP) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputCriblHTTP) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputCriblHTTP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputCriblHTTP) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputCriblHTTP) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputCriblHTTP) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputCriblHTTP) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputCriblHTTP) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputCriblHTTP) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputCriblHTTP) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputCriblHTTP) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputCriblHTTP) GetMetadata() []MetadatumCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeCriblTCP string

const (
	TypeCriblTCPCriblTCP TypeCriblTCP = "cribl_tcp"
)

func (e TypeCriblTCP) ToPointer() *TypeCriblTCP {
	return &e
}
func (e *TypeCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_tcp":
		*e = TypeCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblTCP: %v", v)
	}
}

type ConnectionCriblTCP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCriblTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCriblTCP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeCriblTCP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCriblTCP string

const (
	ModeCriblTCPSmart  ModeCriblTCP = "smart"
	ModeCriblTCPAlways ModeCriblTCP = "always"
)

func (e ModeCriblTCP) ToPointer() *ModeCriblTCP {
	return &e
}
func (e *ModeCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeCriblTCP: %v", v)
	}
}

// CompressionCriblTCP - Codec to use to compress the persisted data
type CompressionCriblTCP string

const (
	CompressionCriblTCPNone CompressionCriblTCP = "none"
	CompressionCriblTCPGzip CompressionCriblTCP = "gzip"
)

func (e CompressionCriblTCP) ToPointer() *CompressionCriblTCP {
	return &e
}
func (e *CompressionCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCriblTCP: %v", v)
	}
}

type PqCriblTCP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCriblTCP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionCriblTCP `default:"none" json:"compress"`
}

func (p PqCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCriblTCP) GetMode() *ModeCriblTCP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCriblTCP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCriblTCP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCriblTCP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCriblTCP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCriblTCP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCriblTCP) GetCompress() *CompressionCriblTCP {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionCriblTCP string

const (
	MinimumTLSVersionCriblTCPTlSv1  MinimumTLSVersionCriblTCP = "TLSv1"
	MinimumTLSVersionCriblTCPTlSv11 MinimumTLSVersionCriblTCP = "TLSv1.1"
	MinimumTLSVersionCriblTCPTlSv12 MinimumTLSVersionCriblTCP = "TLSv1.2"
	MinimumTLSVersionCriblTCPTlSv13 MinimumTLSVersionCriblTCP = "TLSv1.3"
)

func (e MinimumTLSVersionCriblTCP) ToPointer() *MinimumTLSVersionCriblTCP {
	return &e
}
func (e *MinimumTLSVersionCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionCriblTCP: %v", v)
	}
}

type MaximumTLSVersionCriblTCP string

const (
	MaximumTLSVersionCriblTCPTlSv1  MaximumTLSVersionCriblTCP = "TLSv1"
	MaximumTLSVersionCriblTCPTlSv11 MaximumTLSVersionCriblTCP = "TLSv1.1"
	MaximumTLSVersionCriblTCPTlSv12 MaximumTLSVersionCriblTCP = "TLSv1.2"
	MaximumTLSVersionCriblTCPTlSv13 MaximumTLSVersionCriblTCP = "TLSv1.3"
)

func (e MaximumTLSVersionCriblTCP) ToPointer() *MaximumTLSVersionCriblTCP {
	return &e
}
func (e *MaximumTLSVersionCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionCriblTCP: %v", v)
	}
}

type TLSSettingsServerSideCriblTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                      `default:"false" json:"requestCert"`
	RejectUnauthorized any                        `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                        `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionCriblTCP `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionCriblTCP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideCriblTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideCriblTCP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideCriblTCP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideCriblTCP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideCriblTCP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideCriblTCP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideCriblTCP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideCriblTCP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideCriblTCP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideCriblTCP) GetMinVersion() *MinimumTLSVersionCriblTCP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideCriblTCP) GetMaxVersion() *MaximumTLSVersionCriblTCP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumCriblTCP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCriblTCP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCriblTCP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblTCP struct {
	// Unique ID for this input
	ID       string        `json:"id"`
	Type     *TypeCriblTCP `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblTCP `json:"connections,omitempty"`
	Pq          *PqCriblTCP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                        `json:"port"`
	TLS  *TLSSettingsServerSideCriblTCP `json:"tls,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumCriblTCP `json:"metadata,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool   `default:"false" json:"enableLoadBalancing"`
	Description         *string `json:"description,omitempty"`
}

func (i InputCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblTCP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCriblTCP) GetType() *TypeCriblTCP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCriblTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblTCP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblTCP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblTCP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblTCP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblTCP) GetConnections() []ConnectionCriblTCP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblTCP) GetPq() *PqCriblTCP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblTCP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputCriblTCP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputCriblTCP) GetTLS() *TLSSettingsServerSideCriblTCP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputCriblTCP) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputCriblTCP) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputCriblTCP) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputCriblTCP) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputCriblTCP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputCriblTCP) GetMetadata() []MetadatumCriblTCP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblTCP) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputCriblTCP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateInputTypeGooglePubsub string

const (
	CreateInputTypeGooglePubsubGooglePubsub CreateInputTypeGooglePubsub = "google_pubsub"
)

func (e CreateInputTypeGooglePubsub) ToPointer() *CreateInputTypeGooglePubsub {
	return &e
}
func (e *CreateInputTypeGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_pubsub":
		*e = CreateInputTypeGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeGooglePubsub: %v", v)
	}
}

type ConnectionGooglePubsub struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionGooglePubsub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionGooglePubsub) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeGooglePubsub - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeGooglePubsub string

const (
	CreateInputModeGooglePubsubSmart  CreateInputModeGooglePubsub = "smart"
	CreateInputModeGooglePubsubAlways CreateInputModeGooglePubsub = "always"
)

func (e CreateInputModeGooglePubsub) ToPointer() *CreateInputModeGooglePubsub {
	return &e
}
func (e *CreateInputModeGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeGooglePubsub: %v", v)
	}
}

// PqCompressionGooglePubsub - Codec to use to compress the persisted data
type PqCompressionGooglePubsub string

const (
	PqCompressionGooglePubsubNone PqCompressionGooglePubsub = "none"
	PqCompressionGooglePubsubGzip PqCompressionGooglePubsub = "gzip"
)

func (e PqCompressionGooglePubsub) ToPointer() *PqCompressionGooglePubsub {
	return &e
}
func (e *PqCompressionGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionGooglePubsub: %v", v)
	}
}

type PqGooglePubsub struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeGooglePubsub `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionGooglePubsub `default:"none" json:"compress"`
}

func (p PqGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqGooglePubsub) GetMode() *CreateInputModeGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqGooglePubsub) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqGooglePubsub) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqGooglePubsub) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqGooglePubsub) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqGooglePubsub) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqGooglePubsub) GetCompress() *PqCompressionGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Compress
}

// CreateInputGoogleAuthenticationMethod - Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
type CreateInputGoogleAuthenticationMethod string

const (
	CreateInputGoogleAuthenticationMethodAuto   CreateInputGoogleAuthenticationMethod = "auto"
	CreateInputGoogleAuthenticationMethodManual CreateInputGoogleAuthenticationMethod = "manual"
	CreateInputGoogleAuthenticationMethodSecret CreateInputGoogleAuthenticationMethod = "secret"
)

func (e CreateInputGoogleAuthenticationMethod) ToPointer() *CreateInputGoogleAuthenticationMethod {
	return &e
}
func (e *CreateInputGoogleAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = CreateInputGoogleAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputGoogleAuthenticationMethod: %v", v)
	}
}

type MetadatumGooglePubsub struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumGooglePubsub) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumGooglePubsub) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGooglePubsub struct {
	// Unique ID for this input
	ID       string                       `json:"id"`
	Type     *CreateInputTypeGooglePubsub `json:"type,omitempty"`
	Disabled *bool                        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionGooglePubsub `json:"connections,omitempty"`
	Pq          *PqGooglePubsub          `json:"pq,omitempty"`
	// ID of the topic to receive events from
	TopicName string `json:"topicName"`
	// ID of the subscription to use when receiving events
	SubscriptionName string `json:"subscriptionName"`
	// Create topic if it does not exist
	CreateTopic *bool `default:"false" json:"createTopic"`
	// Create subscription if it does not exist
	CreateSubscription *bool `default:"true" json:"createSubscription"`
	// Region to retrieve messages from. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
	Region *string `json:"region,omitempty"`
	// Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
	GoogleAuthMethod *CreateInputGoogleAuthenticationMethod `default:"manual" json:"googleAuthMethod"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitempty"`
	// If Destination exerts backpressure, this setting limits how many inbound events Stream will queue for processing before it stops retrieving events
	MaxBacklog *float64 `default:"1000" json:"maxBacklog"`
	// How many streams to pull messages from at one time. Doubling the value doubles the number of messages this Source pulls from the topic (if available), while consuming more CPU and memory. Defaults to 5.
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Pull request timeout, in milliseconds
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// Fields to add to events from this input
	Metadata    []MetadatumGooglePubsub `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	// Receive events in the order they were added to the queue. The process sending events must have ordering enabled.
	OrderedDelivery *bool `default:"false" json:"orderedDelivery"`
}

func (i InputGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGooglePubsub) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputGooglePubsub) GetType() *CreateInputTypeGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGooglePubsub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGooglePubsub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGooglePubsub) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGooglePubsub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGooglePubsub) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGooglePubsub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGooglePubsub) GetConnections() []ConnectionGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGooglePubsub) GetPq() *PqGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGooglePubsub) GetTopicName() string {
	if o == nil {
		return ""
	}
	return o.TopicName
}

func (o *InputGooglePubsub) GetSubscriptionName() string {
	if o == nil {
		return ""
	}
	return o.SubscriptionName
}

func (o *InputGooglePubsub) GetCreateTopic() *bool {
	if o == nil {
		return nil
	}
	return o.CreateTopic
}

func (o *InputGooglePubsub) GetCreateSubscription() *bool {
	if o == nil {
		return nil
	}
	return o.CreateSubscription
}

func (o *InputGooglePubsub) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputGooglePubsub) GetGoogleAuthMethod() *CreateInputGoogleAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.GoogleAuthMethod
}

func (o *InputGooglePubsub) GetServiceAccountCredentials() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentials
}

func (o *InputGooglePubsub) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputGooglePubsub) GetMaxBacklog() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBacklog
}

func (o *InputGooglePubsub) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *InputGooglePubsub) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGooglePubsub) GetMetadata() []MetadatumGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGooglePubsub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputGooglePubsub) GetOrderedDelivery() *bool {
	if o == nil {
		return nil
	}
	return o.OrderedDelivery
}

type TypeFirehose string

const (
	TypeFirehoseFirehose TypeFirehose = "firehose"
)

func (e TypeFirehose) ToPointer() *TypeFirehose {
	return &e
}
func (e *TypeFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "firehose":
		*e = TypeFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeFirehose: %v", v)
	}
}

type ConnectionFirehose struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionFirehose) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionFirehose) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeFirehose - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeFirehose string

const (
	ModeFirehoseSmart  ModeFirehose = "smart"
	ModeFirehoseAlways ModeFirehose = "always"
)

func (e ModeFirehose) ToPointer() *ModeFirehose {
	return &e
}
func (e *ModeFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeFirehose: %v", v)
	}
}

// CompressionFirehose - Codec to use to compress the persisted data
type CompressionFirehose string

const (
	CompressionFirehoseNone CompressionFirehose = "none"
	CompressionFirehoseGzip CompressionFirehose = "gzip"
)

func (e CompressionFirehose) ToPointer() *CompressionFirehose {
	return &e
}
func (e *CompressionFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionFirehose: %v", v)
	}
}

type PqFirehose struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeFirehose `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionFirehose `default:"none" json:"compress"`
}

func (p PqFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqFirehose) GetMode() *ModeFirehose {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqFirehose) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqFirehose) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqFirehose) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqFirehose) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqFirehose) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqFirehose) GetCompress() *CompressionFirehose {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionFirehose string

const (
	MinimumTLSVersionFirehoseTlSv1  MinimumTLSVersionFirehose = "TLSv1"
	MinimumTLSVersionFirehoseTlSv11 MinimumTLSVersionFirehose = "TLSv1.1"
	MinimumTLSVersionFirehoseTlSv12 MinimumTLSVersionFirehose = "TLSv1.2"
	MinimumTLSVersionFirehoseTlSv13 MinimumTLSVersionFirehose = "TLSv1.3"
)

func (e MinimumTLSVersionFirehose) ToPointer() *MinimumTLSVersionFirehose {
	return &e
}
func (e *MinimumTLSVersionFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionFirehose: %v", v)
	}
}

type MaximumTLSVersionFirehose string

const (
	MaximumTLSVersionFirehoseTlSv1  MaximumTLSVersionFirehose = "TLSv1"
	MaximumTLSVersionFirehoseTlSv11 MaximumTLSVersionFirehose = "TLSv1.1"
	MaximumTLSVersionFirehoseTlSv12 MaximumTLSVersionFirehose = "TLSv1.2"
	MaximumTLSVersionFirehoseTlSv13 MaximumTLSVersionFirehose = "TLSv1.3"
)

func (e MaximumTLSVersionFirehose) ToPointer() *MaximumTLSVersionFirehose {
	return &e
}
func (e *MaximumTLSVersionFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionFirehose: %v", v)
	}
}

type TLSSettingsServerSideFirehose struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                      `default:"false" json:"requestCert"`
	RejectUnauthorized any                        `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                        `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionFirehose `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionFirehose `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideFirehose) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideFirehose) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideFirehose) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideFirehose) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideFirehose) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideFirehose) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideFirehose) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideFirehose) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideFirehose) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideFirehose) GetMinVersion() *MinimumTLSVersionFirehose {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideFirehose) GetMaxVersion() *MaximumTLSVersionFirehose {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumFirehose struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumFirehose) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumFirehose) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputFirehose struct {
	// Unique ID for this input
	ID       string        `json:"id"`
	Type     *TypeFirehose `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionFirehose `json:"connections,omitempty"`
	Pq          *PqFirehose          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                       `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideFirehose `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata    []MetadatumFirehose `json:"metadata,omitempty"`
	Description *string             `json:"description,omitempty"`
}

func (i InputFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputFirehose) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputFirehose) GetType() *TypeFirehose {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputFirehose) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputFirehose) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputFirehose) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputFirehose) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputFirehose) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputFirehose) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputFirehose) GetConnections() []ConnectionFirehose {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputFirehose) GetPq() *PqFirehose {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputFirehose) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputFirehose) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputFirehose) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputFirehose) GetTLS() *TLSSettingsServerSideFirehose {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputFirehose) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputFirehose) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputFirehose) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputFirehose) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputFirehose) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputFirehose) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputFirehose) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputFirehose) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputFirehose) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputFirehose) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputFirehose) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputFirehose) GetMetadata() []MetadatumFirehose {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputFirehose) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputExecType string

const (
	InputExecTypeExec InputExecType = "exec"
)

func (e InputExecType) ToPointer() *InputExecType {
	return &e
}
func (e *InputExecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "exec":
		*e = InputExecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecType: %v", v)
	}
}

type InputExecConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputExecConnection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputExecConnection) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputExecMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputExecMode string

const (
	InputExecModeSmart  InputExecMode = "smart"
	InputExecModeAlways InputExecMode = "always"
)

func (e InputExecMode) ToPointer() *InputExecMode {
	return &e
}
func (e *InputExecMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputExecMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecMode: %v", v)
	}
}

// InputExecCompression - Codec to use to compress the persisted data
type InputExecCompression string

const (
	InputExecCompressionNone InputExecCompression = "none"
	InputExecCompressionGzip InputExecCompression = "gzip"
)

func (e InputExecCompression) ToPointer() *InputExecCompression {
	return &e
}
func (e *InputExecCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputExecCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecCompression: %v", v)
	}
}

type InputExecPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputExecMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputExecCompression `default:"none" json:"compress"`
}

func (i InputExecPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExecPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputExecPq) GetMode() *InputExecMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputExecPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputExecPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputExecPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputExecPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputExecPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputExecPq) GetCompress() *InputExecCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ScheduleType - Select a schedule type; either an interval (in seconds) or a cron-style schedule.
type ScheduleType string

const (
	ScheduleTypeInterval     ScheduleType = "interval"
	ScheduleTypeCronSchedule ScheduleType = "cronSchedule"
)

func (e ScheduleType) ToPointer() *ScheduleType {
	return &e
}
func (e *ScheduleType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "interval":
		fallthrough
	case "cronSchedule":
		*e = ScheduleType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ScheduleType: %v", v)
	}
}

type InputExecMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputExecMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputExecMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputExec struct {
	// Unique ID for this input
	ID       string        `json:"id"`
	Type     InputExecType `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputExecConnection `json:"connections,omitempty"`
	Pq          *InputExecPq          `json:"pq,omitempty"`
	// Command to execute; supports Bourne shell (or CMD on Windows) syntax
	Command string `json:"command"`
	// Maximum number of retry attempts in the event that the command fails
	Retries *float64 `default:"10" json:"retries"`
	// Select a schedule type; either an interval (in seconds) or a cron-style schedule.
	ScheduleType *ScheduleType `default:"interval" json:"scheduleType"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata    []InputExecMetadatum `json:"metadata,omitempty"`
	Description *string              `json:"description,omitempty"`
	// Interval between command executions in seconds.
	Interval *float64 `default:"60" json:"interval"`
	// Cron schedule to execute the command on.
	CronSchedule *string `default:"* * * * *" json:"cronSchedule"`
}

func (i InputExec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputExec) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputExec) GetType() InputExecType {
	if o == nil {
		return InputExecType("")
	}
	return o.Type
}

func (o *InputExec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputExec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputExec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputExec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputExec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputExec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputExec) GetConnections() []InputExecConnection {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputExec) GetPq() *InputExecPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputExec) GetCommand() string {
	if o == nil {
		return ""
	}
	return o.Command
}

func (o *InputExec) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

func (o *InputExec) GetScheduleType() *ScheduleType {
	if o == nil {
		return nil
	}
	return o.ScheduleType
}

func (o *InputExec) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputExec) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputExec) GetMetadata() []InputExecMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputExec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputExec) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputExec) GetCronSchedule() *string {
	if o == nil {
		return nil
	}
	return o.CronSchedule
}

type TypeEventhub string

const (
	TypeEventhubEventhub TypeEventhub = "eventhub"
)

func (e TypeEventhub) ToPointer() *TypeEventhub {
	return &e
}
func (e *TypeEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "eventhub":
		*e = TypeEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeEventhub: %v", v)
	}
}

type ConnectionEventhub struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionEventhub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionEventhub) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeEventhub - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeEventhub string

const (
	ModeEventhubSmart  ModeEventhub = "smart"
	ModeEventhubAlways ModeEventhub = "always"
)

func (e ModeEventhub) ToPointer() *ModeEventhub {
	return &e
}
func (e *ModeEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeEventhub: %v", v)
	}
}

// CompressionEventhub - Codec to use to compress the persisted data
type CompressionEventhub string

const (
	CompressionEventhubNone CompressionEventhub = "none"
	CompressionEventhubGzip CompressionEventhub = "gzip"
)

func (e CompressionEventhub) ToPointer() *CompressionEventhub {
	return &e
}
func (e *CompressionEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionEventhub: %v", v)
	}
}

type PqEventhub struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeEventhub `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionEventhub `default:"none" json:"compress"`
}

func (p PqEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqEventhub) GetMode() *ModeEventhub {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqEventhub) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqEventhub) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqEventhub) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqEventhub) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqEventhub) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqEventhub) GetCompress() *CompressionEventhub {
	if o == nil {
		return nil
	}
	return o.Compress
}

type SASLMechanismEventhub string

const (
	SASLMechanismEventhubPlain       SASLMechanismEventhub = "plain"
	SASLMechanismEventhubOauthbearer SASLMechanismEventhub = "oauthbearer"
)

func (e SASLMechanismEventhub) ToPointer() *SASLMechanismEventhub {
	return &e
}
func (e *SASLMechanismEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "oauthbearer":
		*e = SASLMechanismEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SASLMechanismEventhub: %v", v)
	}
}

// AuthenticationEventhub - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type AuthenticationEventhub struct {
	Disabled  *bool                  `default:"false" json:"disabled"`
	Mechanism *SASLMechanismEventhub `default:"plain" json:"mechanism"`
}

func (a AuthenticationEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthenticationEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *AuthenticationEventhub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *AuthenticationEventhub) GetMechanism() *SASLMechanismEventhub {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type TLSSettingsClientSideEventhub struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another trusted CA (such as the system's)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (t TLSSettingsClientSideEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsClientSideEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsClientSideEventhub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsClientSideEventhub) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

type MetadatumEventhub struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumEventhub) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumEventhub) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputEventhub struct {
	// Unique ID for this input
	ID       string        `json:"id"`
	Type     *TypeEventhub `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionEventhub `json:"connections,omitempty"`
	Pq          *PqEventhub          `json:"pq,omitempty"`
	// List of Event Hubs Kafka brokers to connect to (example: yourdomain.servicebus.windows.net:9093). The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// The name of the Event Hub (Kafka topic) to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Event Hubs Source to only a single topic.
	Topics []string `json:"topics"`
	// The consumer group this instance belongs to. Default is 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Start reading from earliest available data; relevant only during initial subscription
	FromBeginning *bool `default:"true" json:"fromBeginning"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *AuthenticationEventhub        `json:"sasl,omitempty"`
	TLS  *TLSSettingsClientSideEventhub `json:"tls,omitempty"`
	//       Timeout (session.timeout.ms in Kafka domain) used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires, the broker will remove the client from the group and initiate a rebalance.
	//       Value must be lower than rebalanceTimeout.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time (rebalance.timeout.ms in Kafka domain) for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time (heartbeat.interval.ms in Kafka domain) between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Minimize duplicate events by starting only one consumer for each topic partition
	MinimizeDuplicates *bool `default:"false" json:"minimizeDuplicates"`
	// Fields to add to events from this input
	Metadata    []MetadatumEventhub `json:"metadata,omitempty"`
	Description *string             `json:"description,omitempty"`
}

func (i InputEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputEventhub) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputEventhub) GetType() *TypeEventhub {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputEventhub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputEventhub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputEventhub) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputEventhub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputEventhub) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputEventhub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputEventhub) GetConnections() []ConnectionEventhub {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputEventhub) GetPq() *PqEventhub {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputEventhub) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputEventhub) GetTopics() []string {
	if o == nil {
		return []string{}
	}
	return o.Topics
}

func (o *InputEventhub) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputEventhub) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputEventhub) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputEventhub) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputEventhub) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputEventhub) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputEventhub) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputEventhub) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputEventhub) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputEventhub) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputEventhub) GetSasl() *AuthenticationEventhub {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputEventhub) GetTLS() *TLSSettingsClientSideEventhub {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputEventhub) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputEventhub) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputEventhub) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputEventhub) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputEventhub) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputEventhub) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputEventhub) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputEventhub) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputEventhub) GetMinimizeDuplicates() *bool {
	if o == nil {
		return nil
	}
	return o.MinimizeDuplicates
}

func (o *InputEventhub) GetMetadata() []MetadatumEventhub {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputEventhub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeOffice365MsgTrace string

const (
	TypeOffice365MsgTraceOffice365MsgTrace TypeOffice365MsgTrace = "office365_msg_trace"
)

func (e TypeOffice365MsgTrace) ToPointer() *TypeOffice365MsgTrace {
	return &e
}
func (e *TypeOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_msg_trace":
		*e = TypeOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365MsgTrace: %v", v)
	}
}

type ConnectionOffice365MsgTrace struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionOffice365MsgTrace) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionOffice365MsgTrace) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeOffice365MsgTrace - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365MsgTrace string

const (
	ModeOffice365MsgTraceSmart  ModeOffice365MsgTrace = "smart"
	ModeOffice365MsgTraceAlways ModeOffice365MsgTrace = "always"
)

func (e ModeOffice365MsgTrace) ToPointer() *ModeOffice365MsgTrace {
	return &e
}
func (e *ModeOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeOffice365MsgTrace: %v", v)
	}
}

// CompressionOffice365MsgTrace - Codec to use to compress the persisted data
type CompressionOffice365MsgTrace string

const (
	CompressionOffice365MsgTraceNone CompressionOffice365MsgTrace = "none"
	CompressionOffice365MsgTraceGzip CompressionOffice365MsgTrace = "gzip"
)

func (e CompressionOffice365MsgTrace) ToPointer() *CompressionOffice365MsgTrace {
	return &e
}
func (e *CompressionOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionOffice365MsgTrace: %v", v)
	}
}

type PqOffice365MsgTrace struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365MsgTrace `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionOffice365MsgTrace `default:"none" json:"compress"`
}

func (p PqOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqOffice365MsgTrace) GetMode() *ModeOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqOffice365MsgTrace) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqOffice365MsgTrace) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqOffice365MsgTrace) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqOffice365MsgTrace) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqOffice365MsgTrace) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqOffice365MsgTrace) GetCompress() *CompressionOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodOffice365MsgTrace - Select authentication method.
type AuthenticationMethodOffice365MsgTrace string

const (
	AuthenticationMethodOffice365MsgTraceManual      AuthenticationMethodOffice365MsgTrace = "manual"
	AuthenticationMethodOffice365MsgTraceSecret      AuthenticationMethodOffice365MsgTrace = "secret"
	AuthenticationMethodOffice365MsgTraceOauth       AuthenticationMethodOffice365MsgTrace = "oauth"
	AuthenticationMethodOffice365MsgTraceOauthSecret AuthenticationMethodOffice365MsgTrace = "oauthSecret"
	AuthenticationMethodOffice365MsgTraceOauthCert   AuthenticationMethodOffice365MsgTrace = "oauthCert"
)

func (e AuthenticationMethodOffice365MsgTrace) ToPointer() *AuthenticationMethodOffice365MsgTrace {
	return &e
}
func (e *AuthenticationMethodOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "oauth":
		fallthrough
	case "oauthSecret":
		fallthrough
	case "oauthCert":
		*e = AuthenticationMethodOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodOffice365MsgTrace: %v", v)
	}
}

// LogLevelOffice365MsgTrace - Log Level (verbosity) for collection runtime behavior.
type LogLevelOffice365MsgTrace string

const (
	LogLevelOffice365MsgTraceError LogLevelOffice365MsgTrace = "error"
	LogLevelOffice365MsgTraceWarn  LogLevelOffice365MsgTrace = "warn"
	LogLevelOffice365MsgTraceInfo  LogLevelOffice365MsgTrace = "info"
	LogLevelOffice365MsgTraceDebug LogLevelOffice365MsgTrace = "debug"
	LogLevelOffice365MsgTraceSilly LogLevelOffice365MsgTrace = "silly"
)

func (e LogLevelOffice365MsgTrace) ToPointer() *LogLevelOffice365MsgTrace {
	return &e
}
func (e *LogLevelOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		fallthrough
	case "silly":
		*e = LogLevelOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelOffice365MsgTrace: %v", v)
	}
}

type MetadatumOffice365MsgTrace struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumOffice365MsgTrace) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumOffice365MsgTrace) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// RetryTypeOffice365MsgTrace - The algorithm to use when performing HTTP retries
type RetryTypeOffice365MsgTrace string

const (
	RetryTypeOffice365MsgTraceNone    RetryTypeOffice365MsgTrace = "none"
	RetryTypeOffice365MsgTraceBackoff RetryTypeOffice365MsgTrace = "backoff"
	RetryTypeOffice365MsgTraceStatic  RetryTypeOffice365MsgTrace = "static"
)

func (e RetryTypeOffice365MsgTrace) ToPointer() *RetryTypeOffice365MsgTrace {
	return &e
}
func (e *RetryTypeOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeOffice365MsgTrace: %v", v)
	}
}

type RetryRulesOffice365MsgTrace struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365MsgTrace `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesOffice365MsgTrace) GetType() *RetryTypeOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesOffice365MsgTrace) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesOffice365MsgTrace) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesOffice365MsgTrace) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesOffice365MsgTrace) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesOffice365MsgTrace) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesOffice365MsgTrace) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesOffice365MsgTrace) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// SubscriptionPlanOffice365MsgTrace - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365MsgTrace string

const (
	SubscriptionPlanOffice365MsgTraceEnterpriseGcc SubscriptionPlanOffice365MsgTrace = "enterprise_gcc"
	SubscriptionPlanOffice365MsgTraceGcc           SubscriptionPlanOffice365MsgTrace = "gcc"
	SubscriptionPlanOffice365MsgTraceGccHigh       SubscriptionPlanOffice365MsgTrace = "gcc_high"
	SubscriptionPlanOffice365MsgTraceDod           SubscriptionPlanOffice365MsgTrace = "dod"
)

func (e SubscriptionPlanOffice365MsgTrace) ToPointer() *SubscriptionPlanOffice365MsgTrace {
	return &e
}
func (e *SubscriptionPlanOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = SubscriptionPlanOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SubscriptionPlanOffice365MsgTrace: %v", v)
	}
}

type CertOptions struct {
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path to the private key to use. Key should be in PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt the private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path to the certificate to use. Certificate should be in PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
}

func (o *CertOptions) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CertOptions) GetPrivKeyPath() string {
	if o == nil {
		return ""
	}
	return o.PrivKeyPath
}

func (o *CertOptions) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CertOptions) GetCertPath() string {
	if o == nil {
		return ""
	}
	return o.CertPath
}

type InputOffice365MsgTrace struct {
	// Unique ID for this input
	ID       string                 `json:"id"`
	Type     *TypeOffice365MsgTrace `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365MsgTrace `json:"connections,omitempty"`
	Pq          *PqOffice365MsgTrace          `json:"pq,omitempty"`
	// URL to use when retrieving report data.
	URL *string `default:"https://reports.office365.com/ecp/reportingwebservice/reporting.svc/MessageTrace" json:"url"`
	// How often (in minutes) to run the report. Must divide evenly into 60 minutes to create a predictable schedule, or Save will fail.
	Interval *float64 `default:"60" json:"interval"`
	// Backward offset for the search range's head. (E.g.: -3h@h) Message Trace data is delayed; this parameter (with Date range end) compensates for delay and gaps.
	StartDate *string `json:"startDate,omitempty"`
	// Backward offset for the search range's tail. (E.g.: -2h@h) Message Trace data is delayed; this parameter (with Date range start) compensates for delay and gaps.
	EndDate *string `json:"endDate,omitempty"`
	// HTTP request inactivity timeout. Maximum is 2400 (40 minutes); enter 0 to wait indefinitely.
	Timeout *float64 `default:"300" json:"timeout"`
	// Disables time filtering of events when a date range is specified.
	DisableTimeFilter *bool `default:"true" json:"disableTimeFilter"`
	// Select authentication method.
	AuthType *AuthenticationMethodOffice365MsgTrace `default:"oauth" json:"authType"`
	// Reschedule tasks that failed with non-fatal errors
	RescheduleDroppedTasks *bool `default:"true" json:"rescheduleDroppedTasks"`
	// Maximum number of times a task can be rescheduled
	MaxTaskReschedule *float64 `default:"1" json:"maxTaskReschedule"`
	// Log Level (verbosity) for collection runtime behavior.
	LogLevel *LogLevelOffice365MsgTrace `default:"info" json:"logLevel"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata    []MetadatumOffice365MsgTrace `json:"metadata,omitempty"`
	RetryRules  *RetryRulesOffice365MsgTrace `json:"retryRules,omitempty"`
	Description *string                      `json:"description,omitempty"`
	// Username to run Message Trace API call.
	Username *string `json:"username,omitempty"`
	// Password to run Message Trace API call.
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials.
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// client_secret to pass in the OAuth request parameter.
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Directory ID (tenant identifier) in Azure Active Directory.
	TenantID *string `json:"tenantId,omitempty"`
	// client_id to pass in the OAuth request parameter.
	ClientID *string `json:"clientId,omitempty"`
	// Resource to pass in the OAuth request parameter.
	Resource *string `default:"https://outlook.office365.com" json:"resource"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365MsgTrace `default:"enterprise_gcc" json:"planType"`
	// Select or create a secret that references your client_secret to pass in the OAuth request parameter.
	TextSecret  *string      `json:"textSecret,omitempty"`
	CertOptions *CertOptions `json:"certOptions,omitempty"`
}

func (i InputOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365MsgTrace) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputOffice365MsgTrace) GetType() *TypeOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365MsgTrace) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365MsgTrace) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365MsgTrace) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365MsgTrace) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365MsgTrace) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365MsgTrace) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365MsgTrace) GetConnections() []ConnectionOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365MsgTrace) GetPq() *PqOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365MsgTrace) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *InputOffice365MsgTrace) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputOffice365MsgTrace) GetStartDate() *string {
	if o == nil {
		return nil
	}
	return o.StartDate
}

func (o *InputOffice365MsgTrace) GetEndDate() *string {
	if o == nil {
		return nil
	}
	return o.EndDate
}

func (o *InputOffice365MsgTrace) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365MsgTrace) GetDisableTimeFilter() *bool {
	if o == nil {
		return nil
	}
	return o.DisableTimeFilter
}

func (o *InputOffice365MsgTrace) GetAuthType() *AuthenticationMethodOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365MsgTrace) GetRescheduleDroppedTasks() *bool {
	if o == nil {
		return nil
	}
	return o.RescheduleDroppedTasks
}

func (o *InputOffice365MsgTrace) GetMaxTaskReschedule() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxTaskReschedule
}

func (o *InputOffice365MsgTrace) GetLogLevel() *LogLevelOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputOffice365MsgTrace) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365MsgTrace) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365MsgTrace) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365MsgTrace) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365MsgTrace) GetIgnoreGroupJobsLimit() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreGroupJobsLimit
}

func (o *InputOffice365MsgTrace) GetMetadata() []MetadatumOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365MsgTrace) GetRetryRules() *RetryRulesOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365MsgTrace) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365MsgTrace) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputOffice365MsgTrace) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputOffice365MsgTrace) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputOffice365MsgTrace) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365MsgTrace) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *InputOffice365MsgTrace) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *InputOffice365MsgTrace) GetResource() *string {
	if o == nil {
		return nil
	}
	return o.Resource
}

func (o *InputOffice365MsgTrace) GetPlanType() *SubscriptionPlanOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365MsgTrace) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOffice365MsgTrace) GetCertOptions() *CertOptions {
	if o == nil {
		return nil
	}
	return o.CertOptions
}

type TypeOffice365Service string

const (
	TypeOffice365ServiceOffice365Service TypeOffice365Service = "office365_service"
)

func (e TypeOffice365Service) ToPointer() *TypeOffice365Service {
	return &e
}
func (e *TypeOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_service":
		*e = TypeOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365Service: %v", v)
	}
}

type ConnectionOffice365Service struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionOffice365Service) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionOffice365Service) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeOffice365Service - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365Service string

const (
	ModeOffice365ServiceSmart  ModeOffice365Service = "smart"
	ModeOffice365ServiceAlways ModeOffice365Service = "always"
)

func (e ModeOffice365Service) ToPointer() *ModeOffice365Service {
	return &e
}
func (e *ModeOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeOffice365Service: %v", v)
	}
}

// CompressionOffice365Service - Codec to use to compress the persisted data
type CompressionOffice365Service string

const (
	CompressionOffice365ServiceNone CompressionOffice365Service = "none"
	CompressionOffice365ServiceGzip CompressionOffice365Service = "gzip"
)

func (e CompressionOffice365Service) ToPointer() *CompressionOffice365Service {
	return &e
}
func (e *CompressionOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionOffice365Service: %v", v)
	}
}

type PqOffice365Service struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365Service `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionOffice365Service `default:"none" json:"compress"`
}

func (p PqOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqOffice365Service) GetMode() *ModeOffice365Service {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqOffice365Service) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqOffice365Service) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqOffice365Service) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqOffice365Service) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqOffice365Service) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqOffice365Service) GetCompress() *CompressionOffice365Service {
	if o == nil {
		return nil
	}
	return o.Compress
}

// SubscriptionPlanOffice365Service - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365Service string

const (
	SubscriptionPlanOffice365ServiceEnterpriseGcc SubscriptionPlanOffice365Service = "enterprise_gcc"
	SubscriptionPlanOffice365ServiceGcc           SubscriptionPlanOffice365Service = "gcc"
	SubscriptionPlanOffice365ServiceGccHigh       SubscriptionPlanOffice365Service = "gcc_high"
	SubscriptionPlanOffice365ServiceDod           SubscriptionPlanOffice365Service = "dod"
)

func (e SubscriptionPlanOffice365Service) ToPointer() *SubscriptionPlanOffice365Service {
	return &e
}
func (e *SubscriptionPlanOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = SubscriptionPlanOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SubscriptionPlanOffice365Service: %v", v)
	}
}

type MetadatumOffice365Service struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumOffice365Service) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumOffice365Service) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// LogLevelOffice365Service - Collector runtime Log Level
type LogLevelOffice365Service string

const (
	LogLevelOffice365ServiceError LogLevelOffice365Service = "error"
	LogLevelOffice365ServiceWarn  LogLevelOffice365Service = "warn"
	LogLevelOffice365ServiceInfo  LogLevelOffice365Service = "info"
	LogLevelOffice365ServiceDebug LogLevelOffice365Service = "debug"
)

func (e LogLevelOffice365Service) ToPointer() *LogLevelOffice365Service {
	return &e
}
func (e *LogLevelOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = LogLevelOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelOffice365Service: %v", v)
	}
}

type ContentConfigOffice365Service struct {
	// Office 365 Services API Content Type
	ContentType *string `json:"contentType,omitempty"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitempty"`
	Interval    *float64 `json:"interval,omitempty"`
	// Collector runtime Log Level
	LogLevel *LogLevelOffice365Service `json:"logLevel,omitempty"`
	Enabled  *bool                     `json:"enabled,omitempty"`
}

func (o *ContentConfigOffice365Service) GetContentType() *string {
	if o == nil {
		return nil
	}
	return o.ContentType
}

func (o *ContentConfigOffice365Service) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *ContentConfigOffice365Service) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *ContentConfigOffice365Service) GetLogLevel() *LogLevelOffice365Service {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *ContentConfigOffice365Service) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

// RetryTypeOffice365Service - The algorithm to use when performing HTTP retries
type RetryTypeOffice365Service string

const (
	RetryTypeOffice365ServiceNone    RetryTypeOffice365Service = "none"
	RetryTypeOffice365ServiceBackoff RetryTypeOffice365Service = "backoff"
	RetryTypeOffice365ServiceStatic  RetryTypeOffice365Service = "static"
)

func (e RetryTypeOffice365Service) ToPointer() *RetryTypeOffice365Service {
	return &e
}
func (e *RetryTypeOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeOffice365Service: %v", v)
	}
}

type RetryRulesOffice365Service struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365Service `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesOffice365Service) GetType() *RetryTypeOffice365Service {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesOffice365Service) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesOffice365Service) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesOffice365Service) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesOffice365Service) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesOffice365Service) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesOffice365Service) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesOffice365Service) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationMethodOffice365Service - Enter client secret directly, or select a stored secret
type AuthenticationMethodOffice365Service string

const (
	AuthenticationMethodOffice365ServiceManual AuthenticationMethodOffice365Service = "manual"
	AuthenticationMethodOffice365ServiceSecret AuthenticationMethodOffice365Service = "secret"
)

func (e AuthenticationMethodOffice365Service) ToPointer() *AuthenticationMethodOffice365Service {
	return &e
}
func (e *AuthenticationMethodOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodOffice365Service: %v", v)
	}
}

type InputOffice365Service struct {
	// Unique ID for this input
	ID       string                `json:"id"`
	Type     *TypeOffice365Service `json:"type,omitempty"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365Service `json:"connections,omitempty"`
	Pq          *PqOffice365Service          `json:"pq,omitempty"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365Service `default:"enterprise_gcc" json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `default:"300" json:"timeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata []MetadatumOffice365Service `json:"metadata,omitempty"`
	// Enable Office 365 Service Communication API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered for current and historical status must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfigOffice365Service `json:"contentConfig,omitempty"`
	RetryRules    *RetryRulesOffice365Service     `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodOffice365Service `default:"manual" json:"authType"`
	Description *string                               `json:"description,omitempty"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (i InputOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365Service) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputOffice365Service) GetType() *TypeOffice365Service {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365Service) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365Service) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365Service) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365Service) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365Service) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365Service) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365Service) GetConnections() []ConnectionOffice365Service {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365Service) GetPq() *PqOffice365Service {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365Service) GetPlanType() *SubscriptionPlanOffice365Service {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365Service) GetTenantID() string {
	if o == nil {
		return ""
	}
	return o.TenantID
}

func (o *InputOffice365Service) GetAppID() string {
	if o == nil {
		return ""
	}
	return o.AppID
}

func (o *InputOffice365Service) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365Service) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365Service) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365Service) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365Service) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365Service) GetIgnoreGroupJobsLimit() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreGroupJobsLimit
}

func (o *InputOffice365Service) GetMetadata() []MetadatumOffice365Service {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365Service) GetContentConfig() []ContentConfigOffice365Service {
	if o == nil {
		return nil
	}
	return o.ContentConfig
}

func (o *InputOffice365Service) GetRetryRules() *RetryRulesOffice365Service {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365Service) GetAuthType() *AuthenticationMethodOffice365Service {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365Service) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365Service) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365Service) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

type TypeOffice365Mgmt string

const (
	TypeOffice365MgmtOffice365Mgmt TypeOffice365Mgmt = "office365_mgmt"
)

func (e TypeOffice365Mgmt) ToPointer() *TypeOffice365Mgmt {
	return &e
}
func (e *TypeOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_mgmt":
		*e = TypeOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365Mgmt: %v", v)
	}
}

type ConnectionOffice365Mgmt struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionOffice365Mgmt) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionOffice365Mgmt) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeOffice365Mgmt - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365Mgmt string

const (
	ModeOffice365MgmtSmart  ModeOffice365Mgmt = "smart"
	ModeOffice365MgmtAlways ModeOffice365Mgmt = "always"
)

func (e ModeOffice365Mgmt) ToPointer() *ModeOffice365Mgmt {
	return &e
}
func (e *ModeOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeOffice365Mgmt: %v", v)
	}
}

// CompressionOffice365Mgmt - Codec to use to compress the persisted data
type CompressionOffice365Mgmt string

const (
	CompressionOffice365MgmtNone CompressionOffice365Mgmt = "none"
	CompressionOffice365MgmtGzip CompressionOffice365Mgmt = "gzip"
)

func (e CompressionOffice365Mgmt) ToPointer() *CompressionOffice365Mgmt {
	return &e
}
func (e *CompressionOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionOffice365Mgmt: %v", v)
	}
}

type PqOffice365Mgmt struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365Mgmt `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionOffice365Mgmt `default:"none" json:"compress"`
}

func (p PqOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqOffice365Mgmt) GetMode() *ModeOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqOffice365Mgmt) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqOffice365Mgmt) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqOffice365Mgmt) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqOffice365Mgmt) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqOffice365Mgmt) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqOffice365Mgmt) GetCompress() *CompressionOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Compress
}

// SubscriptionPlanOffice365Mgmt - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365Mgmt string

const (
	SubscriptionPlanOffice365MgmtEnterpriseGcc SubscriptionPlanOffice365Mgmt = "enterprise_gcc"
	SubscriptionPlanOffice365MgmtGcc           SubscriptionPlanOffice365Mgmt = "gcc"
	SubscriptionPlanOffice365MgmtGccHigh       SubscriptionPlanOffice365Mgmt = "gcc_high"
	SubscriptionPlanOffice365MgmtDod           SubscriptionPlanOffice365Mgmt = "dod"
)

func (e SubscriptionPlanOffice365Mgmt) ToPointer() *SubscriptionPlanOffice365Mgmt {
	return &e
}
func (e *SubscriptionPlanOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = SubscriptionPlanOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SubscriptionPlanOffice365Mgmt: %v", v)
	}
}

type MetadatumOffice365Mgmt struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumOffice365Mgmt) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumOffice365Mgmt) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// LogLevelOffice365Mgmt - Collector runtime Log Level
type LogLevelOffice365Mgmt string

const (
	LogLevelOffice365MgmtError LogLevelOffice365Mgmt = "error"
	LogLevelOffice365MgmtWarn  LogLevelOffice365Mgmt = "warn"
	LogLevelOffice365MgmtInfo  LogLevelOffice365Mgmt = "info"
	LogLevelOffice365MgmtDebug LogLevelOffice365Mgmt = "debug"
)

func (e LogLevelOffice365Mgmt) ToPointer() *LogLevelOffice365Mgmt {
	return &e
}
func (e *LogLevelOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = LogLevelOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelOffice365Mgmt: %v", v)
	}
}

type ContentConfigOffice365Mgmt struct {
	// Office 365 Management Activity API Content Type
	ContentType *string `json:"contentType,omitempty"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitempty"`
	Interval    *float64 `json:"interval,omitempty"`
	// Collector runtime Log Level
	LogLevel *LogLevelOffice365Mgmt `json:"logLevel,omitempty"`
	Enabled  *bool                  `json:"enabled,omitempty"`
}

func (o *ContentConfigOffice365Mgmt) GetContentType() *string {
	if o == nil {
		return nil
	}
	return o.ContentType
}

func (o *ContentConfigOffice365Mgmt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *ContentConfigOffice365Mgmt) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *ContentConfigOffice365Mgmt) GetLogLevel() *LogLevelOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *ContentConfigOffice365Mgmt) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

// RetryTypeOffice365Mgmt - The algorithm to use when performing HTTP retries
type RetryTypeOffice365Mgmt string

const (
	RetryTypeOffice365MgmtNone    RetryTypeOffice365Mgmt = "none"
	RetryTypeOffice365MgmtBackoff RetryTypeOffice365Mgmt = "backoff"
	RetryTypeOffice365MgmtStatic  RetryTypeOffice365Mgmt = "static"
)

func (e RetryTypeOffice365Mgmt) ToPointer() *RetryTypeOffice365Mgmt {
	return &e
}
func (e *RetryTypeOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeOffice365Mgmt: %v", v)
	}
}

type RetryRulesOffice365Mgmt struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365Mgmt `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesOffice365Mgmt) GetType() *RetryTypeOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesOffice365Mgmt) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesOffice365Mgmt) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesOffice365Mgmt) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesOffice365Mgmt) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesOffice365Mgmt) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesOffice365Mgmt) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesOffice365Mgmt) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationMethodOffice365Mgmt - Enter client secret directly, or select a stored secret
type AuthenticationMethodOffice365Mgmt string

const (
	AuthenticationMethodOffice365MgmtManual AuthenticationMethodOffice365Mgmt = "manual"
	AuthenticationMethodOffice365MgmtSecret AuthenticationMethodOffice365Mgmt = "secret"
)

func (e AuthenticationMethodOffice365Mgmt) ToPointer() *AuthenticationMethodOffice365Mgmt {
	return &e
}
func (e *AuthenticationMethodOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodOffice365Mgmt: %v", v)
	}
}

type InputOffice365Mgmt struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     *TypeOffice365Mgmt `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365Mgmt `json:"connections,omitempty"`
	Pq          *PqOffice365Mgmt          `json:"pq,omitempty"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365Mgmt `default:"enterprise_gcc" json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `default:"300" json:"timeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata []MetadatumOffice365Mgmt `json:"metadata,omitempty"`
	// Optional Publisher Identifier to use in API requests, defaults to tenant id if not defined. For more information see [here](https://docs.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference#start-a-subscription)
	PublisherIdentifier *string `json:"publisherIdentifier,omitempty"`
	// Enable Office 365 Management Activity API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfigOffice365Mgmt `json:"contentConfig,omitempty"`
	// Use this setting to account for ingestion lag. This is necessary because there can be a lag of 60 - 90 minutes (or longer) before Office 365 events are available for retrieval.
	IngestionLag *float64                 `default:"0" json:"ingestionLag"`
	RetryRules   *RetryRulesOffice365Mgmt `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodOffice365Mgmt `default:"manual" json:"authType"`
	Description *string                            `json:"description,omitempty"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
}

func (i InputOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365Mgmt) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputOffice365Mgmt) GetType() *TypeOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365Mgmt) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365Mgmt) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365Mgmt) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365Mgmt) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365Mgmt) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365Mgmt) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365Mgmt) GetConnections() []ConnectionOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365Mgmt) GetPq() *PqOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365Mgmt) GetPlanType() *SubscriptionPlanOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365Mgmt) GetTenantID() string {
	if o == nil {
		return ""
	}
	return o.TenantID
}

func (o *InputOffice365Mgmt) GetAppID() string {
	if o == nil {
		return ""
	}
	return o.AppID
}

func (o *InputOffice365Mgmt) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365Mgmt) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365Mgmt) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365Mgmt) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365Mgmt) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365Mgmt) GetIgnoreGroupJobsLimit() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreGroupJobsLimit
}

func (o *InputOffice365Mgmt) GetMetadata() []MetadatumOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365Mgmt) GetPublisherIdentifier() *string {
	if o == nil {
		return nil
	}
	return o.PublisherIdentifier
}

func (o *InputOffice365Mgmt) GetContentConfig() []ContentConfigOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.ContentConfig
}

func (o *InputOffice365Mgmt) GetIngestionLag() *float64 {
	if o == nil {
		return nil
	}
	return o.IngestionLag
}

func (o *InputOffice365Mgmt) GetRetryRules() *RetryRulesOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365Mgmt) GetAuthType() *AuthenticationMethodOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365Mgmt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365Mgmt) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365Mgmt) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

type TypeEdgePrometheus string

const (
	TypeEdgePrometheusEdgePrometheus TypeEdgePrometheus = "edge_prometheus"
)

func (e TypeEdgePrometheus) ToPointer() *TypeEdgePrometheus {
	return &e
}
func (e *TypeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "edge_prometheus":
		*e = TypeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeEdgePrometheus: %v", v)
	}
}

type ConnectionEdgePrometheus struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionEdgePrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionEdgePrometheus) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeEdgePrometheus - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeEdgePrometheus string

const (
	ModeEdgePrometheusSmart  ModeEdgePrometheus = "smart"
	ModeEdgePrometheusAlways ModeEdgePrometheus = "always"
)

func (e ModeEdgePrometheus) ToPointer() *ModeEdgePrometheus {
	return &e
}
func (e *ModeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeEdgePrometheus: %v", v)
	}
}

// PqCompressionEdgePrometheus - Codec to use to compress the persisted data
type PqCompressionEdgePrometheus string

const (
	PqCompressionEdgePrometheusNone PqCompressionEdgePrometheus = "none"
	PqCompressionEdgePrometheusGzip PqCompressionEdgePrometheus = "gzip"
)

func (e PqCompressionEdgePrometheus) ToPointer() *PqCompressionEdgePrometheus {
	return &e
}
func (e *PqCompressionEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionEdgePrometheus: %v", v)
	}
}

type PqEdgePrometheus struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeEdgePrometheus `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionEdgePrometheus `default:"none" json:"compress"`
}

func (p PqEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqEdgePrometheus) GetMode() *ModeEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqEdgePrometheus) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqEdgePrometheus) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqEdgePrometheus) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqEdgePrometheus) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqEdgePrometheus) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqEdgePrometheus) GetCompress() *PqCompressionEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Compress
}

// DiscoveryTypeEdgePrometheus - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryTypeEdgePrometheus string

const (
	DiscoveryTypeEdgePrometheusStatic  DiscoveryTypeEdgePrometheus = "static"
	DiscoveryTypeEdgePrometheusDNS     DiscoveryTypeEdgePrometheus = "dns"
	DiscoveryTypeEdgePrometheusEc2     DiscoveryTypeEdgePrometheus = "ec2"
	DiscoveryTypeEdgePrometheusK8sNode DiscoveryTypeEdgePrometheus = "k8s-node"
	DiscoveryTypeEdgePrometheusK8sPods DiscoveryTypeEdgePrometheus = "k8s-pods"
)

func (e DiscoveryTypeEdgePrometheus) ToPointer() *DiscoveryTypeEdgePrometheus {
	return &e
}
func (e *DiscoveryTypeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "static":
		fallthrough
	case "dns":
		fallthrough
	case "ec2":
		fallthrough
	case "k8s-node":
		fallthrough
	case "k8s-pods":
		*e = DiscoveryTypeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DiscoveryTypeEdgePrometheus: %v", v)
	}
}

// PersistenceCompression - Data compression format. Default is gzip.
type PersistenceCompression string

const (
	PersistenceCompressionNone PersistenceCompression = "none"
	PersistenceCompressionGzip PersistenceCompression = "gzip"
)

func (e PersistenceCompression) ToPointer() *PersistenceCompression {
	return &e
}
func (e *PersistenceCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PersistenceCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PersistenceCompression: %v", v)
	}
}

type DiskSpooling struct {
	// Spool events on disk for Cribl Edge and Search. Default is disabled.
	Enable *bool `default:"false" json:"enable"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `default:"24h" json:"maxDataTime"`
	// Data compression format. Default is gzip.
	Compress *PersistenceCompression `default:"gzip" json:"compress"`
}

func (d DiskSpooling) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSpooling) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DiskSpooling) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *DiskSpooling) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *DiskSpooling) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *DiskSpooling) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *DiskSpooling) GetCompress() *PersistenceCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumEdgePrometheus struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumEdgePrometheus) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumEdgePrometheus) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// AuthTypeAuthenticationMethodEdgePrometheus - Enter credentials directly, or select a stored secret
type AuthTypeAuthenticationMethodEdgePrometheus string

const (
	AuthTypeAuthenticationMethodEdgePrometheusManual     AuthTypeAuthenticationMethodEdgePrometheus = "manual"
	AuthTypeAuthenticationMethodEdgePrometheusSecret     AuthTypeAuthenticationMethodEdgePrometheus = "secret"
	AuthTypeAuthenticationMethodEdgePrometheusKubernetes AuthTypeAuthenticationMethodEdgePrometheus = "kubernetes"
)

func (e AuthTypeAuthenticationMethodEdgePrometheus) ToPointer() *AuthTypeAuthenticationMethodEdgePrometheus {
	return &e
}
func (e *AuthTypeAuthenticationMethodEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "kubernetes":
		*e = AuthTypeAuthenticationMethodEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthTypeAuthenticationMethodEdgePrometheus: %v", v)
	}
}

// TargetProtocol - Protocol to use when collecting metrics
type TargetProtocol string

const (
	TargetProtocolHTTP  TargetProtocol = "http"
	TargetProtocolHTTPS TargetProtocol = "https"
)

func (e TargetProtocol) ToPointer() *TargetProtocol {
	return &e
}
func (e *TargetProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = TargetProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TargetProtocol: %v", v)
	}
}

type Target struct {
	// Protocol to use when collecting metrics
	Protocol *TargetProtocol `default:"http" json:"protocol"`
	// Name of host from which to pull metrics.
	Host string `json:"host"`
	// The port number in the metrics URL for discovered targets.
	Port *float64 `default:"9090" json:"port"`
	// Path to use when collecting metrics from discovered targets
	Path *string `default:"/metrics" json:"path"`
}

func (t Target) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *Target) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Target) GetProtocol() *TargetProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *Target) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *Target) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *Target) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

// RecordTypeEdgePrometheus - DNS Record type to resolve
type RecordTypeEdgePrometheus string

const (
	RecordTypeEdgePrometheusSrv  RecordTypeEdgePrometheus = "SRV"
	RecordTypeEdgePrometheusA    RecordTypeEdgePrometheus = "A"
	RecordTypeEdgePrometheusAaaa RecordTypeEdgePrometheus = "AAAA"
)

func (e RecordTypeEdgePrometheus) ToPointer() *RecordTypeEdgePrometheus {
	return &e
}
func (e *RecordTypeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SRV":
		fallthrough
	case "A":
		fallthrough
	case "AAAA":
		*e = RecordTypeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RecordTypeEdgePrometheus: %v", v)
	}
}

// ScrapeProtocolProtocol - Protocol to use when collecting metrics
type ScrapeProtocolProtocol string

const (
	ScrapeProtocolProtocolHTTP  ScrapeProtocolProtocol = "http"
	ScrapeProtocolProtocolHTTPS ScrapeProtocolProtocol = "https"
)

func (e ScrapeProtocolProtocol) ToPointer() *ScrapeProtocolProtocol {
	return &e
}
func (e *ScrapeProtocolProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = ScrapeProtocolProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ScrapeProtocolProtocol: %v", v)
	}
}

type SearchFilterEdgePrometheus struct {
	// Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
	Name string `json:"Name"`
	// Search Filter Values, if empty only "running" EC2 instances will be returned
	Values []string `json:"Values"`
}

func (o *SearchFilterEdgePrometheus) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SearchFilterEdgePrometheus) GetValues() []string {
	if o == nil {
		return []string{}
	}
	return o.Values
}

// AwsAuthenticationMethodAuthenticationMethodEdgePrometheus - AWS authentication method. Choose Auto to use IAM roles.
type AwsAuthenticationMethodAuthenticationMethodEdgePrometheus string

const (
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusAuto   AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "auto"
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusManual AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "manual"
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusSecret AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "secret"
)

func (e AwsAuthenticationMethodAuthenticationMethodEdgePrometheus) ToPointer() *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus {
	return &e
}
func (e *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AwsAuthenticationMethodAuthenticationMethodEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AwsAuthenticationMethodAuthenticationMethodEdgePrometheus: %v", v)
	}
}

// SignatureVersionEdgePrometheus - Signature version to use for signing EC2 requests
type SignatureVersionEdgePrometheus string

const (
	SignatureVersionEdgePrometheusV2 SignatureVersionEdgePrometheus = "v2"
	SignatureVersionEdgePrometheusV4 SignatureVersionEdgePrometheus = "v4"
)

func (e SignatureVersionEdgePrometheus) ToPointer() *SignatureVersionEdgePrometheus {
	return &e
}
func (e *SignatureVersionEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersionEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersionEdgePrometheus: %v", v)
	}
}

type PodFilter struct {
	// JavaScript expression applied to pods objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *PodFilter) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *PodFilter) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputEdgePrometheus struct {
	// Unique ID for this input
	ID       string              `json:"id"`
	Type     *TypeEdgePrometheus `json:"type,omitempty"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionEdgePrometheus `json:"connections,omitempty"`
	Pq          *PqEdgePrometheus          `json:"pq,omitempty"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitempty"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *DiscoveryTypeEdgePrometheus `default:"static" json:"discoveryType"`
	// How often in seconds to scrape targets for metrics.
	Interval *float64 `default:"15" json:"interval"`
	// Timeout, in milliseconds, before aborting HTTP connection attempts; 1-60000 or 0 to disable
	Timeout     *float64      `default:"5000" json:"timeout"`
	Persistence *DiskSpooling `json:"persistence,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumEdgePrometheus `json:"metadata,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthTypeAuthenticationMethodEdgePrometheus `default:"manual" json:"authType"`
	Description *string                                     `json:"description,omitempty"`
	Targets     []Target                                    `json:"targets,omitempty"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitempty"`
	// DNS Record type to resolve
	RecordType *RecordTypeEdgePrometheus `default:"SRV" json:"recordType"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *ScrapeProtocolProtocol `default:"http" json:"scrapeProtocol"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `default:"/metrics" json:"scrapePath"`
	// Use public IP address for discovered targets. Set to false if the private IP address should be used.
	UsePublicIP *bool `default:"true" json:"usePublicIp"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `default:"9090" json:"scrapePort"`
	// EC2 Instance Search Filter
	SearchFilter []SearchFilterEdgePrometheus `json:"searchFilter,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                                    `json:"awsSecretKey,omitempty"`
	// Region where the EC2 is located
	Region *string `json:"region,omitempty"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *SignatureVersionEdgePrometheus `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Protocol to use when collecting metrics
	ScrapeProtocolExpr *string `default:"metadata.annotations['prometheus.io/scheme'] || 'http'" json:"scrapeProtocolExpr"`
	// The port number in the metrics URL for discovered targets.
	ScrapePortExpr *string `default:"metadata.annotations['prometheus.io/port'] || 9090" json:"scrapePortExpr"`
	// Path to use when collecting metrics from discovered targets
	ScrapePathExpr *string `default:"metadata.annotations['prometheus.io/path'] || '/metrics'" json:"scrapePathExpr"`
	//   Add rules to decide which pods to discover for metrics.
	//   Pods are searched if no rules are given or of all the rules'
	//   expressions evaluate to true.
	//
	PodFilter []PodFilter `json:"podFilter,omitempty"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputEdgePrometheus) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputEdgePrometheus) GetType() *TypeEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputEdgePrometheus) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputEdgePrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputEdgePrometheus) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputEdgePrometheus) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputEdgePrometheus) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputEdgePrometheus) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputEdgePrometheus) GetConnections() []ConnectionEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputEdgePrometheus) GetPq() *PqEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputEdgePrometheus) GetDimensionList() []string {
	if o == nil {
		return nil
	}
	return o.DimensionList
}

func (o *InputEdgePrometheus) GetDiscoveryType() *DiscoveryTypeEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.DiscoveryType
}

func (o *InputEdgePrometheus) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputEdgePrometheus) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputEdgePrometheus) GetPersistence() *DiskSpooling {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputEdgePrometheus) GetMetadata() []MetadatumEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputEdgePrometheus) GetAuthType() *AuthTypeAuthenticationMethodEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputEdgePrometheus) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputEdgePrometheus) GetTargets() []Target {
	if o == nil {
		return nil
	}
	return o.Targets
}

func (o *InputEdgePrometheus) GetNameList() []string {
	if o == nil {
		return nil
	}
	return o.NameList
}

func (o *InputEdgePrometheus) GetRecordType() *RecordTypeEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.RecordType
}

func (o *InputEdgePrometheus) GetScrapeProtocol() *ScrapeProtocolProtocol {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocol
}

func (o *InputEdgePrometheus) GetScrapePath() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePath
}

func (o *InputEdgePrometheus) GetUsePublicIP() *bool {
	if o == nil {
		return nil
	}
	return o.UsePublicIP
}

func (o *InputEdgePrometheus) GetScrapePort() *float64 {
	if o == nil {
		return nil
	}
	return o.ScrapePort
}

func (o *InputEdgePrometheus) GetSearchFilter() []SearchFilterEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.SearchFilter
}

func (o *InputEdgePrometheus) GetAwsAuthenticationMethod() *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputEdgePrometheus) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputEdgePrometheus) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputEdgePrometheus) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputEdgePrometheus) GetSignatureVersion() *SignatureVersionEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputEdgePrometheus) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputEdgePrometheus) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputEdgePrometheus) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputEdgePrometheus) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputEdgePrometheus) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputEdgePrometheus) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputEdgePrometheus) GetScrapeProtocolExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocolExpr
}

func (o *InputEdgePrometheus) GetScrapePortExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePortExpr
}

func (o *InputEdgePrometheus) GetScrapePathExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePathExpr
}

func (o *InputEdgePrometheus) GetPodFilter() []PodFilter {
	if o == nil {
		return nil
	}
	return o.PodFilter
}

func (o *InputEdgePrometheus) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputEdgePrometheus) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputEdgePrometheus) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

type CreateInputTypePrometheus string

const (
	CreateInputTypePrometheusPrometheus CreateInputTypePrometheus = "prometheus"
)

func (e CreateInputTypePrometheus) ToPointer() *CreateInputTypePrometheus {
	return &e
}
func (e *CreateInputTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus":
		*e = CreateInputTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypePrometheus: %v", v)
	}
}

type ConnectionPrometheus struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionPrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionPrometheus) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModePrometheus - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModePrometheus string

const (
	CreateInputModePrometheusSmart  CreateInputModePrometheus = "smart"
	CreateInputModePrometheusAlways CreateInputModePrometheus = "always"
)

func (e CreateInputModePrometheus) ToPointer() *CreateInputModePrometheus {
	return &e
}
func (e *CreateInputModePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModePrometheus: %v", v)
	}
}

// PqCompressionPrometheus - Codec to use to compress the persisted data
type PqCompressionPrometheus string

const (
	PqCompressionPrometheusNone PqCompressionPrometheus = "none"
	PqCompressionPrometheusGzip PqCompressionPrometheus = "gzip"
)

func (e PqCompressionPrometheus) ToPointer() *PqCompressionPrometheus {
	return &e
}
func (e *PqCompressionPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionPrometheus: %v", v)
	}
}

type PqPrometheus struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModePrometheus `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionPrometheus `default:"none" json:"compress"`
}

func (p PqPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqPrometheus) GetMode() *CreateInputModePrometheus {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqPrometheus) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqPrometheus) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqPrometheus) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqPrometheus) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqPrometheus) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqPrometheus) GetCompress() *PqCompressionPrometheus {
	if o == nil {
		return nil
	}
	return o.Compress
}

// DiscoveryTypePrometheus - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryTypePrometheus string

const (
	DiscoveryTypePrometheusStatic DiscoveryTypePrometheus = "static"
	DiscoveryTypePrometheusDNS    DiscoveryTypePrometheus = "dns"
	DiscoveryTypePrometheusEc2    DiscoveryTypePrometheus = "ec2"
)

func (e DiscoveryTypePrometheus) ToPointer() *DiscoveryTypePrometheus {
	return &e
}
func (e *DiscoveryTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "static":
		fallthrough
	case "dns":
		fallthrough
	case "ec2":
		*e = DiscoveryTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DiscoveryTypePrometheus: %v", v)
	}
}

// LogLevelPrometheus - Collector runtime Log Level
type LogLevelPrometheus string

const (
	LogLevelPrometheusError LogLevelPrometheus = "error"
	LogLevelPrometheusWarn  LogLevelPrometheus = "warn"
	LogLevelPrometheusInfo  LogLevelPrometheus = "info"
	LogLevelPrometheusDebug LogLevelPrometheus = "debug"
)

func (e LogLevelPrometheus) ToPointer() *LogLevelPrometheus {
	return &e
}
func (e *LogLevelPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = LogLevelPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelPrometheus: %v", v)
	}
}

type MetadatumPrometheus struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumPrometheus) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumPrometheus) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// AuthTypeAuthenticationMethodPrometheus - Enter credentials directly, or select a stored secret
type AuthTypeAuthenticationMethodPrometheus string

const (
	AuthTypeAuthenticationMethodPrometheusManual AuthTypeAuthenticationMethodPrometheus = "manual"
	AuthTypeAuthenticationMethodPrometheusSecret AuthTypeAuthenticationMethodPrometheus = "secret"
)

func (e AuthTypeAuthenticationMethodPrometheus) ToPointer() *AuthTypeAuthenticationMethodPrometheus {
	return &e
}
func (e *AuthTypeAuthenticationMethodPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthTypeAuthenticationMethodPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthTypeAuthenticationMethodPrometheus: %v", v)
	}
}

// RecordTypePrometheus - DNS Record type to resolve
type RecordTypePrometheus string

const (
	RecordTypePrometheusSrv  RecordTypePrometheus = "SRV"
	RecordTypePrometheusA    RecordTypePrometheus = "A"
	RecordTypePrometheusAaaa RecordTypePrometheus = "AAAA"
)

func (e RecordTypePrometheus) ToPointer() *RecordTypePrometheus {
	return &e
}
func (e *RecordTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SRV":
		fallthrough
	case "A":
		fallthrough
	case "AAAA":
		*e = RecordTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RecordTypePrometheus: %v", v)
	}
}

// MetricsProtocol - Protocol to use when collecting metrics
type MetricsProtocol string

const (
	MetricsProtocolHTTP  MetricsProtocol = "http"
	MetricsProtocolHTTPS MetricsProtocol = "https"
)

func (e MetricsProtocol) ToPointer() *MetricsProtocol {
	return &e
}
func (e *MetricsProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = MetricsProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MetricsProtocol: %v", v)
	}
}

type SearchFilterPrometheus struct {
	// Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
	Name string `json:"Name"`
	// Search Filter Values, if empty only "running" EC2 instances will be returned
	Values []string `json:"Values"`
}

func (o *SearchFilterPrometheus) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SearchFilterPrometheus) GetValues() []string {
	if o == nil {
		return []string{}
	}
	return o.Values
}

// AwsAuthenticationMethodAuthenticationMethodPrometheus - AWS authentication method. Choose Auto to use IAM roles.
type AwsAuthenticationMethodAuthenticationMethodPrometheus string

const (
	AwsAuthenticationMethodAuthenticationMethodPrometheusAuto   AwsAuthenticationMethodAuthenticationMethodPrometheus = "auto"
	AwsAuthenticationMethodAuthenticationMethodPrometheusManual AwsAuthenticationMethodAuthenticationMethodPrometheus = "manual"
	AwsAuthenticationMethodAuthenticationMethodPrometheusSecret AwsAuthenticationMethodAuthenticationMethodPrometheus = "secret"
)

func (e AwsAuthenticationMethodAuthenticationMethodPrometheus) ToPointer() *AwsAuthenticationMethodAuthenticationMethodPrometheus {
	return &e
}
func (e *AwsAuthenticationMethodAuthenticationMethodPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AwsAuthenticationMethodAuthenticationMethodPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AwsAuthenticationMethodAuthenticationMethodPrometheus: %v", v)
	}
}

// SignatureVersionPrometheus - Signature version to use for signing EC2 requests
type SignatureVersionPrometheus string

const (
	SignatureVersionPrometheusV2 SignatureVersionPrometheus = "v2"
	SignatureVersionPrometheusV4 SignatureVersionPrometheus = "v4"
)

func (e SignatureVersionPrometheus) ToPointer() *SignatureVersionPrometheus {
	return &e
}
func (e *SignatureVersionPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersionPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersionPrometheus: %v", v)
	}
}

type InputPrometheus struct {
	// Unique ID for this input
	ID       string                     `json:"id"`
	Type     *CreateInputTypePrometheus `json:"type,omitempty"`
	Disabled *bool                      `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionPrometheus `json:"connections,omitempty"`
	Pq          *PqPrometheus          `json:"pq,omitempty"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitempty"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *DiscoveryTypePrometheus `default:"static" json:"discoveryType"`
	// How often in minutes to scrape targets for metrics, 60 must be evenly divisible by the value or save will fail.
	Interval *float64 `default:"15" json:"interval"`
	// Collector runtime Log Level
	LogLevel *LogLevelPrometheus `default:"info" json:"logLevel"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata []MetadatumPrometheus `json:"metadata,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthTypeAuthenticationMethodPrometheus `default:"manual" json:"authType"`
	Description *string                                 `json:"description,omitempty"`
	// List of Prometheus targets to pull metrics from. Values can be in URL or host[:port] format. For example: http://localhost:9090/metrics, localhost:9090, or localhost. In cases where just host[:port] is specified, the endpoint will resolve to 'http://host[:port]/metrics'.
	TargetList []string `json:"targetList,omitempty"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitempty"`
	// DNS Record type to resolve
	RecordType *RecordTypePrometheus `default:"SRV" json:"recordType"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *MetricsProtocol `default:"http" json:"scrapeProtocol"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `default:"/metrics" json:"scrapePath"`
	// Use public IP address for discovered targets. Set to false if the private IP address should be used.
	UsePublicIP *bool `default:"true" json:"usePublicIp"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `default:"9090" json:"scrapePort"`
	// EC2 Instance Search Filter
	SearchFilter []SearchFilterPrometheus `json:"searchFilter,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AwsAuthenticationMethodAuthenticationMethodPrometheus `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// Region where the EC2 is located
	Region *string `json:"region,omitempty"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *SignatureVersionPrometheus `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheus) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputPrometheus) GetType() *CreateInputTypePrometheus {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputPrometheus) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputPrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputPrometheus) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputPrometheus) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputPrometheus) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputPrometheus) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputPrometheus) GetConnections() []ConnectionPrometheus {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputPrometheus) GetPq() *PqPrometheus {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputPrometheus) GetDimensionList() []string {
	if o == nil {
		return nil
	}
	return o.DimensionList
}

func (o *InputPrometheus) GetDiscoveryType() *DiscoveryTypePrometheus {
	if o == nil {
		return nil
	}
	return o.DiscoveryType
}

func (o *InputPrometheus) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputPrometheus) GetLogLevel() *LogLevelPrometheus {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputPrometheus) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputPrometheus) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputPrometheus) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputPrometheus) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputPrometheus) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputPrometheus) GetIgnoreGroupJobsLimit() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreGroupJobsLimit
}

func (o *InputPrometheus) GetMetadata() []MetadatumPrometheus {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputPrometheus) GetAuthType() *AuthTypeAuthenticationMethodPrometheus {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputPrometheus) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputPrometheus) GetTargetList() []string {
	if o == nil {
		return nil
	}
	return o.TargetList
}

func (o *InputPrometheus) GetNameList() []string {
	if o == nil {
		return nil
	}
	return o.NameList
}

func (o *InputPrometheus) GetRecordType() *RecordTypePrometheus {
	if o == nil {
		return nil
	}
	return o.RecordType
}

func (o *InputPrometheus) GetScrapeProtocol() *MetricsProtocol {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocol
}

func (o *InputPrometheus) GetScrapePath() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePath
}

func (o *InputPrometheus) GetUsePublicIP() *bool {
	if o == nil {
		return nil
	}
	return o.UsePublicIP
}

func (o *InputPrometheus) GetScrapePort() *float64 {
	if o == nil {
		return nil
	}
	return o.ScrapePort
}

func (o *InputPrometheus) GetSearchFilter() []SearchFilterPrometheus {
	if o == nil {
		return nil
	}
	return o.SearchFilter
}

func (o *InputPrometheus) GetAwsAuthenticationMethod() *AwsAuthenticationMethodAuthenticationMethodPrometheus {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputPrometheus) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputPrometheus) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputPrometheus) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputPrometheus) GetSignatureVersion() *SignatureVersionPrometheus {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputPrometheus) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputPrometheus) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputPrometheus) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputPrometheus) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputPrometheus) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputPrometheus) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputPrometheus) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputPrometheus) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

type TypePrometheusRw string

const (
	TypePrometheusRwPrometheusRw TypePrometheusRw = "prometheus_rw"
)

func (e TypePrometheusRw) ToPointer() *TypePrometheusRw {
	return &e
}
func (e *TypePrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus_rw":
		*e = TypePrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypePrometheusRw: %v", v)
	}
}

type ConnectionPrometheusRw struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionPrometheusRw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionPrometheusRw) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModePrometheusRw - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModePrometheusRw string

const (
	ModePrometheusRwSmart  ModePrometheusRw = "smart"
	ModePrometheusRwAlways ModePrometheusRw = "always"
)

func (e ModePrometheusRw) ToPointer() *ModePrometheusRw {
	return &e
}
func (e *ModePrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModePrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModePrometheusRw: %v", v)
	}
}

// CompressionPrometheusRw - Codec to use to compress the persisted data
type CompressionPrometheusRw string

const (
	CompressionPrometheusRwNone CompressionPrometheusRw = "none"
	CompressionPrometheusRwGzip CompressionPrometheusRw = "gzip"
)

func (e CompressionPrometheusRw) ToPointer() *CompressionPrometheusRw {
	return &e
}
func (e *CompressionPrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionPrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionPrometheusRw: %v", v)
	}
}

type PqPrometheusRw struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModePrometheusRw `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionPrometheusRw `default:"none" json:"compress"`
}

func (p PqPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqPrometheusRw) GetMode() *ModePrometheusRw {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqPrometheusRw) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqPrometheusRw) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqPrometheusRw) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqPrometheusRw) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqPrometheusRw) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqPrometheusRw) GetCompress() *CompressionPrometheusRw {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionPrometheusRw string

const (
	MinimumTLSVersionPrometheusRwTlSv1  MinimumTLSVersionPrometheusRw = "TLSv1"
	MinimumTLSVersionPrometheusRwTlSv11 MinimumTLSVersionPrometheusRw = "TLSv1.1"
	MinimumTLSVersionPrometheusRwTlSv12 MinimumTLSVersionPrometheusRw = "TLSv1.2"
	MinimumTLSVersionPrometheusRwTlSv13 MinimumTLSVersionPrometheusRw = "TLSv1.3"
)

func (e MinimumTLSVersionPrometheusRw) ToPointer() *MinimumTLSVersionPrometheusRw {
	return &e
}
func (e *MinimumTLSVersionPrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionPrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionPrometheusRw: %v", v)
	}
}

type MaximumTLSVersionPrometheusRw string

const (
	MaximumTLSVersionPrometheusRwTlSv1  MaximumTLSVersionPrometheusRw = "TLSv1"
	MaximumTLSVersionPrometheusRwTlSv11 MaximumTLSVersionPrometheusRw = "TLSv1.1"
	MaximumTLSVersionPrometheusRwTlSv12 MaximumTLSVersionPrometheusRw = "TLSv1.2"
	MaximumTLSVersionPrometheusRwTlSv13 MaximumTLSVersionPrometheusRw = "TLSv1.3"
)

func (e MaximumTLSVersionPrometheusRw) ToPointer() *MaximumTLSVersionPrometheusRw {
	return &e
}
func (e *MaximumTLSVersionPrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionPrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionPrometheusRw: %v", v)
	}
}

type TLSSettingsServerSidePrometheusRw struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                          `default:"false" json:"requestCert"`
	RejectUnauthorized any                            `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                            `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionPrometheusRw `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionPrometheusRw `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSidePrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSidePrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSidePrometheusRw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSidePrometheusRw) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSidePrometheusRw) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSidePrometheusRw) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSidePrometheusRw) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSidePrometheusRw) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSidePrometheusRw) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSidePrometheusRw) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSidePrometheusRw) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSidePrometheusRw) GetMinVersion() *MinimumTLSVersionPrometheusRw {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSidePrometheusRw) GetMaxVersion() *MaximumTLSVersionPrometheusRw {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// AuthenticationTypePrometheusRw - Remote Write authentication type
type AuthenticationTypePrometheusRw string

const (
	AuthenticationTypePrometheusRwNone              AuthenticationTypePrometheusRw = "none"
	AuthenticationTypePrometheusRwBasic             AuthenticationTypePrometheusRw = "basic"
	AuthenticationTypePrometheusRwCredentialsSecret AuthenticationTypePrometheusRw = "credentialsSecret"
	AuthenticationTypePrometheusRwToken             AuthenticationTypePrometheusRw = "token"
	AuthenticationTypePrometheusRwTextSecret        AuthenticationTypePrometheusRw = "textSecret"
	AuthenticationTypePrometheusRwOauth             AuthenticationTypePrometheusRw = "oauth"
)

func (e AuthenticationTypePrometheusRw) ToPointer() *AuthenticationTypePrometheusRw {
	return &e
}
func (e *AuthenticationTypePrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = AuthenticationTypePrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationTypePrometheusRw: %v", v)
	}
}

type MetadatumPrometheusRw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumPrometheusRw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumPrometheusRw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthParamPrometheusRw struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OauthParamPrometheusRw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamPrometheusRw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderPrometheusRw struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OauthHeaderPrometheusRw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderPrometheusRw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputPrometheusRw struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     *TypePrometheusRw `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionPrometheusRw `json:"connections,omitempty"`
	Pq          *PqPrometheusRw          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *TLSSettingsServerSidePrometheusRw `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Prometheus requests. Defaults to /write, which will expand as: http://<your‑upstream‑URL>:<your‑port>/write.
	PrometheusAPI *string `default:"/write" json:"prometheusAPI"`
	// Remote Write authentication type
	AuthType *AuthenticationTypePrometheusRw `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata    []MetadatumPrometheusRw `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Username    *string                 `json:"username,omitempty"`
	Password    *string                 `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamPrometheusRw `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OauthHeaderPrometheusRw `json:"oauthHeaders,omitempty"`
}

func (i InputPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheusRw) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputPrometheusRw) GetType() *TypePrometheusRw {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputPrometheusRw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputPrometheusRw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputPrometheusRw) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputPrometheusRw) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputPrometheusRw) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputPrometheusRw) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputPrometheusRw) GetConnections() []ConnectionPrometheusRw {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputPrometheusRw) GetPq() *PqPrometheusRw {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputPrometheusRw) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputPrometheusRw) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputPrometheusRw) GetTLS() *TLSSettingsServerSidePrometheusRw {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputPrometheusRw) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputPrometheusRw) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputPrometheusRw) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputPrometheusRw) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputPrometheusRw) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputPrometheusRw) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputPrometheusRw) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputPrometheusRw) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputPrometheusRw) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputPrometheusRw) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputPrometheusRw) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputPrometheusRw) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputPrometheusRw) GetAuthType() *AuthenticationTypePrometheusRw {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputPrometheusRw) GetMetadata() []MetadatumPrometheusRw {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputPrometheusRw) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputPrometheusRw) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputPrometheusRw) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputPrometheusRw) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputPrometheusRw) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputPrometheusRw) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputPrometheusRw) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputPrometheusRw) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputPrometheusRw) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputPrometheusRw) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputPrometheusRw) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputPrometheusRw) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputPrometheusRw) GetOauthParams() []OauthParamPrometheusRw {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputPrometheusRw) GetOauthHeaders() []OauthHeaderPrometheusRw {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type CreateInputTypeLoki string

const (
	CreateInputTypeLokiLoki CreateInputTypeLoki = "loki"
)

func (e CreateInputTypeLoki) ToPointer() *CreateInputTypeLoki {
	return &e
}
func (e *CreateInputTypeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "loki":
		*e = CreateInputTypeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeLoki: %v", v)
	}
}

type ConnectionLoki struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionLoki) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionLoki) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeLoki - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeLoki string

const (
	CreateInputModeLokiSmart  CreateInputModeLoki = "smart"
	CreateInputModeLokiAlways CreateInputModeLoki = "always"
)

func (e CreateInputModeLoki) ToPointer() *CreateInputModeLoki {
	return &e
}
func (e *CreateInputModeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeLoki: %v", v)
	}
}

// PqCompressionLoki - Codec to use to compress the persisted data
type PqCompressionLoki string

const (
	PqCompressionLokiNone PqCompressionLoki = "none"
	PqCompressionLokiGzip PqCompressionLoki = "gzip"
)

func (e PqCompressionLoki) ToPointer() *PqCompressionLoki {
	return &e
}
func (e *PqCompressionLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionLoki: %v", v)
	}
}

type PqLoki struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeLoki `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionLoki `default:"none" json:"compress"`
}

func (p PqLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqLoki) GetMode() *CreateInputModeLoki {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqLoki) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqLoki) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqLoki) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqLoki) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqLoki) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqLoki) GetCompress() *PqCompressionLoki {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionLoki string

const (
	MinimumTLSVersionLokiTlSv1  MinimumTLSVersionLoki = "TLSv1"
	MinimumTLSVersionLokiTlSv11 MinimumTLSVersionLoki = "TLSv1.1"
	MinimumTLSVersionLokiTlSv12 MinimumTLSVersionLoki = "TLSv1.2"
	MinimumTLSVersionLokiTlSv13 MinimumTLSVersionLoki = "TLSv1.3"
)

func (e MinimumTLSVersionLoki) ToPointer() *MinimumTLSVersionLoki {
	return &e
}
func (e *MinimumTLSVersionLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionLoki: %v", v)
	}
}

type MaximumTLSVersionLoki string

const (
	MaximumTLSVersionLokiTlSv1  MaximumTLSVersionLoki = "TLSv1"
	MaximumTLSVersionLokiTlSv11 MaximumTLSVersionLoki = "TLSv1.1"
	MaximumTLSVersionLokiTlSv12 MaximumTLSVersionLoki = "TLSv1.2"
	MaximumTLSVersionLokiTlSv13 MaximumTLSVersionLoki = "TLSv1.3"
)

func (e MaximumTLSVersionLoki) ToPointer() *MaximumTLSVersionLoki {
	return &e
}
func (e *MaximumTLSVersionLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionLoki: %v", v)
	}
}

type TLSSettingsServerSideLoki struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                  `default:"false" json:"requestCert"`
	RejectUnauthorized any                    `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                    `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionLoki `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionLoki `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideLoki) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideLoki) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideLoki) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideLoki) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideLoki) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideLoki) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideLoki) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideLoki) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideLoki) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideLoki) GetMinVersion() *MinimumTLSVersionLoki {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideLoki) GetMaxVersion() *MaximumTLSVersionLoki {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// CreateInputAuthenticationTypeLoki - Loki logs authentication type
type CreateInputAuthenticationTypeLoki string

const (
	CreateInputAuthenticationTypeLokiNone              CreateInputAuthenticationTypeLoki = "none"
	CreateInputAuthenticationTypeLokiBasic             CreateInputAuthenticationTypeLoki = "basic"
	CreateInputAuthenticationTypeLokiCredentialsSecret CreateInputAuthenticationTypeLoki = "credentialsSecret"
	CreateInputAuthenticationTypeLokiToken             CreateInputAuthenticationTypeLoki = "token"
	CreateInputAuthenticationTypeLokiTextSecret        CreateInputAuthenticationTypeLoki = "textSecret"
	CreateInputAuthenticationTypeLokiOauth             CreateInputAuthenticationTypeLoki = "oauth"
)

func (e CreateInputAuthenticationTypeLoki) ToPointer() *CreateInputAuthenticationTypeLoki {
	return &e
}
func (e *CreateInputAuthenticationTypeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = CreateInputAuthenticationTypeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAuthenticationTypeLoki: %v", v)
	}
}

type MetadatumLoki struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumLoki) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumLoki) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthParamLoki struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OauthParamLoki) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamLoki) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderLoki struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OauthHeaderLoki) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderLoki) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputLoki struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     *CreateInputTypeLoki `json:"type,omitempty"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionLoki `json:"connections,omitempty"`
	Pq          *PqLoki          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                    `json:"port"`
	TLS  *TLSSettingsServerSideLoki `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<your‑upstream‑URL>:<your‑port>/loki/api/v1/push'.
	LokiAPI *string `default:"/loki/api/v1/push" json:"lokiAPI"`
	// Loki logs authentication type
	AuthType *CreateInputAuthenticationTypeLoki `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata    []MetadatumLoki `json:"metadata,omitempty"`
	Description *string         `json:"description,omitempty"`
	Username    *string         `json:"username,omitempty"`
	Password    *string         `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamLoki `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OauthHeaderLoki `json:"oauthHeaders,omitempty"`
}

func (i InputLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputLoki) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputLoki) GetType() *CreateInputTypeLoki {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputLoki) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputLoki) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputLoki) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputLoki) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputLoki) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputLoki) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputLoki) GetConnections() []ConnectionLoki {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputLoki) GetPq() *PqLoki {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputLoki) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputLoki) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputLoki) GetTLS() *TLSSettingsServerSideLoki {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputLoki) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputLoki) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputLoki) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputLoki) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputLoki) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputLoki) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputLoki) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputLoki) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputLoki) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputLoki) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputLoki) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputLoki) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputLoki) GetAuthType() *CreateInputAuthenticationTypeLoki {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputLoki) GetMetadata() []MetadatumLoki {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputLoki) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputLoki) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputLoki) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputLoki) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputLoki) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputLoki) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputLoki) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputLoki) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputLoki) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputLoki) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputLoki) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputLoki) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputLoki) GetOauthParams() []OauthParamLoki {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputLoki) GetOauthHeaders() []OauthHeaderLoki {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type InputGrafanaType2 string

const (
	InputGrafanaType2Grafana InputGrafanaType2 = "grafana"
)

func (e InputGrafanaType2) ToPointer() *InputGrafanaType2 {
	return &e
}
func (e *InputGrafanaType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType2: %v", v)
	}
}

type InputGrafanaConnection2 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputGrafanaConnection2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaConnection2) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputGrafanaMode2 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputGrafanaMode2 string

const (
	InputGrafanaMode2Smart  InputGrafanaMode2 = "smart"
	InputGrafanaMode2Always InputGrafanaMode2 = "always"
)

func (e InputGrafanaMode2) ToPointer() *InputGrafanaMode2 {
	return &e
}
func (e *InputGrafanaMode2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputGrafanaMode2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMode2: %v", v)
	}
}

// InputGrafanaCompression2 - Codec to use to compress the persisted data
type InputGrafanaCompression2 string

const (
	InputGrafanaCompression2None InputGrafanaCompression2 = "none"
	InputGrafanaCompression2Gzip InputGrafanaCompression2 = "gzip"
)

func (e InputGrafanaCompression2) ToPointer() *InputGrafanaCompression2 {
	return &e
}
func (e *InputGrafanaCompression2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputGrafanaCompression2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaCompression2: %v", v)
	}
}

type InputGrafanaPq2 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputGrafanaMode2 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputGrafanaCompression2 `default:"none" json:"compress"`
}

func (i InputGrafanaPq2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPq2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaPq2) GetMode() *InputGrafanaMode2 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputGrafanaPq2) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputGrafanaPq2) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputGrafanaPq2) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputGrafanaPq2) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputGrafanaPq2) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputGrafanaPq2) GetCompress() *InputGrafanaCompression2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputGrafanaMinimumTLSVersion2 string

const (
	InputGrafanaMinimumTLSVersion2TlSv1  InputGrafanaMinimumTLSVersion2 = "TLSv1"
	InputGrafanaMinimumTLSVersion2TlSv11 InputGrafanaMinimumTLSVersion2 = "TLSv1.1"
	InputGrafanaMinimumTLSVersion2TlSv12 InputGrafanaMinimumTLSVersion2 = "TLSv1.2"
	InputGrafanaMinimumTLSVersion2TlSv13 InputGrafanaMinimumTLSVersion2 = "TLSv1.3"
)

func (e InputGrafanaMinimumTLSVersion2) ToPointer() *InputGrafanaMinimumTLSVersion2 {
	return &e
}
func (e *InputGrafanaMinimumTLSVersion2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMinimumTLSVersion2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMinimumTLSVersion2: %v", v)
	}
}

type InputGrafanaMaximumTLSVersion2 string

const (
	InputGrafanaMaximumTLSVersion2TlSv1  InputGrafanaMaximumTLSVersion2 = "TLSv1"
	InputGrafanaMaximumTLSVersion2TlSv11 InputGrafanaMaximumTLSVersion2 = "TLSv1.1"
	InputGrafanaMaximumTLSVersion2TlSv12 InputGrafanaMaximumTLSVersion2 = "TLSv1.2"
	InputGrafanaMaximumTLSVersion2TlSv13 InputGrafanaMaximumTLSVersion2 = "TLSv1.3"
)

func (e InputGrafanaMaximumTLSVersion2) ToPointer() *InputGrafanaMaximumTLSVersion2 {
	return &e
}
func (e *InputGrafanaMaximumTLSVersion2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMaximumTLSVersion2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMaximumTLSVersion2: %v", v)
	}
}

type InputGrafanaTLSSettingsServerSide2 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                           `default:"false" json:"requestCert"`
	RejectUnauthorized any                             `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                             `json:"commonNameRegex,omitempty"`
	MinVersion         *InputGrafanaMinimumTLSVersion2 `json:"minVersion,omitempty"`
	MaxVersion         *InputGrafanaMaximumTLSVersion2 `json:"maxVersion,omitempty"`
}

func (i InputGrafanaTLSSettingsServerSide2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaTLSSettingsServerSide2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaTLSSettingsServerSide2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaTLSSettingsServerSide2) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputGrafanaTLSSettingsServerSide2) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputGrafanaTLSSettingsServerSide2) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputGrafanaTLSSettingsServerSide2) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputGrafanaTLSSettingsServerSide2) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputGrafanaTLSSettingsServerSide2) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputGrafanaTLSSettingsServerSide2) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputGrafanaTLSSettingsServerSide2) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputGrafanaTLSSettingsServerSide2) GetMinVersion() *InputGrafanaMinimumTLSVersion2 {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputGrafanaTLSSettingsServerSide2) GetMaxVersion() *InputGrafanaMaximumTLSVersion2 {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// PrometheusAuthAuthenticationType2 - Remote Write authentication type
type PrometheusAuthAuthenticationType2 string

const (
	PrometheusAuthAuthenticationType2None              PrometheusAuthAuthenticationType2 = "none"
	PrometheusAuthAuthenticationType2Basic             PrometheusAuthAuthenticationType2 = "basic"
	PrometheusAuthAuthenticationType2CredentialsSecret PrometheusAuthAuthenticationType2 = "credentialsSecret"
	PrometheusAuthAuthenticationType2Token             PrometheusAuthAuthenticationType2 = "token"
	PrometheusAuthAuthenticationType2TextSecret        PrometheusAuthAuthenticationType2 = "textSecret"
	PrometheusAuthAuthenticationType2Oauth             PrometheusAuthAuthenticationType2 = "oauth"
)

func (e PrometheusAuthAuthenticationType2) ToPointer() *PrometheusAuthAuthenticationType2 {
	return &e
}
func (e *PrometheusAuthAuthenticationType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = PrometheusAuthAuthenticationType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PrometheusAuthAuthenticationType2: %v", v)
	}
}

type PrometheusAuthOauthParam2 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *PrometheusAuthOauthParam2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *PrometheusAuthOauthParam2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PrometheusAuthOauthHeader2 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *PrometheusAuthOauthHeader2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *PrometheusAuthOauthHeader2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PrometheusAuth2 struct {
	// Remote Write authentication type
	AuthType *PrometheusAuthAuthenticationType2 `default:"none" json:"authType"`
	Username *string                            `json:"username,omitempty"`
	Password *string                            `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []PrometheusAuthOauthParam2 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []PrometheusAuthOauthHeader2 `json:"oauthHeaders,omitempty"`
}

func (p PrometheusAuth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PrometheusAuth2) GetAuthType() *PrometheusAuthAuthenticationType2 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *PrometheusAuth2) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *PrometheusAuth2) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *PrometheusAuth2) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *PrometheusAuth2) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *PrometheusAuth2) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *PrometheusAuth2) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *PrometheusAuth2) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *PrometheusAuth2) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *PrometheusAuth2) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *PrometheusAuth2) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *PrometheusAuth2) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *PrometheusAuth2) GetOauthParams() []PrometheusAuthOauthParam2 {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *PrometheusAuth2) GetOauthHeaders() []PrometheusAuthOauthHeader2 {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

// LokiAuthAuthenticationType2 - Loki logs authentication type
type LokiAuthAuthenticationType2 string

const (
	LokiAuthAuthenticationType2None              LokiAuthAuthenticationType2 = "none"
	LokiAuthAuthenticationType2Basic             LokiAuthAuthenticationType2 = "basic"
	LokiAuthAuthenticationType2CredentialsSecret LokiAuthAuthenticationType2 = "credentialsSecret"
	LokiAuthAuthenticationType2Token             LokiAuthAuthenticationType2 = "token"
	LokiAuthAuthenticationType2TextSecret        LokiAuthAuthenticationType2 = "textSecret"
	LokiAuthAuthenticationType2Oauth             LokiAuthAuthenticationType2 = "oauth"
)

func (e LokiAuthAuthenticationType2) ToPointer() *LokiAuthAuthenticationType2 {
	return &e
}
func (e *LokiAuthAuthenticationType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = LokiAuthAuthenticationType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LokiAuthAuthenticationType2: %v", v)
	}
}

type LokiAuthOauthParam2 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *LokiAuthOauthParam2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *LokiAuthOauthParam2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type LokiAuthOauthHeader2 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *LokiAuthOauthHeader2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *LokiAuthOauthHeader2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type LokiAuth2 struct {
	// Loki logs authentication type
	AuthType *LokiAuthAuthenticationType2 `default:"none" json:"authType"`
	Username *string                      `json:"username,omitempty"`
	Password *string                      `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []LokiAuthOauthParam2 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []LokiAuthOauthHeader2 `json:"oauthHeaders,omitempty"`
}

func (l LokiAuth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *LokiAuth2) GetAuthType() *LokiAuthAuthenticationType2 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *LokiAuth2) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *LokiAuth2) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *LokiAuth2) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *LokiAuth2) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *LokiAuth2) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *LokiAuth2) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *LokiAuth2) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *LokiAuth2) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *LokiAuth2) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *LokiAuth2) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *LokiAuth2) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *LokiAuth2) GetOauthParams() []LokiAuthOauthParam2 {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *LokiAuth2) GetOauthHeaders() []LokiAuthOauthHeader2 {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type InputGrafanaMetadatum2 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputGrafanaMetadatum2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputGrafanaMetadatum2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafanaGrafana2 struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     *InputGrafanaType2 `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputGrafanaConnection2 `json:"connections,omitempty"`
	Pq          *InputGrafanaPq2          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                             `json:"port"`
	TLS  *InputGrafanaTLSSettingsServerSide2 `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<your‑upstream‑URL>:<your‑port>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `default:"/api/prom/push" json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<your‑upstream‑URL>:<your‑port>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string          `default:"/loki/api/v1/push" json:"lokiAPI"`
	PrometheusAuth *PrometheusAuth2 `json:"prometheusAuth,omitempty"`
	LokiAuth       *LokiAuth2       `json:"lokiAuth,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputGrafanaMetadatum2 `json:"metadata,omitempty"`
	Description *string                  `json:"description,omitempty"`
}

func (i InputGrafanaGrafana2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaGrafana2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaGrafana2) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputGrafanaGrafana2) GetType() *InputGrafanaType2 {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGrafanaGrafana2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaGrafana2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaGrafana2) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGrafanaGrafana2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGrafanaGrafana2) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGrafanaGrafana2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGrafanaGrafana2) GetConnections() []InputGrafanaConnection2 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGrafanaGrafana2) GetPq() *InputGrafanaPq2 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGrafanaGrafana2) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputGrafanaGrafana2) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputGrafanaGrafana2) GetTLS() *InputGrafanaTLSSettingsServerSide2 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputGrafanaGrafana2) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputGrafanaGrafana2) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputGrafanaGrafana2) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputGrafanaGrafana2) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputGrafanaGrafana2) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputGrafanaGrafana2) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGrafanaGrafana2) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputGrafanaGrafana2) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputGrafanaGrafana2) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputGrafanaGrafana2) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputGrafanaGrafana2) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputGrafanaGrafana2) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputGrafanaGrafana2) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputGrafanaGrafana2) GetPrometheusAuth() *PrometheusAuth2 {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *InputGrafanaGrafana2) GetLokiAuth() *LokiAuth2 {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *InputGrafanaGrafana2) GetMetadata() []InputGrafanaMetadatum2 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGrafanaGrafana2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputGrafanaType1 string

const (
	InputGrafanaType1Grafana InputGrafanaType1 = "grafana"
)

func (e InputGrafanaType1) ToPointer() *InputGrafanaType1 {
	return &e
}
func (e *InputGrafanaType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType1: %v", v)
	}
}

type InputGrafanaConnection1 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputGrafanaConnection1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaConnection1) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputGrafanaMode1 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputGrafanaMode1 string

const (
	InputGrafanaMode1Smart  InputGrafanaMode1 = "smart"
	InputGrafanaMode1Always InputGrafanaMode1 = "always"
)

func (e InputGrafanaMode1) ToPointer() *InputGrafanaMode1 {
	return &e
}
func (e *InputGrafanaMode1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputGrafanaMode1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMode1: %v", v)
	}
}

// InputGrafanaCompression1 - Codec to use to compress the persisted data
type InputGrafanaCompression1 string

const (
	InputGrafanaCompression1None InputGrafanaCompression1 = "none"
	InputGrafanaCompression1Gzip InputGrafanaCompression1 = "gzip"
)

func (e InputGrafanaCompression1) ToPointer() *InputGrafanaCompression1 {
	return &e
}
func (e *InputGrafanaCompression1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputGrafanaCompression1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaCompression1: %v", v)
	}
}

type InputGrafanaPq1 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputGrafanaMode1 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputGrafanaCompression1 `default:"none" json:"compress"`
}

func (i InputGrafanaPq1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPq1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaPq1) GetMode() *InputGrafanaMode1 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputGrafanaPq1) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputGrafanaPq1) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputGrafanaPq1) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputGrafanaPq1) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputGrafanaPq1) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputGrafanaPq1) GetCompress() *InputGrafanaCompression1 {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputGrafanaMinimumTLSVersion1 string

const (
	InputGrafanaMinimumTLSVersion1TlSv1  InputGrafanaMinimumTLSVersion1 = "TLSv1"
	InputGrafanaMinimumTLSVersion1TlSv11 InputGrafanaMinimumTLSVersion1 = "TLSv1.1"
	InputGrafanaMinimumTLSVersion1TlSv12 InputGrafanaMinimumTLSVersion1 = "TLSv1.2"
	InputGrafanaMinimumTLSVersion1TlSv13 InputGrafanaMinimumTLSVersion1 = "TLSv1.3"
)

func (e InputGrafanaMinimumTLSVersion1) ToPointer() *InputGrafanaMinimumTLSVersion1 {
	return &e
}
func (e *InputGrafanaMinimumTLSVersion1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMinimumTLSVersion1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMinimumTLSVersion1: %v", v)
	}
}

type InputGrafanaMaximumTLSVersion1 string

const (
	InputGrafanaMaximumTLSVersion1TlSv1  InputGrafanaMaximumTLSVersion1 = "TLSv1"
	InputGrafanaMaximumTLSVersion1TlSv11 InputGrafanaMaximumTLSVersion1 = "TLSv1.1"
	InputGrafanaMaximumTLSVersion1TlSv12 InputGrafanaMaximumTLSVersion1 = "TLSv1.2"
	InputGrafanaMaximumTLSVersion1TlSv13 InputGrafanaMaximumTLSVersion1 = "TLSv1.3"
)

func (e InputGrafanaMaximumTLSVersion1) ToPointer() *InputGrafanaMaximumTLSVersion1 {
	return &e
}
func (e *InputGrafanaMaximumTLSVersion1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMaximumTLSVersion1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMaximumTLSVersion1: %v", v)
	}
}

type InputGrafanaTLSSettingsServerSide1 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                           `default:"false" json:"requestCert"`
	RejectUnauthorized any                             `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                             `json:"commonNameRegex,omitempty"`
	MinVersion         *InputGrafanaMinimumTLSVersion1 `json:"minVersion,omitempty"`
	MaxVersion         *InputGrafanaMaximumTLSVersion1 `json:"maxVersion,omitempty"`
}

func (i InputGrafanaTLSSettingsServerSide1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaTLSSettingsServerSide1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaTLSSettingsServerSide1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaTLSSettingsServerSide1) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputGrafanaTLSSettingsServerSide1) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputGrafanaTLSSettingsServerSide1) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputGrafanaTLSSettingsServerSide1) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputGrafanaTLSSettingsServerSide1) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputGrafanaTLSSettingsServerSide1) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputGrafanaTLSSettingsServerSide1) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputGrafanaTLSSettingsServerSide1) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputGrafanaTLSSettingsServerSide1) GetMinVersion() *InputGrafanaMinimumTLSVersion1 {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputGrafanaTLSSettingsServerSide1) GetMaxVersion() *InputGrafanaMaximumTLSVersion1 {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// PrometheusAuthAuthenticationType1 - Remote Write authentication type
type PrometheusAuthAuthenticationType1 string

const (
	PrometheusAuthAuthenticationType1None              PrometheusAuthAuthenticationType1 = "none"
	PrometheusAuthAuthenticationType1Basic             PrometheusAuthAuthenticationType1 = "basic"
	PrometheusAuthAuthenticationType1CredentialsSecret PrometheusAuthAuthenticationType1 = "credentialsSecret"
	PrometheusAuthAuthenticationType1Token             PrometheusAuthAuthenticationType1 = "token"
	PrometheusAuthAuthenticationType1TextSecret        PrometheusAuthAuthenticationType1 = "textSecret"
	PrometheusAuthAuthenticationType1Oauth             PrometheusAuthAuthenticationType1 = "oauth"
)

func (e PrometheusAuthAuthenticationType1) ToPointer() *PrometheusAuthAuthenticationType1 {
	return &e
}
func (e *PrometheusAuthAuthenticationType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = PrometheusAuthAuthenticationType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PrometheusAuthAuthenticationType1: %v", v)
	}
}

type PrometheusAuthOauthParam1 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *PrometheusAuthOauthParam1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *PrometheusAuthOauthParam1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PrometheusAuthOauthHeader1 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *PrometheusAuthOauthHeader1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *PrometheusAuthOauthHeader1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PrometheusAuth1 struct {
	// Remote Write authentication type
	AuthType *PrometheusAuthAuthenticationType1 `default:"none" json:"authType"`
	Username *string                            `json:"username,omitempty"`
	Password *string                            `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []PrometheusAuthOauthParam1 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []PrometheusAuthOauthHeader1 `json:"oauthHeaders,omitempty"`
}

func (p PrometheusAuth1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PrometheusAuth1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PrometheusAuth1) GetAuthType() *PrometheusAuthAuthenticationType1 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *PrometheusAuth1) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *PrometheusAuth1) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *PrometheusAuth1) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *PrometheusAuth1) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *PrometheusAuth1) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *PrometheusAuth1) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *PrometheusAuth1) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *PrometheusAuth1) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *PrometheusAuth1) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *PrometheusAuth1) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *PrometheusAuth1) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *PrometheusAuth1) GetOauthParams() []PrometheusAuthOauthParam1 {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *PrometheusAuth1) GetOauthHeaders() []PrometheusAuthOauthHeader1 {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

// LokiAuthAuthenticationType1 - Loki logs authentication type
type LokiAuthAuthenticationType1 string

const (
	LokiAuthAuthenticationType1None              LokiAuthAuthenticationType1 = "none"
	LokiAuthAuthenticationType1Basic             LokiAuthAuthenticationType1 = "basic"
	LokiAuthAuthenticationType1CredentialsSecret LokiAuthAuthenticationType1 = "credentialsSecret"
	LokiAuthAuthenticationType1Token             LokiAuthAuthenticationType1 = "token"
	LokiAuthAuthenticationType1TextSecret        LokiAuthAuthenticationType1 = "textSecret"
	LokiAuthAuthenticationType1Oauth             LokiAuthAuthenticationType1 = "oauth"
)

func (e LokiAuthAuthenticationType1) ToPointer() *LokiAuthAuthenticationType1 {
	return &e
}
func (e *LokiAuthAuthenticationType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = LokiAuthAuthenticationType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LokiAuthAuthenticationType1: %v", v)
	}
}

type LokiAuthOauthParam1 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *LokiAuthOauthParam1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *LokiAuthOauthParam1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type LokiAuthOauthHeader1 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *LokiAuthOauthHeader1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *LokiAuthOauthHeader1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type LokiAuth1 struct {
	// Loki logs authentication type
	AuthType *LokiAuthAuthenticationType1 `default:"none" json:"authType"`
	Username *string                      `json:"username,omitempty"`
	Password *string                      `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []LokiAuthOauthParam1 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []LokiAuthOauthHeader1 `json:"oauthHeaders,omitempty"`
}

func (l LokiAuth1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LokiAuth1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *LokiAuth1) GetAuthType() *LokiAuthAuthenticationType1 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *LokiAuth1) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *LokiAuth1) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *LokiAuth1) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *LokiAuth1) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *LokiAuth1) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *LokiAuth1) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *LokiAuth1) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *LokiAuth1) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *LokiAuth1) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *LokiAuth1) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *LokiAuth1) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *LokiAuth1) GetOauthParams() []LokiAuthOauthParam1 {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *LokiAuth1) GetOauthHeaders() []LokiAuthOauthHeader1 {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type InputGrafanaMetadatum1 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputGrafanaMetadatum1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputGrafanaMetadatum1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafanaGrafana1 struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     *InputGrafanaType1 `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputGrafanaConnection1 `json:"connections,omitempty"`
	Pq          *InputGrafanaPq1          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                             `json:"port"`
	TLS  *InputGrafanaTLSSettingsServerSide1 `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<your‑upstream‑URL>:<your‑port>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `default:"/api/prom/push" json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<your‑upstream‑URL>:<your‑port>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string          `default:"/loki/api/v1/push" json:"lokiAPI"`
	PrometheusAuth *PrometheusAuth1 `json:"prometheusAuth,omitempty"`
	LokiAuth       *LokiAuth1       `json:"lokiAuth,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputGrafanaMetadatum1 `json:"metadata,omitempty"`
	Description *string                  `json:"description,omitempty"`
}

func (i InputGrafanaGrafana1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaGrafana1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaGrafana1) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputGrafanaGrafana1) GetType() *InputGrafanaType1 {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGrafanaGrafana1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaGrafana1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaGrafana1) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGrafanaGrafana1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGrafanaGrafana1) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGrafanaGrafana1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGrafanaGrafana1) GetConnections() []InputGrafanaConnection1 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGrafanaGrafana1) GetPq() *InputGrafanaPq1 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGrafanaGrafana1) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputGrafanaGrafana1) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputGrafanaGrafana1) GetTLS() *InputGrafanaTLSSettingsServerSide1 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputGrafanaGrafana1) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputGrafanaGrafana1) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputGrafanaGrafana1) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputGrafanaGrafana1) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputGrafanaGrafana1) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputGrafanaGrafana1) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGrafanaGrafana1) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputGrafanaGrafana1) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputGrafanaGrafana1) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputGrafanaGrafana1) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputGrafanaGrafana1) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputGrafanaGrafana1) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputGrafanaGrafana1) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputGrafanaGrafana1) GetPrometheusAuth() *PrometheusAuth1 {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *InputGrafanaGrafana1) GetLokiAuth() *LokiAuth1 {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *InputGrafanaGrafana1) GetMetadata() []InputGrafanaMetadatum1 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGrafanaGrafana1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputGrafanaType string

const (
	InputGrafanaTypeInputGrafanaGrafana1 InputGrafanaType = "InputGrafana_Grafana_1"
	InputGrafanaTypeInputGrafanaGrafana2 InputGrafanaType = "InputGrafana_Grafana_2"
)

type InputGrafana struct {
	InputGrafanaGrafana1 *InputGrafanaGrafana1 `queryParam:"inline"`
	InputGrafanaGrafana2 *InputGrafanaGrafana2 `queryParam:"inline"`

	Type InputGrafanaType
}

func CreateInputGrafanaInputGrafanaGrafana1(inputGrafanaGrafana1 InputGrafanaGrafana1) InputGrafana {
	typ := InputGrafanaTypeInputGrafanaGrafana1

	return InputGrafana{
		InputGrafanaGrafana1: &inputGrafanaGrafana1,
		Type:                 typ,
	}
}

func CreateInputGrafanaInputGrafanaGrafana2(inputGrafanaGrafana2 InputGrafanaGrafana2) InputGrafana {
	typ := InputGrafanaTypeInputGrafanaGrafana2

	return InputGrafana{
		InputGrafanaGrafana2: &inputGrafanaGrafana2,
		Type:                 typ,
	}
}

func (u *InputGrafana) UnmarshalJSON(data []byte) error {

	var inputGrafanaGrafana1 InputGrafanaGrafana1 = InputGrafanaGrafana1{}
	if err := utils.UnmarshalJSON(data, &inputGrafanaGrafana1, "", true, true); err == nil {
		u.InputGrafanaGrafana1 = &inputGrafanaGrafana1
		u.Type = InputGrafanaTypeInputGrafanaGrafana1
		return nil
	}

	var inputGrafanaGrafana2 InputGrafanaGrafana2 = InputGrafanaGrafana2{}
	if err := utils.UnmarshalJSON(data, &inputGrafanaGrafana2, "", true, true); err == nil {
		u.InputGrafanaGrafana2 = &inputGrafanaGrafana2
		u.Type = InputGrafanaTypeInputGrafanaGrafana2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputGrafana", string(data))
}

func (u InputGrafana) MarshalJSON() ([]byte, error) {
	if u.InputGrafanaGrafana1 != nil {
		return utils.MarshalJSON(u.InputGrafanaGrafana1, "", true)
	}

	if u.InputGrafanaGrafana2 != nil {
		return utils.MarshalJSON(u.InputGrafanaGrafana2, "", true)
	}

	return nil, errors.New("could not marshal union type InputGrafana: all fields are null")
}

type CreateInputTypeConfluentCloud string

const (
	CreateInputTypeConfluentCloudConfluentCloud CreateInputTypeConfluentCloud = "confluent_cloud"
)

func (e CreateInputTypeConfluentCloud) ToPointer() *CreateInputTypeConfluentCloud {
	return &e
}
func (e *CreateInputTypeConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "confluent_cloud":
		*e = CreateInputTypeConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeConfluentCloud: %v", v)
	}
}

type ConnectionConfluentCloud struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionConfluentCloud) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionConfluentCloud) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeConfluentCloud - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeConfluentCloud string

const (
	CreateInputModeConfluentCloudSmart  CreateInputModeConfluentCloud = "smart"
	CreateInputModeConfluentCloudAlways CreateInputModeConfluentCloud = "always"
)

func (e CreateInputModeConfluentCloud) ToPointer() *CreateInputModeConfluentCloud {
	return &e
}
func (e *CreateInputModeConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeConfluentCloud: %v", v)
	}
}

// PqCompressionConfluentCloud - Codec to use to compress the persisted data
type PqCompressionConfluentCloud string

const (
	PqCompressionConfluentCloudNone PqCompressionConfluentCloud = "none"
	PqCompressionConfluentCloudGzip PqCompressionConfluentCloud = "gzip"
)

func (e PqCompressionConfluentCloud) ToPointer() *PqCompressionConfluentCloud {
	return &e
}
func (e *PqCompressionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionConfluentCloud: %v", v)
	}
}

type PqConfluentCloud struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeConfluentCloud `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionConfluentCloud `default:"none" json:"compress"`
}

func (p PqConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqConfluentCloud) GetMode() *CreateInputModeConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqConfluentCloud) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqConfluentCloud) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqConfluentCloud) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqConfluentCloud) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqConfluentCloud) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqConfluentCloud) GetCompress() *PqCompressionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Compress
}

type CreateInputMinimumTLSVersionConfluentCloud string

const (
	CreateInputMinimumTLSVersionConfluentCloudTlSv1  CreateInputMinimumTLSVersionConfluentCloud = "TLSv1"
	CreateInputMinimumTLSVersionConfluentCloudTlSv11 CreateInputMinimumTLSVersionConfluentCloud = "TLSv1.1"
	CreateInputMinimumTLSVersionConfluentCloudTlSv12 CreateInputMinimumTLSVersionConfluentCloud = "TLSv1.2"
	CreateInputMinimumTLSVersionConfluentCloudTlSv13 CreateInputMinimumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e CreateInputMinimumTLSVersionConfluentCloud) ToPointer() *CreateInputMinimumTLSVersionConfluentCloud {
	return &e
}
func (e *CreateInputMinimumTLSVersionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMinimumTLSVersionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMinimumTLSVersionConfluentCloud: %v", v)
	}
}

type CreateInputMaximumTLSVersionConfluentCloud string

const (
	CreateInputMaximumTLSVersionConfluentCloudTlSv1  CreateInputMaximumTLSVersionConfluentCloud = "TLSv1"
	CreateInputMaximumTLSVersionConfluentCloudTlSv11 CreateInputMaximumTLSVersionConfluentCloud = "TLSv1.1"
	CreateInputMaximumTLSVersionConfluentCloudTlSv12 CreateInputMaximumTLSVersionConfluentCloud = "TLSv1.2"
	CreateInputMaximumTLSVersionConfluentCloudTlSv13 CreateInputMaximumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e CreateInputMaximumTLSVersionConfluentCloud) ToPointer() *CreateInputMaximumTLSVersionConfluentCloud {
	return &e
}
func (e *CreateInputMaximumTLSVersionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMaximumTLSVersionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMaximumTLSVersionConfluentCloud: %v", v)
	}
}

type CreateInputTLSSettingsClientSideConfluentCloud struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                                     `json:"passphrase,omitempty"`
	MinVersion *CreateInputMinimumTLSVersionConfluentCloud `json:"minVersion,omitempty"`
	MaxVersion *CreateInputMaximumTLSVersionConfluentCloud `json:"maxVersion,omitempty"`
}

func (c CreateInputTLSSettingsClientSideConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputTLSSettingsClientSideConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetMinVersion() *CreateInputMinimumTLSVersionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *CreateInputTLSSettingsClientSideConfluentCloud) GetMaxVersion() *CreateInputMaximumTLSVersionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// CreateInputAuthConfluentCloud - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type CreateInputAuthConfluentCloud struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (c CreateInputAuthConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputAuthConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputAuthConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputAuthConfluentCloud) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

type CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud string

const (
	CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv1  CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv11 CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.1"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv12 CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.2"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv13 CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud) ToPointer() *CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud {
	return &e
}
func (e *CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud: %v", v)
	}
}

type CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud string

const (
	CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv1  CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv11 CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.1"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv12 CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.2"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv13 CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud) ToPointer() *CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud {
	return &e
}
func (e *CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud: %v", v)
	}
}

type CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                                                        `json:"passphrase,omitempty"`
	MinVersion *CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud `json:"minVersion,omitempty"`
	MaxVersion *CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud `json:"maxVersion,omitempty"`
}

func (c CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetMinVersion() *CreateInputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetMaxVersion() *CreateInputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud struct {
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *CreateInputAuthConfluentCloud                                     `json:"auth,omitempty"`
	TLS  *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud `json:"tls,omitempty"`
}

func (c CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) GetAuth() *CreateInputAuthConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud) GetTLS() *CreateInputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud {
	if o == nil {
		return nil
	}
	return o.TLS
}

type CreateInputSASLMechanismConfluentCloud string

const (
	CreateInputSASLMechanismConfluentCloudPlain       CreateInputSASLMechanismConfluentCloud = "plain"
	CreateInputSASLMechanismConfluentCloudScramSha256 CreateInputSASLMechanismConfluentCloud = "scram-sha-256"
	CreateInputSASLMechanismConfluentCloudScramSha512 CreateInputSASLMechanismConfluentCloud = "scram-sha-512"
	CreateInputSASLMechanismConfluentCloudKerberos    CreateInputSASLMechanismConfluentCloud = "kerberos"
)

func (e CreateInputSASLMechanismConfluentCloud) ToPointer() *CreateInputSASLMechanismConfluentCloud {
	return &e
}
func (e *CreateInputSASLMechanismConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = CreateInputSASLMechanismConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputSASLMechanismConfluentCloud: %v", v)
	}
}

// CreateInputAuthenticationConfluentCloud - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type CreateInputAuthenticationConfluentCloud struct {
	Disabled  *bool                                   `default:"true" json:"disabled"`
	Mechanism *CreateInputSASLMechanismConfluentCloud `default:"plain" json:"mechanism"`
}

func (c CreateInputAuthenticationConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputAuthenticationConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputAuthenticationConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputAuthenticationConfluentCloud) GetMechanism() *CreateInputSASLMechanismConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type MetadatumConfluentCloud struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumConfluentCloud) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumConfluentCloud) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputConfluentCloud struct {
	// Unique ID for this input
	ID       string                         `json:"id"`
	Type     *CreateInputTypeConfluentCloud `json:"type,omitempty"`
	Disabled *bool                          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionConfluentCloud `json:"connections,omitempty"`
	Pq          *PqConfluentCloud          `json:"pq,omitempty"`
	// List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092
	Brokers []string                                        `json:"brokers"`
	TLS     *CreateInputTLSSettingsClientSideConfluentCloud `json:"tls,omitempty"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                                       `default:"true" json:"fromBeginning"`
	KafkaSchemaRegistry *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *CreateInputAuthenticationConfluentCloud `json:"sasl,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Fields to add to events from this input
	Metadata    []MetadatumConfluentCloud `json:"metadata,omitempty"`
	Description *string                   `json:"description,omitempty"`
}

func (i InputConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloud) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputConfluentCloud) GetType() *CreateInputTypeConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputConfluentCloud) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputConfluentCloud) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputConfluentCloud) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputConfluentCloud) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputConfluentCloud) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputConfluentCloud) GetConnections() []ConnectionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputConfluentCloud) GetPq() *PqConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputConfluentCloud) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputConfluentCloud) GetTLS() *CreateInputTLSSettingsClientSideConfluentCloud {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputConfluentCloud) GetTopics() []string {
	if o == nil {
		return []string{}
	}
	return o.Topics
}

func (o *InputConfluentCloud) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputConfluentCloud) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputConfluentCloud) GetKafkaSchemaRegistry() *CreateInputKafkaSchemaRegistryAuthenticationConfluentCloud {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputConfluentCloud) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputConfluentCloud) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputConfluentCloud) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputConfluentCloud) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputConfluentCloud) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputConfluentCloud) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputConfluentCloud) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputConfluentCloud) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputConfluentCloud) GetSasl() *CreateInputAuthenticationConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputConfluentCloud) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputConfluentCloud) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputConfluentCloud) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputConfluentCloud) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputConfluentCloud) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputConfluentCloud) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputConfluentCloud) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputConfluentCloud) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputConfluentCloud) GetMetadata() []MetadatumConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputConfluentCloud) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateInputTypeElastic string

const (
	CreateInputTypeElasticElastic CreateInputTypeElastic = "elastic"
)

func (e CreateInputTypeElastic) ToPointer() *CreateInputTypeElastic {
	return &e
}
func (e *CreateInputTypeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic":
		*e = CreateInputTypeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeElastic: %v", v)
	}
}

type ConnectionElastic struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionElastic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionElastic) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeElastic - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeElastic string

const (
	CreateInputModeElasticSmart  CreateInputModeElastic = "smart"
	CreateInputModeElasticAlways CreateInputModeElastic = "always"
)

func (e CreateInputModeElastic) ToPointer() *CreateInputModeElastic {
	return &e
}
func (e *CreateInputModeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeElastic: %v", v)
	}
}

// PqCompressionElastic - Codec to use to compress the persisted data
type PqCompressionElastic string

const (
	PqCompressionElasticNone PqCompressionElastic = "none"
	PqCompressionElasticGzip PqCompressionElastic = "gzip"
)

func (e PqCompressionElastic) ToPointer() *PqCompressionElastic {
	return &e
}
func (e *PqCompressionElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionElastic: %v", v)
	}
}

type PqElastic struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeElastic `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionElastic `default:"none" json:"compress"`
}

func (p PqElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqElastic) GetMode() *CreateInputModeElastic {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqElastic) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqElastic) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqElastic) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqElastic) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqElastic) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqElastic) GetCompress() *PqCompressionElastic {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionElastic string

const (
	MinimumTLSVersionElasticTlSv1  MinimumTLSVersionElastic = "TLSv1"
	MinimumTLSVersionElasticTlSv11 MinimumTLSVersionElastic = "TLSv1.1"
	MinimumTLSVersionElasticTlSv12 MinimumTLSVersionElastic = "TLSv1.2"
	MinimumTLSVersionElasticTlSv13 MinimumTLSVersionElastic = "TLSv1.3"
)

func (e MinimumTLSVersionElastic) ToPointer() *MinimumTLSVersionElastic {
	return &e
}
func (e *MinimumTLSVersionElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionElastic: %v", v)
	}
}

type MaximumTLSVersionElastic string

const (
	MaximumTLSVersionElasticTlSv1  MaximumTLSVersionElastic = "TLSv1"
	MaximumTLSVersionElasticTlSv11 MaximumTLSVersionElastic = "TLSv1.1"
	MaximumTLSVersionElasticTlSv12 MaximumTLSVersionElastic = "TLSv1.2"
	MaximumTLSVersionElasticTlSv13 MaximumTLSVersionElastic = "TLSv1.3"
)

func (e MaximumTLSVersionElastic) ToPointer() *MaximumTLSVersionElastic {
	return &e
}
func (e *MaximumTLSVersionElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionElastic: %v", v)
	}
}

type TLSSettingsServerSideElastic struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                     `default:"false" json:"requestCert"`
	RejectUnauthorized any                       `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                       `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionElastic `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionElastic `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideElastic) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideElastic) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideElastic) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideElastic) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideElastic) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideElastic) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideElastic) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideElastic) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideElastic) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideElastic) GetMinVersion() *MinimumTLSVersionElastic {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideElastic) GetMaxVersion() *MaximumTLSVersionElastic {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type AuthenticationTypeElastic string

const (
	AuthenticationTypeElasticNone              AuthenticationTypeElastic = "none"
	AuthenticationTypeElasticBasic             AuthenticationTypeElastic = "basic"
	AuthenticationTypeElasticCredentialsSecret AuthenticationTypeElastic = "credentialsSecret"
	AuthenticationTypeElasticAuthTokens        AuthenticationTypeElastic = "authTokens"
)

func (e AuthenticationTypeElastic) ToPointer() *AuthenticationTypeElastic {
	return &e
}
func (e *AuthenticationTypeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "authTokens":
		*e = AuthenticationTypeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationTypeElastic: %v", v)
	}
}

// CreateInputAPIVersion - The API version to use for communicating with the server
type CreateInputAPIVersion string

const (
	CreateInputAPIVersionSixDot8Dot4   CreateInputAPIVersion = "6.8.4"
	CreateInputAPIVersionEightDot3Dot2 CreateInputAPIVersion = "8.3.2"
	CreateInputAPIVersionCustom        CreateInputAPIVersion = "custom"
)

func (e CreateInputAPIVersion) ToPointer() *CreateInputAPIVersion {
	return &e
}
func (e *CreateInputAPIVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "6.8.4":
		fallthrough
	case "8.3.2":
		fallthrough
	case "custom":
		*e = CreateInputAPIVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAPIVersion: %v", v)
	}
}

type CreateInputExtraHTTPHeader struct {
	Name  *string `json:"name,omitempty"`
	Value string  `json:"value"`
}

func (o *CreateInputExtraHTTPHeader) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *CreateInputExtraHTTPHeader) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type MetadatumElastic struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumElastic) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumElastic) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// ProxyModeAuthenticationMethod - Enter credentials directly, or select a stored secret
type ProxyModeAuthenticationMethod string

const (
	ProxyModeAuthenticationMethodNone   ProxyModeAuthenticationMethod = "none"
	ProxyModeAuthenticationMethodManual ProxyModeAuthenticationMethod = "manual"
	ProxyModeAuthenticationMethodSecret ProxyModeAuthenticationMethod = "secret"
)

func (e ProxyModeAuthenticationMethod) ToPointer() *ProxyModeAuthenticationMethod {
	return &e
}
func (e *ProxyModeAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = ProxyModeAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ProxyModeAuthenticationMethod: %v", v)
	}
}

type ProxyModeElastic struct {
	// Enable proxying of non-bulk API requests to an external Elastic server. Enable this only if you understand the implications. See [Cribl Docs](https://docs.cribl.io/stream/sources-elastic/#proxy-mode) for more details.
	Enabled *bool `default:"false" json:"enabled"`
	// URL of the Elastic server to proxy non-bulk requests to, such as http://elastic:9200
	URL *string `json:"url,omitempty"`
	// Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// List of headers to remove from the request to proxy
	RemoveHeaders []string `json:"removeHeaders,omitempty"`
	// Amount of time, in seconds, to wait for a proxy request to complete before canceling it
	TimeoutSec *float64 `default:"60" json:"timeoutSec"`
	// Enter credentials directly, or select a stored secret
	AuthType *ProxyModeAuthenticationMethod `default:"none" json:"authType"`
}

func (p ProxyModeElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyModeElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ProxyModeElastic) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *ProxyModeElastic) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *ProxyModeElastic) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *ProxyModeElastic) GetRemoveHeaders() []string {
	if o == nil {
		return nil
	}
	return o.RemoveHeaders
}

func (o *ProxyModeElastic) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *ProxyModeElastic) GetAuthType() *ProxyModeAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

type InputElastic struct {
	// Unique ID for this input
	ID       string                  `json:"id"`
	Type     *CreateInputTypeElastic `json:"type,omitempty"`
	Disabled *bool                   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionElastic `json:"connections,omitempty"`
	Pq          *PqElastic          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                       `json:"port"`
	TLS  *TLSSettingsServerSideElastic `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Elasticsearch API requests. Defaults to /. _bulk will be appended automatically. For example, /myPath becomes /myPath/_bulk. Requests can then be made to either /myPath/_bulk or /myPath/<myIndexName>/_bulk. Other entries are faked as success.
	ElasticAPI *string                    `default:"/" json:"elasticAPI"`
	AuthType   *AuthenticationTypeElastic `default:"none" json:"authType"`
	// The API version to use for communicating with the server
	APIVersion *CreateInputAPIVersion `default:"8.3.2" json:"apiVersion"`
	// Headers to add to all events
	ExtraHTTPHeaders []CreateInputExtraHTTPHeader `json:"extraHttpHeaders,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumElastic `json:"metadata,omitempty"`
	ProxyMode   *ProxyModeElastic  `json:"proxyMode,omitempty"`
	Description *string            `json:"description,omitempty"`
	Username    *string            `json:"username,omitempty"`
	Password    *string            `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Bearer tokens to include in the authorization header
	AuthTokens []string `json:"authTokens,omitempty"`
	// Custom version information to respond to requests
	CustomAPIVersion *string `default:"{\n    \"name\": \"AzU84iL\",\n    \"cluster_name\": \"cribl\",\n    \"cluster_uuid\": \"Js6_Z2VKS3KbfRSxPmPbaw\",\n    \"version\": {\n        \"number\": \"8.3.2\",\n        \"build_type\": \"tar\",\n        \"build_hash\": \"bca0c8d\",\n        \"build_date\": \"2019-10-16T06:19:49.319352Z\",\n        \"build_snapshot\": false,\n        \"lucene_version\": \"9.7.2\",\n        \"minimum_wire_compatibility_version\": \"7.17.0\",\n        \"minimum_index_compatibility_version\": \"7.0.0\"\n    },\n    \"tagline\": \"You Know, for Search\"\n}" json:"customAPIVersion"`
}

func (i InputElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputElastic) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputElastic) GetType() *CreateInputTypeElastic {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputElastic) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputElastic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputElastic) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputElastic) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputElastic) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputElastic) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputElastic) GetConnections() []ConnectionElastic {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputElastic) GetPq() *PqElastic {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputElastic) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputElastic) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputElastic) GetTLS() *TLSSettingsServerSideElastic {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputElastic) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputElastic) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputElastic) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputElastic) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputElastic) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputElastic) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputElastic) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputElastic) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputElastic) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputElastic) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputElastic) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputElastic) GetElasticAPI() *string {
	if o == nil {
		return nil
	}
	return o.ElasticAPI
}

func (o *InputElastic) GetAuthType() *AuthenticationTypeElastic {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputElastic) GetAPIVersion() *CreateInputAPIVersion {
	if o == nil {
		return nil
	}
	return o.APIVersion
}

func (o *InputElastic) GetExtraHTTPHeaders() []CreateInputExtraHTTPHeader {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *InputElastic) GetMetadata() []MetadatumElastic {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputElastic) GetProxyMode() *ProxyModeElastic {
	if o == nil {
		return nil
	}
	return o.ProxyMode
}

func (o *InputElastic) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputElastic) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputElastic) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputElastic) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputElastic) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputElastic) GetCustomAPIVersion() *string {
	if o == nil {
		return nil
	}
	return o.CustomAPIVersion
}

type CreateInputTypeAzureBlob string

const (
	CreateInputTypeAzureBlobAzureBlob CreateInputTypeAzureBlob = "azure_blob"
)

func (e CreateInputTypeAzureBlob) ToPointer() *CreateInputTypeAzureBlob {
	return &e
}
func (e *CreateInputTypeAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = CreateInputTypeAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeAzureBlob: %v", v)
	}
}

type ConnectionAzureBlob struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionAzureBlob) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionAzureBlob) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeAzureBlob - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeAzureBlob string

const (
	ModeAzureBlobSmart  ModeAzureBlob = "smart"
	ModeAzureBlobAlways ModeAzureBlob = "always"
)

func (e ModeAzureBlob) ToPointer() *ModeAzureBlob {
	return &e
}
func (e *ModeAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeAzureBlob: %v", v)
	}
}

// PqCompressionAzureBlob - Codec to use to compress the persisted data
type PqCompressionAzureBlob string

const (
	PqCompressionAzureBlobNone PqCompressionAzureBlob = "none"
	PqCompressionAzureBlobGzip PqCompressionAzureBlob = "gzip"
)

func (e PqCompressionAzureBlob) ToPointer() *PqCompressionAzureBlob {
	return &e
}
func (e *PqCompressionAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionAzureBlob: %v", v)
	}
}

type PqAzureBlob struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeAzureBlob `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionAzureBlob `default:"none" json:"compress"`
}

func (p PqAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqAzureBlob) GetMode() *ModeAzureBlob {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqAzureBlob) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqAzureBlob) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqAzureBlob) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqAzureBlob) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqAzureBlob) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqAzureBlob) GetCompress() *PqCompressionAzureBlob {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumAzureBlob struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumAzureBlob) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumAzureBlob) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CreateInputAuthenticationMethodAzureBlob string

const (
	CreateInputAuthenticationMethodAzureBlobManual       CreateInputAuthenticationMethodAzureBlob = "manual"
	CreateInputAuthenticationMethodAzureBlobSecret       CreateInputAuthenticationMethodAzureBlob = "secret"
	CreateInputAuthenticationMethodAzureBlobClientSecret CreateInputAuthenticationMethodAzureBlob = "clientSecret"
	CreateInputAuthenticationMethodAzureBlobClientCert   CreateInputAuthenticationMethodAzureBlob = "clientCert"
)

func (e CreateInputAuthenticationMethodAzureBlob) ToPointer() *CreateInputAuthenticationMethodAzureBlob {
	return &e
}
func (e *CreateInputAuthenticationMethodAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "clientSecret":
		fallthrough
	case "clientCert":
		*e = CreateInputAuthenticationMethodAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAuthenticationMethodAzureBlob: %v", v)
	}
}

type CreateInputCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal
	CertificateName string `json:"certificateName"`
}

func (o *CreateInputCertificate) GetCertificateName() string {
	if o == nil {
		return ""
	}
	return o.CertificateName
}

type InputAzureBlob struct {
	// Unique ID for this input
	ID       string                   `json:"id"`
	Type     CreateInputTypeAzureBlob `json:"type"`
	Disabled *bool                    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionAzureBlob `json:"connections,omitempty"`
	Pq          *PqAzureBlob          `json:"pq,omitempty"`
	// The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// The duration (in seconds) which pollers should be validated and restarted if exited
	ServicePeriodSecs *float64 `default:"5" json:"servicePeriodSecs"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Fields to add to events from this input
	Metadata []MetadatumAzureBlob `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                                  `default:"600" json:"parquetChunkDownloadTimeout"`
	AuthType                    *CreateInputAuthenticationMethodAzureBlob `default:"manual" json:"authType"`
	Description                 *string                                   `json:"description,omitempty"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitempty"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitempty"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitempty"`
	// The Azure cloud to use. Defaults to Azure Public Cloud.
	AzureCloud *string `json:"azureCloud,omitempty"`
	// Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string                 `json:"clientTextSecret,omitempty"`
	Certificate      *CreateInputCertificate `json:"certificate,omitempty"`
}

func (i InputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlob) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputAzureBlob) GetType() CreateInputTypeAzureBlob {
	if o == nil {
		return CreateInputTypeAzureBlob("")
	}
	return o.Type
}

func (o *InputAzureBlob) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAzureBlob) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAzureBlob) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputAzureBlob) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputAzureBlob) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputAzureBlob) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputAzureBlob) GetConnections() []ConnectionAzureBlob {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputAzureBlob) GetPq() *PqAzureBlob {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputAzureBlob) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputAzureBlob) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputAzureBlob) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputAzureBlob) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputAzureBlob) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputAzureBlob) GetServicePeriodSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.ServicePeriodSecs
}

func (o *InputAzureBlob) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputAzureBlob) GetMetadata() []MetadatumAzureBlob {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputAzureBlob) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputAzureBlob) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputAzureBlob) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputAzureBlob) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputAzureBlob) GetAuthType() *CreateInputAuthenticationMethodAzureBlob {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputAzureBlob) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputAzureBlob) GetConnectionString() *string {
	if o == nil {
		return nil
	}
	return o.ConnectionString
}

func (o *InputAzureBlob) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputAzureBlob) GetStorageAccountName() *string {
	if o == nil {
		return nil
	}
	return o.StorageAccountName
}

func (o *InputAzureBlob) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *InputAzureBlob) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *InputAzureBlob) GetAzureCloud() *string {
	if o == nil {
		return nil
	}
	return o.AzureCloud
}

func (o *InputAzureBlob) GetEndpointSuffix() *string {
	if o == nil {
		return nil
	}
	return o.EndpointSuffix
}

func (o *InputAzureBlob) GetClientTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientTextSecret
}

func (o *InputAzureBlob) GetCertificate() *CreateInputCertificate {
	if o == nil {
		return nil
	}
	return o.Certificate
}

type TypeSplunkHec string

const (
	TypeSplunkHecSplunkHec TypeSplunkHec = "splunk_hec"
)

func (e TypeSplunkHec) ToPointer() *TypeSplunkHec {
	return &e
}
func (e *TypeSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_hec":
		*e = TypeSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSplunkHec: %v", v)
	}
}

type ConnectionSplunkHec struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSplunkHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSplunkHec) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeSplunkHec - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSplunkHec string

const (
	ModeSplunkHecSmart  ModeSplunkHec = "smart"
	ModeSplunkHecAlways ModeSplunkHec = "always"
)

func (e ModeSplunkHec) ToPointer() *ModeSplunkHec {
	return &e
}
func (e *ModeSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeSplunkHec: %v", v)
	}
}

// CompressionSplunkHec - Codec to use to compress the persisted data
type CompressionSplunkHec string

const (
	CompressionSplunkHecNone CompressionSplunkHec = "none"
	CompressionSplunkHecGzip CompressionSplunkHec = "gzip"
)

func (e CompressionSplunkHec) ToPointer() *CompressionSplunkHec {
	return &e
}
func (e *CompressionSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSplunkHec: %v", v)
	}
}

type PqSplunkHec struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSplunkHec `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSplunkHec `default:"none" json:"compress"`
}

func (p PqSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSplunkHec) GetMode() *ModeSplunkHec {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSplunkHec) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSplunkHec) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSplunkHec) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSplunkHec) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSplunkHec) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSplunkHec) GetCompress() *CompressionSplunkHec {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodSplunkHec - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodSplunkHec string

const (
	AuthenticationMethodSplunkHecManual AuthenticationMethodSplunkHec = "manual"
	AuthenticationMethodSplunkHecSecret AuthenticationMethodSplunkHec = "secret"
)

func (e AuthenticationMethodSplunkHec) ToPointer() *AuthenticationMethodSplunkHec {
	return &e
}
func (e *AuthenticationMethodSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodSplunkHec: %v", v)
	}
}

type AuthTokenMetadatumSplunkHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *AuthTokenMetadatumSplunkHec) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *AuthTokenMetadatumSplunkHec) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokenSplunkHec struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthenticationMethodSplunkHec `default:"manual" json:"authType"`
	TokenSecret any                            `json:"tokenSecret,omitempty"`
	Token       any                            `json:"token"`
	Enabled     *bool                          `default:"true" json:"enabled"`
	// Optional token description
	Description *string `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokenMetadatumSplunkHec `json:"metadata,omitempty"`
}

func (a AuthTokenSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *AuthTokenSplunkHec) GetAuthType() *AuthenticationMethodSplunkHec {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *AuthTokenSplunkHec) GetTokenSecret() any {
	if o == nil {
		return nil
	}
	return o.TokenSecret
}

func (o *AuthTokenSplunkHec) GetToken() any {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *AuthTokenSplunkHec) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *AuthTokenSplunkHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokenSplunkHec) GetAllowedIndexesAtToken() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexesAtToken
}

func (o *AuthTokenSplunkHec) GetMetadata() []AuthTokenMetadatumSplunkHec {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type MinimumTLSVersionSplunkHec string

const (
	MinimumTLSVersionSplunkHecTlSv1  MinimumTLSVersionSplunkHec = "TLSv1"
	MinimumTLSVersionSplunkHecTlSv11 MinimumTLSVersionSplunkHec = "TLSv1.1"
	MinimumTLSVersionSplunkHecTlSv12 MinimumTLSVersionSplunkHec = "TLSv1.2"
	MinimumTLSVersionSplunkHecTlSv13 MinimumTLSVersionSplunkHec = "TLSv1.3"
)

func (e MinimumTLSVersionSplunkHec) ToPointer() *MinimumTLSVersionSplunkHec {
	return &e
}
func (e *MinimumTLSVersionSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionSplunkHec: %v", v)
	}
}

type MaximumTLSVersionSplunkHec string

const (
	MaximumTLSVersionSplunkHecTlSv1  MaximumTLSVersionSplunkHec = "TLSv1"
	MaximumTLSVersionSplunkHecTlSv11 MaximumTLSVersionSplunkHec = "TLSv1.1"
	MaximumTLSVersionSplunkHecTlSv12 MaximumTLSVersionSplunkHec = "TLSv1.2"
	MaximumTLSVersionSplunkHecTlSv13 MaximumTLSVersionSplunkHec = "TLSv1.3"
)

func (e MaximumTLSVersionSplunkHec) ToPointer() *MaximumTLSVersionSplunkHec {
	return &e
}
func (e *MaximumTLSVersionSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionSplunkHec: %v", v)
	}
}

type TLSSettingsServerSideSplunkHec struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                       `default:"false" json:"requestCert"`
	RejectUnauthorized any                         `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                         `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionSplunkHec `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionSplunkHec `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideSplunkHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideSplunkHec) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideSplunkHec) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideSplunkHec) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideSplunkHec) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideSplunkHec) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideSplunkHec) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideSplunkHec) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideSplunkHec) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideSplunkHec) GetMinVersion() *MinimumTLSVersionSplunkHec {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideSplunkHec) GetMaxVersion() *MaximumTLSVersionSplunkHec {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumSplunkHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSplunkHec) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSplunkHec) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSplunkHec struct {
	// Unique ID for this input
	ID       string         `json:"id"`
	Type     *TypeSplunkHec `json:"type,omitempty"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunkHec `json:"connections,omitempty"`
	Pq          *PqSplunkHec          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenSplunkHec            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideSplunkHec `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Splunk HTTP Event Collector API requests. This input supports the /event, /raw and /s2s endpoints.
	SplunkHecAPI *string `default:"/services/collector" json:"splunkHecAPI"`
	// Fields to add to every event. Overrides fields added at the token or request level. See [the Source documentation](https://docs.cribl.io/stream/sources-splunk-hec/#fields) for more info.
	Metadata []MetadatumSplunkHec `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// Enable Splunk HEC acknowledgements
	SplunkHecAcks *bool `default:"false" json:"splunkHecAcks"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `default:"true" json:"useFwdTimezone"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `default:"true" json:"dropControlFields"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool   `default:"false" json:"emitTokenMetrics"`
	Description      *string `json:"description,omitempty"`
}

func (i InputSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkHec) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSplunkHec) GetType() *TypeSplunkHec {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunkHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunkHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkHec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunkHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunkHec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunkHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunkHec) GetConnections() []ConnectionSplunkHec {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunkHec) GetPq() *PqSplunkHec {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunkHec) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSplunkHec) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputSplunkHec) GetAuthTokens() []AuthTokenSplunkHec {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputSplunkHec) GetTLS() *TLSSettingsServerSideSplunkHec {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSplunkHec) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputSplunkHec) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputSplunkHec) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSplunkHec) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputSplunkHec) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputSplunkHec) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputSplunkHec) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputSplunkHec) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputSplunkHec) GetEnableHealthCheck() any {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputSplunkHec) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputSplunkHec) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputSplunkHec) GetSplunkHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.SplunkHecAPI
}

func (o *InputSplunkHec) GetMetadata() []MetadatumSplunkHec {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunkHec) GetAllowedIndexes() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexes
}

func (o *InputSplunkHec) GetSplunkHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.SplunkHecAcks
}

func (o *InputSplunkHec) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunkHec) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunkHec) GetUseFwdTimezone() *bool {
	if o == nil {
		return nil
	}
	return o.UseFwdTimezone
}

func (o *InputSplunkHec) GetDropControlFields() *bool {
	if o == nil {
		return nil
	}
	return o.DropControlFields
}

func (o *InputSplunkHec) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputSplunkHec) GetAccessControlAllowOrigin() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowOrigin
}

func (o *InputSplunkHec) GetAccessControlAllowHeaders() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowHeaders
}

func (o *InputSplunkHec) GetEmitTokenMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EmitTokenMetrics
}

func (o *InputSplunkHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type TypeSplunkSearch string

const (
	TypeSplunkSearchSplunkSearch TypeSplunkSearch = "splunk_search"
)

func (e TypeSplunkSearch) ToPointer() *TypeSplunkSearch {
	return &e
}
func (e *TypeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_search":
		*e = TypeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSplunkSearch: %v", v)
	}
}

type ConnectionSplunkSearch struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSplunkSearch) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSplunkSearch) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeSplunkSearch - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSplunkSearch string

const (
	ModeSplunkSearchSmart  ModeSplunkSearch = "smart"
	ModeSplunkSearchAlways ModeSplunkSearch = "always"
)

func (e ModeSplunkSearch) ToPointer() *ModeSplunkSearch {
	return &e
}
func (e *ModeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeSplunkSearch: %v", v)
	}
}

// CompressionSplunkSearch - Codec to use to compress the persisted data
type CompressionSplunkSearch string

const (
	CompressionSplunkSearchNone CompressionSplunkSearch = "none"
	CompressionSplunkSearchGzip CompressionSplunkSearch = "gzip"
)

func (e CompressionSplunkSearch) ToPointer() *CompressionSplunkSearch {
	return &e
}
func (e *CompressionSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSplunkSearch: %v", v)
	}
}

type PqSplunkSearch struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSplunkSearch `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSplunkSearch `default:"none" json:"compress"`
}

func (p PqSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSplunkSearch) GetMode() *ModeSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSplunkSearch) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSplunkSearch) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSplunkSearch) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSplunkSearch) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSplunkSearch) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSplunkSearch) GetCompress() *CompressionSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Compress
}

// OutputMode - Format of the returned output
type OutputMode string

const (
	OutputModeCsv  OutputMode = "csv"
	OutputModeJSON OutputMode = "json"
)

func (e OutputMode) ToPointer() *OutputMode {
	return &e
}
func (e *OutputMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "csv":
		fallthrough
	case "json":
		*e = OutputMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMode: %v", v)
	}
}

type EndpointParam struct {
	Name string `json:"name"`
	// JavaScript expression to compute the parameter's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (o *EndpointParam) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *EndpointParam) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type EndpointHeader struct {
	Name string `json:"name"`
	// JavaScript expression to compute the header's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (o *EndpointHeader) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *EndpointHeader) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// LogLevelSplunkSearch - Collector runtime log level (verbosity)
type LogLevelSplunkSearch string

const (
	LogLevelSplunkSearchError LogLevelSplunkSearch = "error"
	LogLevelSplunkSearchWarn  LogLevelSplunkSearch = "warn"
	LogLevelSplunkSearchInfo  LogLevelSplunkSearch = "info"
	LogLevelSplunkSearchDebug LogLevelSplunkSearch = "debug"
)

func (e LogLevelSplunkSearch) ToPointer() *LogLevelSplunkSearch {
	return &e
}
func (e *LogLevelSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = LogLevelSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelSplunkSearch: %v", v)
	}
}

type MetadatumSplunkSearch struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSplunkSearch) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSplunkSearch) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// RetryTypeSplunkSearch - The algorithm to use when performing HTTP retries
type RetryTypeSplunkSearch string

const (
	RetryTypeSplunkSearchNone    RetryTypeSplunkSearch = "none"
	RetryTypeSplunkSearchBackoff RetryTypeSplunkSearch = "backoff"
	RetryTypeSplunkSearchStatic  RetryTypeSplunkSearch = "static"
)

func (e RetryTypeSplunkSearch) ToPointer() *RetryTypeSplunkSearch {
	return &e
}
func (e *RetryTypeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeSplunkSearch: %v", v)
	}
}

type RetryRulesSplunkSearch struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeSplunkSearch `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesSplunkSearch) GetType() *RetryTypeSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesSplunkSearch) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesSplunkSearch) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesSplunkSearch) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesSplunkSearch) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesSplunkSearch) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesSplunkSearch) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesSplunkSearch) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationTypeSplunkSearch - Splunk Search authentication type
type AuthenticationTypeSplunkSearch string

const (
	AuthenticationTypeSplunkSearchNone              AuthenticationTypeSplunkSearch = "none"
	AuthenticationTypeSplunkSearchBasic             AuthenticationTypeSplunkSearch = "basic"
	AuthenticationTypeSplunkSearchCredentialsSecret AuthenticationTypeSplunkSearch = "credentialsSecret"
	AuthenticationTypeSplunkSearchToken             AuthenticationTypeSplunkSearch = "token"
	AuthenticationTypeSplunkSearchTextSecret        AuthenticationTypeSplunkSearch = "textSecret"
	AuthenticationTypeSplunkSearchOauth             AuthenticationTypeSplunkSearch = "oauth"
)

func (e AuthenticationTypeSplunkSearch) ToPointer() *AuthenticationTypeSplunkSearch {
	return &e
}
func (e *AuthenticationTypeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = AuthenticationTypeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationTypeSplunkSearch: %v", v)
	}
}

type OauthParamSplunkSearch struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OauthParamSplunkSearch) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamSplunkSearch) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderSplunkSearch struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OauthHeaderSplunkSearch) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderSplunkSearch) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSplunkSearch struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     *TypeSplunkSearch `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunkSearch `json:"connections,omitempty"`
	Pq          *PqSplunkSearch          `json:"pq,omitempty"`
	// Search head base URL. Can be an expression. Default is https://localhost:8089.
	SearchHead *string `default:"https://localhost:8089" json:"searchHead"`
	// Enter Splunk search here. Examples: 'index=myAppLogs level=error channel=myApp' OR '| mstats avg(myStat) as myStat WHERE index=myStatsIndex.'
	Search string `json:"search"`
	// The earliest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-16m@m'
	Earliest *string `default:"-16m@m" json:"earliest"`
	// The latest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-1m@m'
	Latest *string `default:"-1m@m" json:"latest"`
	// A cron schedule on which to run this job
	CronSchedule *string `default:"*/15 * * * *" json:"cronSchedule"`
	// REST API used to create a search
	Endpoint *string `default:"/services/search/v2/jobs/export" json:"endpoint"`
	// Format of the returned output
	OutputMode *OutputMode `default:"json" json:"outputMode"`
	// Optional request parameters to send to the endpoint
	EndpointParams []EndpointParam `json:"endpointParams,omitempty"`
	// Optional request headers to send to the endpoint
	EndpointHeaders []EndpointHeader `json:"endpointHeaders,omitempty"`
	// Collector runtime log level (verbosity)
	LogLevel *LogLevelSplunkSearch `json:"logLevel,omitempty"`
	// HTTP request inactivity timeout. Use 0 for no timeout.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding *string `json:"encoding,omitempty"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
	IgnoreGroupJobsLimit *bool `default:"false" json:"ignoreGroupJobsLimit"`
	// Fields to add to events from this input
	Metadata   []MetadatumSplunkSearch `json:"metadata,omitempty"`
	RetryRules *RetryRulesSplunkSearch `json:"retryRules,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Splunk Search authentication type
	AuthType    *AuthenticationTypeSplunkSearch `default:"basic" json:"authType"`
	Description *string                         `json:"description,omitempty"`
	Username    *string                         `json:"username,omitempty"`
	Password    *string                         `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamSplunkSearch `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OauthHeaderSplunkSearch `json:"oauthHeaders,omitempty"`
}

func (i InputSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkSearch) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSplunkSearch) GetType() *TypeSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunkSearch) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunkSearch) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkSearch) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunkSearch) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunkSearch) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunkSearch) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunkSearch) GetConnections() []ConnectionSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunkSearch) GetPq() *PqSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunkSearch) GetSearchHead() *string {
	if o == nil {
		return nil
	}
	return o.SearchHead
}

func (o *InputSplunkSearch) GetSearch() string {
	if o == nil {
		return ""
	}
	return o.Search
}

func (o *InputSplunkSearch) GetEarliest() *string {
	if o == nil {
		return nil
	}
	return o.Earliest
}

func (o *InputSplunkSearch) GetLatest() *string {
	if o == nil {
		return nil
	}
	return o.Latest
}

func (o *InputSplunkSearch) GetCronSchedule() *string {
	if o == nil {
		return nil
	}
	return o.CronSchedule
}

func (o *InputSplunkSearch) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSplunkSearch) GetOutputMode() *OutputMode {
	if o == nil {
		return nil
	}
	return o.OutputMode
}

func (o *InputSplunkSearch) GetEndpointParams() []EndpointParam {
	if o == nil {
		return nil
	}
	return o.EndpointParams
}

func (o *InputSplunkSearch) GetEndpointHeaders() []EndpointHeader {
	if o == nil {
		return nil
	}
	return o.EndpointHeaders
}

func (o *InputSplunkSearch) GetLogLevel() *LogLevelSplunkSearch {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputSplunkSearch) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputSplunkSearch) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *InputSplunkSearch) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSplunkSearch) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputSplunkSearch) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputSplunkSearch) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputSplunkSearch) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputSplunkSearch) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputSplunkSearch) GetIgnoreGroupJobsLimit() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreGroupJobsLimit
}

func (o *InputSplunkSearch) GetMetadata() []MetadatumSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunkSearch) GetRetryRules() *RetryRulesSplunkSearch {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputSplunkSearch) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunkSearch) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunkSearch) GetAuthType() *AuthenticationTypeSplunkSearch {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputSplunkSearch) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunkSearch) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputSplunkSearch) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputSplunkSearch) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputSplunkSearch) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputSplunkSearch) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputSplunkSearch) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputSplunkSearch) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputSplunkSearch) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputSplunkSearch) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputSplunkSearch) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputSplunkSearch) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputSplunkSearch) GetOauthParams() []OauthParamSplunkSearch {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputSplunkSearch) GetOauthHeaders() []OauthHeaderSplunkSearch {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type CreateInputTypeSplunk string

const (
	CreateInputTypeSplunkSplunk CreateInputTypeSplunk = "splunk"
)

func (e CreateInputTypeSplunk) ToPointer() *CreateInputTypeSplunk {
	return &e
}
func (e *CreateInputTypeSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		*e = CreateInputTypeSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeSplunk: %v", v)
	}
}

type ConnectionSplunk struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSplunk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSplunk) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeSplunk - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeSplunk string

const (
	CreateInputModeSplunkSmart  CreateInputModeSplunk = "smart"
	CreateInputModeSplunkAlways CreateInputModeSplunk = "always"
)

func (e CreateInputModeSplunk) ToPointer() *CreateInputModeSplunk {
	return &e
}
func (e *CreateInputModeSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeSplunk: %v", v)
	}
}

// PqCompressionSplunk - Codec to use to compress the persisted data
type PqCompressionSplunk string

const (
	PqCompressionSplunkNone PqCompressionSplunk = "none"
	PqCompressionSplunkGzip PqCompressionSplunk = "gzip"
)

func (e PqCompressionSplunk) ToPointer() *PqCompressionSplunk {
	return &e
}
func (e *PqCompressionSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionSplunk: %v", v)
	}
}

type PqSplunk struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeSplunk `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionSplunk `default:"none" json:"compress"`
}

func (p PqSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSplunk) GetMode() *CreateInputModeSplunk {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSplunk) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSplunk) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSplunk) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSplunk) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSplunk) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSplunk) GetCompress() *PqCompressionSplunk {
	if o == nil {
		return nil
	}
	return o.Compress
}

type CreateInputMinimumTLSVersionSplunk string

const (
	CreateInputMinimumTLSVersionSplunkTlSv1  CreateInputMinimumTLSVersionSplunk = "TLSv1"
	CreateInputMinimumTLSVersionSplunkTlSv11 CreateInputMinimumTLSVersionSplunk = "TLSv1.1"
	CreateInputMinimumTLSVersionSplunkTlSv12 CreateInputMinimumTLSVersionSplunk = "TLSv1.2"
	CreateInputMinimumTLSVersionSplunkTlSv13 CreateInputMinimumTLSVersionSplunk = "TLSv1.3"
)

func (e CreateInputMinimumTLSVersionSplunk) ToPointer() *CreateInputMinimumTLSVersionSplunk {
	return &e
}
func (e *CreateInputMinimumTLSVersionSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMinimumTLSVersionSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMinimumTLSVersionSplunk: %v", v)
	}
}

type CreateInputMaximumTLSVersionSplunk string

const (
	CreateInputMaximumTLSVersionSplunkTlSv1  CreateInputMaximumTLSVersionSplunk = "TLSv1"
	CreateInputMaximumTLSVersionSplunkTlSv11 CreateInputMaximumTLSVersionSplunk = "TLSv1.1"
	CreateInputMaximumTLSVersionSplunkTlSv12 CreateInputMaximumTLSVersionSplunk = "TLSv1.2"
	CreateInputMaximumTLSVersionSplunkTlSv13 CreateInputMaximumTLSVersionSplunk = "TLSv1.3"
)

func (e CreateInputMaximumTLSVersionSplunk) ToPointer() *CreateInputMaximumTLSVersionSplunk {
	return &e
}
func (e *CreateInputMaximumTLSVersionSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMaximumTLSVersionSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMaximumTLSVersionSplunk: %v", v)
	}
}

type TLSSettingsServerSideSplunk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                               `default:"false" json:"requestCert"`
	RejectUnauthorized any                                 `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                                 `json:"commonNameRegex,omitempty"`
	MinVersion         *CreateInputMinimumTLSVersionSplunk `json:"minVersion,omitempty"`
	MaxVersion         *CreateInputMaximumTLSVersionSplunk `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideSplunk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideSplunk) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideSplunk) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideSplunk) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideSplunk) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideSplunk) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideSplunk) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideSplunk) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideSplunk) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideSplunk) GetMinVersion() *CreateInputMinimumTLSVersionSplunk {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideSplunk) GetMaxVersion() *CreateInputMaximumTLSVersionSplunk {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumSplunk struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSplunk) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSplunk) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokenSplunk struct {
	// Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
}

func (o *AuthTokenSplunk) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *AuthTokenSplunk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

// CreateInputMaxS2SVersion - The highest S2S protocol version to advertise during handshake
type CreateInputMaxS2SVersion string

const (
	CreateInputMaxS2SVersionV3 CreateInputMaxS2SVersion = "v3"
	CreateInputMaxS2SVersionV4 CreateInputMaxS2SVersion = "v4"
)

func (e CreateInputMaxS2SVersion) ToPointer() *CreateInputMaxS2SVersion {
	return &e
}
func (e *CreateInputMaxS2SVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v3":
		fallthrough
	case "v4":
		*e = CreateInputMaxS2SVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMaxS2SVersion: %v", v)
	}
}

// CreateInputCompressionSplunk - Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
type CreateInputCompressionSplunk string

const (
	CreateInputCompressionSplunkDisabled CreateInputCompressionSplunk = "disabled"
	CreateInputCompressionSplunkAuto     CreateInputCompressionSplunk = "auto"
	CreateInputCompressionSplunkAlways   CreateInputCompressionSplunk = "always"
)

func (e CreateInputCompressionSplunk) ToPointer() *CreateInputCompressionSplunk {
	return &e
}
func (e *CreateInputCompressionSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "disabled":
		fallthrough
	case "auto":
		fallthrough
	case "always":
		*e = CreateInputCompressionSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputCompressionSplunk: %v", v)
	}
}

type InputSplunk struct {
	// Unique ID for this input
	ID       string                 `json:"id"`
	Type     *CreateInputTypeSplunk `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunk `json:"connections,omitempty"`
	Pq          *PqSplunk          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                      `json:"port"`
	TLS  *TLSSettingsServerSideSplunk `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumSplunk `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenSplunk `json:"authTokens,omitempty"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *CreateInputMaxS2SVersion `default:"v3" json:"maxS2Sversion"`
	Description   *string                   `json:"description,omitempty"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `default:"true" json:"useFwdTimezone"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `default:"true" json:"dropControlFields"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
	Compress *CreateInputCompressionSplunk `default:"disabled" json:"compress"`
}

func (i InputSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunk) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSplunk) GetType() *CreateInputTypeSplunk {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunk) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunk) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunk) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunk) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunk) GetConnections() []ConnectionSplunk {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunk) GetPq() *PqSplunk {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunk) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSplunk) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputSplunk) GetTLS() *TLSSettingsServerSideSplunk {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSplunk) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSplunk) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSplunk) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSplunk) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSplunk) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSplunk) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSplunk) GetMetadata() []MetadatumSplunk {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunk) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunk) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunk) GetAuthTokens() []AuthTokenSplunk {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputSplunk) GetMaxS2Sversion() *CreateInputMaxS2SVersion {
	if o == nil {
		return nil
	}
	return o.MaxS2Sversion
}

func (o *InputSplunk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunk) GetUseFwdTimezone() *bool {
	if o == nil {
		return nil
	}
	return o.UseFwdTimezone
}

func (o *InputSplunk) GetDropControlFields() *bool {
	if o == nil {
		return nil
	}
	return o.DropControlFields
}

func (o *InputSplunk) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputSplunk) GetCompress() *CreateInputCompressionSplunk {
	if o == nil {
		return nil
	}
	return o.Compress
}

type CreateInputTypeHTTP string

const (
	CreateInputTypeHTTPHTTP CreateInputTypeHTTP = "http"
)

func (e CreateInputTypeHTTP) ToPointer() *CreateInputTypeHTTP {
	return &e
}
func (e *CreateInputTypeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		*e = CreateInputTypeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeHTTP: %v", v)
	}
}

type ConnectionHTTP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionHTTP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeHTTP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeHTTP string

const (
	CreateInputModeHTTPSmart  CreateInputModeHTTP = "smart"
	CreateInputModeHTTPAlways CreateInputModeHTTP = "always"
)

func (e CreateInputModeHTTP) ToPointer() *CreateInputModeHTTP {
	return &e
}
func (e *CreateInputModeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeHTTP: %v", v)
	}
}

// PqCompressionHTTP - Codec to use to compress the persisted data
type PqCompressionHTTP string

const (
	PqCompressionHTTPNone PqCompressionHTTP = "none"
	PqCompressionHTTPGzip PqCompressionHTTP = "gzip"
)

func (e PqCompressionHTTP) ToPointer() *PqCompressionHTTP {
	return &e
}
func (e *PqCompressionHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionHTTP: %v", v)
	}
}

type PqHTTP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeHTTP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionHTTP `default:"none" json:"compress"`
}

func (p PqHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqHTTP) GetMode() *CreateInputModeHTTP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqHTTP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqHTTP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqHTTP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqHTTP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqHTTP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqHTTP) GetCompress() *PqCompressionHTTP {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MinimumTLSVersionHTTP string

const (
	MinimumTLSVersionHTTPTlSv1  MinimumTLSVersionHTTP = "TLSv1"
	MinimumTLSVersionHTTPTlSv11 MinimumTLSVersionHTTP = "TLSv1.1"
	MinimumTLSVersionHTTPTlSv12 MinimumTLSVersionHTTP = "TLSv1.2"
	MinimumTLSVersionHTTPTlSv13 MinimumTLSVersionHTTP = "TLSv1.3"
)

func (e MinimumTLSVersionHTTP) ToPointer() *MinimumTLSVersionHTTP {
	return &e
}
func (e *MinimumTLSVersionHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionHTTP: %v", v)
	}
}

type MaximumTLSVersionHTTP string

const (
	MaximumTLSVersionHTTPTlSv1  MaximumTLSVersionHTTP = "TLSv1"
	MaximumTLSVersionHTTPTlSv11 MaximumTLSVersionHTTP = "TLSv1.1"
	MaximumTLSVersionHTTPTlSv12 MaximumTLSVersionHTTP = "TLSv1.2"
	MaximumTLSVersionHTTPTlSv13 MaximumTLSVersionHTTP = "TLSv1.3"
)

func (e MaximumTLSVersionHTTP) ToPointer() *MaximumTLSVersionHTTP {
	return &e
}
func (e *MaximumTLSVersionHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionHTTP: %v", v)
	}
}

type TLSSettingsServerSideHTTP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool                  `default:"false" json:"requestCert"`
	RejectUnauthorized any                    `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any                    `json:"commonNameRegex,omitempty"`
	MinVersion         *MinimumTLSVersionHTTP `json:"minVersion,omitempty"`
	MaxVersion         *MaximumTLSVersionHTTP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideHTTP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideHTTP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideHTTP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideHTTP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideHTTP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideHTTP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideHTTP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideHTTP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideHTTP) GetMinVersion() *MinimumTLSVersionHTTP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideHTTP) GetMaxVersion() *MaximumTLSVersionHTTP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type CreateInputMetadatumHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *CreateInputMetadatumHTTP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *CreateInputMetadatumHTTP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExtMetadatumHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *AuthTokensExtMetadatumHTTP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *AuthTokensExtMetadatumHTTP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExtHTTP struct {
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokensExtMetadatumHTTP `json:"metadata,omitempty"`
}

func (o *AuthTokensExtHTTP) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *AuthTokensExtHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokensExtHTTP) GetMetadata() []AuthTokensExtMetadatumHTTP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type InputHTTP struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     *CreateInputTypeHTTP `json:"type,omitempty"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionHTTP `json:"connections,omitempty"`
	Pq          *PqHTTP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                   `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideHTTP `json:"tls,omitempty"`
	// Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
	CriblAPI *string `default:"/cribl" json:"criblAPI"`
	// Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
	ElasticAPI *string `default:"/elastic" json:"elasticAPI"`
	// Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
	SplunkHecAPI  *string `default:"/services/collector" json:"splunkHecAPI"`
	SplunkHecAcks *bool   `default:"false" json:"splunkHecAcks"`
	// Fields to add to events from this input
	Metadata []CreateInputMetadatumHTTP `json:"metadata,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []AuthTokensExtHTTP `json:"authTokensExt,omitempty"`
	Description   *string             `json:"description,omitempty"`
}

func (i InputHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTP) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputHTTP) GetType() *CreateInputTypeHTTP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputHTTP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputHTTP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputHTTP) GetConnections() []ConnectionHTTP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputHTTP) GetPq() *PqHTTP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputHTTP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputHTTP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputHTTP) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputHTTP) GetTLS() *TLSSettingsServerSideHTTP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputHTTP) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputHTTP) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputHTTP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputHTTP) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputHTTP) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputHTTP) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputHTTP) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputHTTP) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputHTTP) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputHTTP) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputHTTP) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputHTTP) GetCriblAPI() *string {
	if o == nil {
		return nil
	}
	return o.CriblAPI
}

func (o *InputHTTP) GetElasticAPI() *string {
	if o == nil {
		return nil
	}
	return o.ElasticAPI
}

func (o *InputHTTP) GetSplunkHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.SplunkHecAPI
}

func (o *InputHTTP) GetSplunkHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.SplunkHecAcks
}

func (o *InputHTTP) GetMetadata() []CreateInputMetadatumHTTP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputHTTP) GetAuthTokensExt() []AuthTokensExtHTTP {
	if o == nil {
		return nil
	}
	return o.AuthTokensExt
}

func (o *InputHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateInputTypeMsk string

const (
	CreateInputTypeMskMsk CreateInputTypeMsk = "msk"
)

func (e CreateInputTypeMsk) ToPointer() *CreateInputTypeMsk {
	return &e
}
func (e *CreateInputTypeMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "msk":
		*e = CreateInputTypeMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeMsk: %v", v)
	}
}

type ConnectionMsk struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionMsk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionMsk) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeMsk - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeMsk string

const (
	CreateInputModeMskSmart  CreateInputModeMsk = "smart"
	CreateInputModeMskAlways CreateInputModeMsk = "always"
)

func (e CreateInputModeMsk) ToPointer() *CreateInputModeMsk {
	return &e
}
func (e *CreateInputModeMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeMsk: %v", v)
	}
}

// PqCompressionMsk - Codec to use to compress the persisted data
type PqCompressionMsk string

const (
	PqCompressionMskNone PqCompressionMsk = "none"
	PqCompressionMskGzip PqCompressionMsk = "gzip"
)

func (e PqCompressionMsk) ToPointer() *PqCompressionMsk {
	return &e
}
func (e *PqCompressionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionMsk: %v", v)
	}
}

type PqMsk struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeMsk `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionMsk `default:"none" json:"compress"`
}

func (p PqMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqMsk) GetMode() *CreateInputModeMsk {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqMsk) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqMsk) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqMsk) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqMsk) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqMsk) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqMsk) GetCompress() *PqCompressionMsk {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumMsk struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumMsk) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumMsk) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// CreateInputAuthMsk - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type CreateInputAuthMsk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (c CreateInputAuthMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputAuthMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputAuthMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputAuthMsk) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

type CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk string

const (
	CreateInputKafkaSchemaRegistryMinimumTLSVersionMskTlSv1  CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionMskTlSv11 CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.1"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionMskTlSv12 CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.2"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionMskTlSv13 CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.3"
)

func (e CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk) ToPointer() *CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk {
	return &e
}
func (e *CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk: %v", v)
	}
}

type CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk string

const (
	CreateInputKafkaSchemaRegistryMaximumTLSVersionMskTlSv1  CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionMskTlSv11 CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.1"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionMskTlSv12 CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.2"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionMskTlSv13 CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.3"
)

func (e CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk) ToPointer() *CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk {
	return &e
}
func (e *CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk: %v", v)
	}
}

type CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                                             `json:"passphrase,omitempty"`
	MinVersion *CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk `json:"minVersion,omitempty"`
	MaxVersion *CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk `json:"maxVersion,omitempty"`
}

func (c CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetMinVersion() *CreateInputKafkaSchemaRegistryMinimumTLSVersionMsk {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetMaxVersion() *CreateInputKafkaSchemaRegistryMaximumTLSVersionMsk {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type CreateInputKafkaSchemaRegistryAuthenticationMsk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *CreateInputAuthMsk                                     `json:"auth,omitempty"`
	TLS  *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk `json:"tls,omitempty"`
}

func (c CreateInputKafkaSchemaRegistryAuthenticationMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputKafkaSchemaRegistryAuthenticationMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationMsk) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationMsk) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationMsk) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationMsk) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationMsk) GetAuth() *CreateInputAuthMsk {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationMsk) GetTLS() *CreateInputKafkaSchemaRegistryTLSSettingsClientSideMsk {
	if o == nil {
		return nil
	}
	return o.TLS
}

// CreateInputAuthenticationMethodMsk - AWS authentication method. Choose Auto to use IAM roles.
type CreateInputAuthenticationMethodMsk string

const (
	CreateInputAuthenticationMethodMskAuto   CreateInputAuthenticationMethodMsk = "auto"
	CreateInputAuthenticationMethodMskManual CreateInputAuthenticationMethodMsk = "manual"
	CreateInputAuthenticationMethodMskSecret CreateInputAuthenticationMethodMsk = "secret"
)

func (e CreateInputAuthenticationMethodMsk) ToPointer() *CreateInputAuthenticationMethodMsk {
	return &e
}
func (e *CreateInputAuthenticationMethodMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = CreateInputAuthenticationMethodMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputAuthenticationMethodMsk: %v", v)
	}
}

// CreateInputSignatureVersionMsk - Signature version to use for signing MSK cluster requests
type CreateInputSignatureVersionMsk string

const (
	CreateInputSignatureVersionMskV2 CreateInputSignatureVersionMsk = "v2"
	CreateInputSignatureVersionMskV4 CreateInputSignatureVersionMsk = "v4"
)

func (e CreateInputSignatureVersionMsk) ToPointer() *CreateInputSignatureVersionMsk {
	return &e
}
func (e *CreateInputSignatureVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = CreateInputSignatureVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputSignatureVersionMsk: %v", v)
	}
}

type CreateInputMinimumTLSVersionMsk string

const (
	CreateInputMinimumTLSVersionMskTlSv1  CreateInputMinimumTLSVersionMsk = "TLSv1"
	CreateInputMinimumTLSVersionMskTlSv11 CreateInputMinimumTLSVersionMsk = "TLSv1.1"
	CreateInputMinimumTLSVersionMskTlSv12 CreateInputMinimumTLSVersionMsk = "TLSv1.2"
	CreateInputMinimumTLSVersionMskTlSv13 CreateInputMinimumTLSVersionMsk = "TLSv1.3"
)

func (e CreateInputMinimumTLSVersionMsk) ToPointer() *CreateInputMinimumTLSVersionMsk {
	return &e
}
func (e *CreateInputMinimumTLSVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMinimumTLSVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMinimumTLSVersionMsk: %v", v)
	}
}

type CreateInputMaximumTLSVersionMsk string

const (
	CreateInputMaximumTLSVersionMskTlSv1  CreateInputMaximumTLSVersionMsk = "TLSv1"
	CreateInputMaximumTLSVersionMskTlSv11 CreateInputMaximumTLSVersionMsk = "TLSv1.1"
	CreateInputMaximumTLSVersionMskTlSv12 CreateInputMaximumTLSVersionMsk = "TLSv1.2"
	CreateInputMaximumTLSVersionMskTlSv13 CreateInputMaximumTLSVersionMsk = "TLSv1.3"
)

func (e CreateInputMaximumTLSVersionMsk) ToPointer() *CreateInputMaximumTLSVersionMsk {
	return &e
}
func (e *CreateInputMaximumTLSVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMaximumTLSVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMaximumTLSVersionMsk: %v", v)
	}
}

type CreateInputTLSSettingsClientSideMsk struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                          `json:"passphrase,omitempty"`
	MinVersion *CreateInputMinimumTLSVersionMsk `json:"minVersion,omitempty"`
	MaxVersion *CreateInputMaximumTLSVersionMsk `json:"maxVersion,omitempty"`
}

func (c CreateInputTLSSettingsClientSideMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputTLSSettingsClientSideMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputTLSSettingsClientSideMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputTLSSettingsClientSideMsk) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *CreateInputTLSSettingsClientSideMsk) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *CreateInputTLSSettingsClientSideMsk) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CreateInputTLSSettingsClientSideMsk) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *CreateInputTLSSettingsClientSideMsk) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *CreateInputTLSSettingsClientSideMsk) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *CreateInputTLSSettingsClientSideMsk) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CreateInputTLSSettingsClientSideMsk) GetMinVersion() *CreateInputMinimumTLSVersionMsk {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *CreateInputTLSSettingsClientSideMsk) GetMaxVersion() *CreateInputMaximumTLSVersionMsk {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputMsk struct {
	// Unique ID for this input
	ID       string              `json:"id"`
	Type     *CreateInputTypeMsk `json:"type,omitempty"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionMsk `json:"connections,omitempty"`
	Pq          *PqMsk          `json:"pq,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning *bool `default:"true" json:"fromBeginning"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// Fields to add to events from this input
	Metadata            []MetadatumMsk                                   `json:"metadata,omitempty"`
	KafkaSchemaRegistry *CreateInputKafkaSchemaRegistryAuthenticationMsk `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *CreateInputAuthenticationMethodMsk `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                             `json:"awsSecretKey,omitempty"`
	// Region where the MSK cluster is located
	Region string `json:"region"`
	// MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing MSK cluster requests
	SignatureVersion *CreateInputSignatureVersionMsk `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access MSK
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64                             `default:"3600" json:"durationSeconds"`
	TLS             *CreateInputTLSSettingsClientSideMsk `json:"tls,omitempty"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	Description     *string  `json:"description,omitempty"`
	AwsAPIKey       *string  `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
}

func (i InputMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputMsk) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputMsk) GetType() *CreateInputTypeMsk {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMsk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputMsk) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputMsk) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputMsk) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputMsk) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputMsk) GetConnections() []ConnectionMsk {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputMsk) GetPq() *PqMsk {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputMsk) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputMsk) GetTopics() []string {
	if o == nil {
		return []string{}
	}
	return o.Topics
}

func (o *InputMsk) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputMsk) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputMsk) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputMsk) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputMsk) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputMsk) GetMetadata() []MetadatumMsk {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputMsk) GetKafkaSchemaRegistry() *CreateInputKafkaSchemaRegistryAuthenticationMsk {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputMsk) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputMsk) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputMsk) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputMsk) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputMsk) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputMsk) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputMsk) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputMsk) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputMsk) GetAwsAuthenticationMethod() *CreateInputAuthenticationMethodMsk {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputMsk) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputMsk) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *InputMsk) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputMsk) GetSignatureVersion() *CreateInputSignatureVersionMsk {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputMsk) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputMsk) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputMsk) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputMsk) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputMsk) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputMsk) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputMsk) GetTLS() *CreateInputTLSSettingsClientSideMsk {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputMsk) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputMsk) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputMsk) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputMsk) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputMsk) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputMsk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputMsk) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputMsk) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

type CreateInputTypeKafka string

const (
	CreateInputTypeKafkaKafka CreateInputTypeKafka = "kafka"
)

func (e CreateInputTypeKafka) ToPointer() *CreateInputTypeKafka {
	return &e
}
func (e *CreateInputTypeKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = CreateInputTypeKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputTypeKafka: %v", v)
	}
}

type ConnectionKafka struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionKafka) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionKafka) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// CreateInputModeKafka - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type CreateInputModeKafka string

const (
	CreateInputModeKafkaSmart  CreateInputModeKafka = "smart"
	CreateInputModeKafkaAlways CreateInputModeKafka = "always"
)

func (e CreateInputModeKafka) ToPointer() *CreateInputModeKafka {
	return &e
}
func (e *CreateInputModeKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = CreateInputModeKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputModeKafka: %v", v)
	}
}

// PqCompressionKafka - Codec to use to compress the persisted data
type PqCompressionKafka string

const (
	PqCompressionKafkaNone PqCompressionKafka = "none"
	PqCompressionKafkaGzip PqCompressionKafka = "gzip"
)

func (e PqCompressionKafka) ToPointer() *PqCompressionKafka {
	return &e
}
func (e *PqCompressionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionKafka: %v", v)
	}
}

type PqKafka struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *CreateInputModeKafka `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionKafka `default:"none" json:"compress"`
}

func (p PqKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqKafka) GetMode() *CreateInputModeKafka {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqKafka) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqKafka) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqKafka) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqKafka) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqKafka) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqKafka) GetCompress() *PqCompressionKafka {
	if o == nil {
		return nil
	}
	return o.Compress
}

// CreateInputAuthKafka - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type CreateInputAuthKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (c CreateInputAuthKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputAuthKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputAuthKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputAuthKafka) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

type CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka string

const (
	CreateInputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv1  CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv11 CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.1"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv12 CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.2"
	CreateInputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv13 CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.3"
)

func (e CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka) ToPointer() *CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka {
	return &e
}
func (e *CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka: %v", v)
	}
}

type CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka string

const (
	CreateInputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv1  CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv11 CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.1"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv12 CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.2"
	CreateInputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv13 CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.3"
)

func (e CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka) ToPointer() *CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka {
	return &e
}
func (e *CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka: %v", v)
	}
}

type CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                                               `json:"passphrase,omitempty"`
	MinVersion *CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka `json:"minVersion,omitempty"`
	MaxVersion *CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka `json:"maxVersion,omitempty"`
}

func (c CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetMinVersion() *CreateInputKafkaSchemaRegistryMinimumTLSVersionKafka {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetMaxVersion() *CreateInputKafkaSchemaRegistryMaximumTLSVersionKafka {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type CreateInputKafkaSchemaRegistryAuthenticationKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *CreateInputAuthKafka                                     `json:"auth,omitempty"`
	TLS  *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka `json:"tls,omitempty"`
}

func (c CreateInputKafkaSchemaRegistryAuthenticationKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputKafkaSchemaRegistryAuthenticationKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationKafka) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationKafka) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationKafka) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationKafka) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationKafka) GetAuth() *CreateInputAuthKafka {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *CreateInputKafkaSchemaRegistryAuthenticationKafka) GetTLS() *CreateInputKafkaSchemaRegistryTLSSettingsClientSideKafka {
	if o == nil {
		return nil
	}
	return o.TLS
}

type CreateInputSASLMechanismKafka string

const (
	CreateInputSASLMechanismKafkaPlain       CreateInputSASLMechanismKafka = "plain"
	CreateInputSASLMechanismKafkaScramSha256 CreateInputSASLMechanismKafka = "scram-sha-256"
	CreateInputSASLMechanismKafkaScramSha512 CreateInputSASLMechanismKafka = "scram-sha-512"
	CreateInputSASLMechanismKafkaKerberos    CreateInputSASLMechanismKafka = "kerberos"
)

func (e CreateInputSASLMechanismKafka) ToPointer() *CreateInputSASLMechanismKafka {
	return &e
}
func (e *CreateInputSASLMechanismKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = CreateInputSASLMechanismKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputSASLMechanismKafka: %v", v)
	}
}

// CreateInputAuthenticationKafka - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type CreateInputAuthenticationKafka struct {
	Disabled  *bool                          `default:"true" json:"disabled"`
	Mechanism *CreateInputSASLMechanismKafka `default:"plain" json:"mechanism"`
}

func (c CreateInputAuthenticationKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputAuthenticationKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputAuthenticationKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputAuthenticationKafka) GetMechanism() *CreateInputSASLMechanismKafka {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type CreateInputMinimumTLSVersionKafka string

const (
	CreateInputMinimumTLSVersionKafkaTlSv1  CreateInputMinimumTLSVersionKafka = "TLSv1"
	CreateInputMinimumTLSVersionKafkaTlSv11 CreateInputMinimumTLSVersionKafka = "TLSv1.1"
	CreateInputMinimumTLSVersionKafkaTlSv12 CreateInputMinimumTLSVersionKafka = "TLSv1.2"
	CreateInputMinimumTLSVersionKafkaTlSv13 CreateInputMinimumTLSVersionKafka = "TLSv1.3"
)

func (e CreateInputMinimumTLSVersionKafka) ToPointer() *CreateInputMinimumTLSVersionKafka {
	return &e
}
func (e *CreateInputMinimumTLSVersionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMinimumTLSVersionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMinimumTLSVersionKafka: %v", v)
	}
}

type CreateInputMaximumTLSVersionKafka string

const (
	CreateInputMaximumTLSVersionKafkaTlSv1  CreateInputMaximumTLSVersionKafka = "TLSv1"
	CreateInputMaximumTLSVersionKafkaTlSv11 CreateInputMaximumTLSVersionKafka = "TLSv1.1"
	CreateInputMaximumTLSVersionKafkaTlSv12 CreateInputMaximumTLSVersionKafka = "TLSv1.2"
	CreateInputMaximumTLSVersionKafkaTlSv13 CreateInputMaximumTLSVersionKafka = "TLSv1.3"
)

func (e CreateInputMaximumTLSVersionKafka) ToPointer() *CreateInputMaximumTLSVersionKafka {
	return &e
}
func (e *CreateInputMaximumTLSVersionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = CreateInputMaximumTLSVersionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateInputMaximumTLSVersionKafka: %v", v)
	}
}

type CreateInputTLSSettingsClientSideKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certificates that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string                            `json:"passphrase,omitempty"`
	MinVersion *CreateInputMinimumTLSVersionKafka `json:"minVersion,omitempty"`
	MaxVersion *CreateInputMaximumTLSVersionKafka `json:"maxVersion,omitempty"`
}

func (c CreateInputTLSSettingsClientSideKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateInputTLSSettingsClientSideKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateInputTLSSettingsClientSideKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *CreateInputTLSSettingsClientSideKafka) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *CreateInputTLSSettingsClientSideKafka) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *CreateInputTLSSettingsClientSideKafka) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CreateInputTLSSettingsClientSideKafka) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *CreateInputTLSSettingsClientSideKafka) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *CreateInputTLSSettingsClientSideKafka) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *CreateInputTLSSettingsClientSideKafka) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CreateInputTLSSettingsClientSideKafka) GetMinVersion() *CreateInputMinimumTLSVersionKafka {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *CreateInputTLSSettingsClientSideKafka) GetMaxVersion() *CreateInputMaximumTLSVersionKafka {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumKafka struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumKafka) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumKafka) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKafka struct {
	// Unique ID for this input
	ID       string                `json:"id"`
	Type     *CreateInputTypeKafka `json:"type,omitempty"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKafka `json:"connections,omitempty"`
	Pq          *PqKafka          `json:"pq,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
	Topics []string `json:"topics"`
	// The consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                              `default:"true" json:"fromBeginning"`
	KafkaSchemaRegistry *CreateInputKafkaSchemaRegistryAuthenticationKafka `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *CreateInputAuthenticationKafka        `json:"sasl,omitempty"`
	TLS  *CreateInputTLSSettingsClientSideKafka `json:"tls,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group-management facilities.
	//       If the client sends no heartbeats to the broker before the timeout expires,
	//       the broker will remove the client from the group and initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance begins.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
	//       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
	//       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer re-creates a socket
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Fields to add to events from this input
	Metadata    []MetadatumKafka `json:"metadata,omitempty"`
	Description *string          `json:"description,omitempty"`
}

func (i InputKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKafka) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputKafka) GetType() *CreateInputTypeKafka {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafka) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKafka) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKafka) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKafka) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKafka) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKafka) GetConnections() []ConnectionKafka {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKafka) GetPq() *PqKafka {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKafka) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputKafka) GetTopics() []string {
	if o == nil {
		return []string{}
	}
	return o.Topics
}

func (o *InputKafka) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputKafka) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputKafka) GetKafkaSchemaRegistry() *CreateInputKafkaSchemaRegistryAuthenticationKafka {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputKafka) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputKafka) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputKafka) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputKafka) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputKafka) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputKafka) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputKafka) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputKafka) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputKafka) GetSasl() *CreateInputAuthenticationKafka {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputKafka) GetTLS() *CreateInputTLSSettingsClientSideKafka {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputKafka) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputKafka) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputKafka) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputKafka) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputKafka) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputKafka) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputKafka) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputKafka) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputKafka) GetMetadata() []MetadatumKafka {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKafka) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type CreateInputRequestType string

const (
	CreateInputRequestTypeInputCollection           CreateInputRequestType = "InputCollection"
	CreateInputRequestTypeInputKafka                CreateInputRequestType = "InputKafka"
	CreateInputRequestTypeInputMsk                  CreateInputRequestType = "InputMsk"
	CreateInputRequestTypeInputHTTP                 CreateInputRequestType = "InputHttp"
	CreateInputRequestTypeInputSplunk               CreateInputRequestType = "InputSplunk"
	CreateInputRequestTypeInputSplunkSearch         CreateInputRequestType = "InputSplunkSearch"
	CreateInputRequestTypeInputSplunkHec            CreateInputRequestType = "InputSplunkHec"
	CreateInputRequestTypeInputAzureBlob            CreateInputRequestType = "InputAzureBlob"
	CreateInputRequestTypeInputElastic              CreateInputRequestType = "InputElastic"
	CreateInputRequestTypeInputConfluentCloud       CreateInputRequestType = "InputConfluentCloud"
	CreateInputRequestTypeInputGrafana              CreateInputRequestType = "InputGrafana"
	CreateInputRequestTypeInputLoki                 CreateInputRequestType = "InputLoki"
	CreateInputRequestTypeInputPrometheusRw         CreateInputRequestType = "InputPrometheusRw"
	CreateInputRequestTypeInputPrometheus           CreateInputRequestType = "InputPrometheus"
	CreateInputRequestTypeInputEdgePrometheus       CreateInputRequestType = "InputEdgePrometheus"
	CreateInputRequestTypeInputOffice365Mgmt        CreateInputRequestType = "InputOffice365Mgmt"
	CreateInputRequestTypeInputOffice365Service     CreateInputRequestType = "InputOffice365Service"
	CreateInputRequestTypeInputOffice365MsgTrace    CreateInputRequestType = "InputOffice365MsgTrace"
	CreateInputRequestTypeInputEventhub             CreateInputRequestType = "InputEventhub"
	CreateInputRequestTypeInputExec                 CreateInputRequestType = "InputExec"
	CreateInputRequestTypeInputFirehose             CreateInputRequestType = "InputFirehose"
	CreateInputRequestTypeInputGooglePubsub         CreateInputRequestType = "InputGooglePubsub"
	CreateInputRequestTypeInputCribl                CreateInputRequestType = "InputCribl"
	CreateInputRequestTypeInputCriblTCP             CreateInputRequestType = "InputCriblTcp"
	CreateInputRequestTypeInputCriblHTTP            CreateInputRequestType = "InputCriblHttp"
	CreateInputRequestTypeInputCriblLakeHTTP        CreateInputRequestType = "InputCriblLakeHttp"
	CreateInputRequestTypeInputTcpjson              CreateInputRequestType = "InputTcpjson"
	CreateInputRequestTypeInputSystemMetrics        CreateInputRequestType = "InputSystemMetrics"
	CreateInputRequestTypeInputSystemState          CreateInputRequestType = "InputSystemState"
	CreateInputRequestTypeInputKubeMetrics          CreateInputRequestType = "InputKubeMetrics"
	CreateInputRequestTypeInputKubeLogs             CreateInputRequestType = "InputKubeLogs"
	CreateInputRequestTypeInputKubeEvents           CreateInputRequestType = "InputKubeEvents"
	CreateInputRequestTypeInputWindowsMetrics       CreateInputRequestType = "InputWindowsMetrics"
	CreateInputRequestTypeInputCrowdstrike          CreateInputRequestType = "InputCrowdstrike"
	CreateInputRequestTypeInputDatadogAgent         CreateInputRequestType = "InputDatadogAgent"
	CreateInputRequestTypeInputDatagen              CreateInputRequestType = "InputDatagen"
	CreateInputRequestTypeInputHTTPRaw              CreateInputRequestType = "InputHttpRaw"
	CreateInputRequestTypeInputKinesis              CreateInputRequestType = "InputKinesis"
	CreateInputRequestTypeInputCriblmetrics         CreateInputRequestType = "InputCriblmetrics"
	CreateInputRequestTypeInputMetrics              CreateInputRequestType = "InputMetrics"
	CreateInputRequestTypeInputS3                   CreateInputRequestType = "InputS3"
	CreateInputRequestTypeInputS3Inventory          CreateInputRequestType = "InputS3Inventory"
	CreateInputRequestTypeInputSnmp                 CreateInputRequestType = "InputSnmp"
	CreateInputRequestTypeInputOpenTelemetry        CreateInputRequestType = "InputOpenTelemetry"
	CreateInputRequestTypeInputModelDrivenTelemetry CreateInputRequestType = "InputModelDrivenTelemetry"
	CreateInputRequestTypeInputSqs                  CreateInputRequestType = "InputSqs"
	CreateInputRequestTypeInputSyslog               CreateInputRequestType = "InputSyslog"
	CreateInputRequestTypeInputFile                 CreateInputRequestType = "InputFile"
	CreateInputRequestTypeInputTCP                  CreateInputRequestType = "InputTcp"
	CreateInputRequestTypeInputAppscope             CreateInputRequestType = "InputAppscope"
	CreateInputRequestTypeInputWef                  CreateInputRequestType = "InputWef"
	CreateInputRequestTypeInputWinEventLogs         CreateInputRequestType = "InputWinEventLogs"
	CreateInputRequestTypeInputRawUDP               CreateInputRequestType = "InputRawUdp"
	CreateInputRequestTypeInputJournalFiles         CreateInputRequestType = "InputJournalFiles"
	CreateInputRequestTypeInputWiz                  CreateInputRequestType = "InputWiz"
	CreateInputRequestTypeInputNetflow              CreateInputRequestType = "InputNetflow"
	CreateInputRequestTypeInputSecurityLake         CreateInputRequestType = "InputSecurityLake"
	CreateInputRequestTypeInputZscalerHec           CreateInputRequestType = "InputZscalerHec"
)

// CreateInputRequest - New Source object
type CreateInputRequest struct {
	InputCollection           *components.InputCollection     `queryParam:"inline"`
	InputKafka                *InputKafka                     `queryParam:"inline"`
	InputMsk                  *InputMsk                       `queryParam:"inline"`
	InputHTTP                 *InputHTTP                      `queryParam:"inline"`
	InputSplunk               *InputSplunk                    `queryParam:"inline"`
	InputSplunkSearch         *InputSplunkSearch              `queryParam:"inline"`
	InputSplunkHec            *InputSplunkHec                 `queryParam:"inline"`
	InputAzureBlob            *InputAzureBlob                 `queryParam:"inline"`
	InputElastic              *InputElastic                   `queryParam:"inline"`
	InputConfluentCloud       *InputConfluentCloud            `queryParam:"inline"`
	InputGrafana              *InputGrafana                   `queryParam:"inline"`
	InputLoki                 *InputLoki                      `queryParam:"inline"`
	InputPrometheusRw         *InputPrometheusRw              `queryParam:"inline"`
	InputPrometheus           *InputPrometheus                `queryParam:"inline"`
	InputEdgePrometheus       *InputEdgePrometheus            `queryParam:"inline"`
	InputOffice365Mgmt        *InputOffice365Mgmt             `queryParam:"inline"`
	InputOffice365Service     *InputOffice365Service          `queryParam:"inline"`
	InputOffice365MsgTrace    *InputOffice365MsgTrace         `queryParam:"inline"`
	InputEventhub             *InputEventhub                  `queryParam:"inline"`
	InputExec                 *InputExec                      `queryParam:"inline"`
	InputFirehose             *InputFirehose                  `queryParam:"inline"`
	InputGooglePubsub         *InputGooglePubsub              `queryParam:"inline"`
	InputCribl                *components.InputCribl          `queryParam:"inline"`
	InputCriblTCP             *InputCriblTCP                  `queryParam:"inline"`
	InputCriblHTTP            *InputCriblHTTP                 `queryParam:"inline"`
	InputCriblLakeHTTP        *InputCriblLakeHTTP             `queryParam:"inline"`
	InputTcpjson              *InputTcpjson                   `queryParam:"inline"`
	InputSystemMetrics        *components.InputSystemMetrics  `queryParam:"inline"`
	InputSystemState          *components.InputSystemState    `queryParam:"inline"`
	InputKubeMetrics          *components.InputKubeMetrics    `queryParam:"inline"`
	InputKubeLogs             *components.InputKubeLogs       `queryParam:"inline"`
	InputKubeEvents           *components.InputKubeEvents     `queryParam:"inline"`
	InputWindowsMetrics       *components.InputWindowsMetrics `queryParam:"inline"`
	InputCrowdstrike          *InputCrowdstrike               `queryParam:"inline"`
	InputDatadogAgent         *InputDatadogAgent              `queryParam:"inline"`
	InputDatagen              *InputDatagen                   `queryParam:"inline"`
	InputHTTPRaw              *InputHTTPRaw                   `queryParam:"inline"`
	InputKinesis              *InputKinesis                   `queryParam:"inline"`
	InputCriblmetrics         *components.InputCriblmetrics   `queryParam:"inline"`
	InputMetrics              *InputMetrics                   `queryParam:"inline"`
	InputS3                   *InputS3                        `queryParam:"inline"`
	InputS3Inventory          *InputS3Inventory               `queryParam:"inline"`
	InputSnmp                 *InputSnmp                      `queryParam:"inline"`
	InputOpenTelemetry        *InputOpenTelemetry             `queryParam:"inline"`
	InputModelDrivenTelemetry *InputModelDrivenTelemetry      `queryParam:"inline"`
	InputSqs                  *InputSqs                       `queryParam:"inline"`
	InputSyslog               *InputSyslog                    `queryParam:"inline"`
	InputFile                 *components.InputFile           `queryParam:"inline"`
	InputTCP                  *InputTCP                       `queryParam:"inline"`
	InputAppscope             *components.InputAppscope       `queryParam:"inline"`
	InputWef                  *InputWef                       `queryParam:"inline"`
	InputWinEventLogs         *InputWinEventLogs              `queryParam:"inline"`
	InputRawUDP               *InputRawUDP                    `queryParam:"inline"`
	InputJournalFiles         *InputJournalFiles              `queryParam:"inline"`
	InputWiz                  *InputWiz                       `queryParam:"inline"`
	InputNetflow              *InputNetflow                   `queryParam:"inline"`
	InputSecurityLake         *InputSecurityLake              `queryParam:"inline"`
	InputZscalerHec           *InputZscalerHec                `queryParam:"inline"`

	Type CreateInputRequestType
}

func CreateCreateInputRequestInputCollection(inputCollection components.InputCollection) CreateInputRequest {
	typ := CreateInputRequestTypeInputCollection

	return CreateInputRequest{
		InputCollection: &inputCollection,
		Type:            typ,
	}
}

func CreateCreateInputRequestInputKafka(inputKafka InputKafka) CreateInputRequest {
	typ := CreateInputRequestTypeInputKafka

	return CreateInputRequest{
		InputKafka: &inputKafka,
		Type:       typ,
	}
}

func CreateCreateInputRequestInputMsk(inputMsk InputMsk) CreateInputRequest {
	typ := CreateInputRequestTypeInputMsk

	return CreateInputRequest{
		InputMsk: &inputMsk,
		Type:     typ,
	}
}

func CreateCreateInputRequestInputHTTP(inputHTTP InputHTTP) CreateInputRequest {
	typ := CreateInputRequestTypeInputHTTP

	return CreateInputRequest{
		InputHTTP: &inputHTTP,
		Type:      typ,
	}
}

func CreateCreateInputRequestInputSplunk(inputSplunk InputSplunk) CreateInputRequest {
	typ := CreateInputRequestTypeInputSplunk

	return CreateInputRequest{
		InputSplunk: &inputSplunk,
		Type:        typ,
	}
}

func CreateCreateInputRequestInputSplunkSearch(inputSplunkSearch InputSplunkSearch) CreateInputRequest {
	typ := CreateInputRequestTypeInputSplunkSearch

	return CreateInputRequest{
		InputSplunkSearch: &inputSplunkSearch,
		Type:              typ,
	}
}

func CreateCreateInputRequestInputSplunkHec(inputSplunkHec InputSplunkHec) CreateInputRequest {
	typ := CreateInputRequestTypeInputSplunkHec

	return CreateInputRequest{
		InputSplunkHec: &inputSplunkHec,
		Type:           typ,
	}
}

func CreateCreateInputRequestInputAzureBlob(inputAzureBlob InputAzureBlob) CreateInputRequest {
	typ := CreateInputRequestTypeInputAzureBlob

	return CreateInputRequest{
		InputAzureBlob: &inputAzureBlob,
		Type:           typ,
	}
}

func CreateCreateInputRequestInputElastic(inputElastic InputElastic) CreateInputRequest {
	typ := CreateInputRequestTypeInputElastic

	return CreateInputRequest{
		InputElastic: &inputElastic,
		Type:         typ,
	}
}

func CreateCreateInputRequestInputConfluentCloud(inputConfluentCloud InputConfluentCloud) CreateInputRequest {
	typ := CreateInputRequestTypeInputConfluentCloud

	return CreateInputRequest{
		InputConfluentCloud: &inputConfluentCloud,
		Type:                typ,
	}
}

func CreateCreateInputRequestInputGrafana(inputGrafana InputGrafana) CreateInputRequest {
	typ := CreateInputRequestTypeInputGrafana

	return CreateInputRequest{
		InputGrafana: &inputGrafana,
		Type:         typ,
	}
}

func CreateCreateInputRequestInputLoki(inputLoki InputLoki) CreateInputRequest {
	typ := CreateInputRequestTypeInputLoki

	return CreateInputRequest{
		InputLoki: &inputLoki,
		Type:      typ,
	}
}

func CreateCreateInputRequestInputPrometheusRw(inputPrometheusRw InputPrometheusRw) CreateInputRequest {
	typ := CreateInputRequestTypeInputPrometheusRw

	return CreateInputRequest{
		InputPrometheusRw: &inputPrometheusRw,
		Type:              typ,
	}
}

func CreateCreateInputRequestInputPrometheus(inputPrometheus InputPrometheus) CreateInputRequest {
	typ := CreateInputRequestTypeInputPrometheus

	return CreateInputRequest{
		InputPrometheus: &inputPrometheus,
		Type:            typ,
	}
}

func CreateCreateInputRequestInputEdgePrometheus(inputEdgePrometheus InputEdgePrometheus) CreateInputRequest {
	typ := CreateInputRequestTypeInputEdgePrometheus

	return CreateInputRequest{
		InputEdgePrometheus: &inputEdgePrometheus,
		Type:                typ,
	}
}

func CreateCreateInputRequestInputOffice365Mgmt(inputOffice365Mgmt InputOffice365Mgmt) CreateInputRequest {
	typ := CreateInputRequestTypeInputOffice365Mgmt

	return CreateInputRequest{
		InputOffice365Mgmt: &inputOffice365Mgmt,
		Type:               typ,
	}
}

func CreateCreateInputRequestInputOffice365Service(inputOffice365Service InputOffice365Service) CreateInputRequest {
	typ := CreateInputRequestTypeInputOffice365Service

	return CreateInputRequest{
		InputOffice365Service: &inputOffice365Service,
		Type:                  typ,
	}
}

func CreateCreateInputRequestInputOffice365MsgTrace(inputOffice365MsgTrace InputOffice365MsgTrace) CreateInputRequest {
	typ := CreateInputRequestTypeInputOffice365MsgTrace

	return CreateInputRequest{
		InputOffice365MsgTrace: &inputOffice365MsgTrace,
		Type:                   typ,
	}
}

func CreateCreateInputRequestInputEventhub(inputEventhub InputEventhub) CreateInputRequest {
	typ := CreateInputRequestTypeInputEventhub

	return CreateInputRequest{
		InputEventhub: &inputEventhub,
		Type:          typ,
	}
}

func CreateCreateInputRequestInputExec(inputExec InputExec) CreateInputRequest {
	typ := CreateInputRequestTypeInputExec

	return CreateInputRequest{
		InputExec: &inputExec,
		Type:      typ,
	}
}

func CreateCreateInputRequestInputFirehose(inputFirehose InputFirehose) CreateInputRequest {
	typ := CreateInputRequestTypeInputFirehose

	return CreateInputRequest{
		InputFirehose: &inputFirehose,
		Type:          typ,
	}
}

func CreateCreateInputRequestInputGooglePubsub(inputGooglePubsub InputGooglePubsub) CreateInputRequest {
	typ := CreateInputRequestTypeInputGooglePubsub

	return CreateInputRequest{
		InputGooglePubsub: &inputGooglePubsub,
		Type:              typ,
	}
}

func CreateCreateInputRequestInputCribl(inputCribl components.InputCribl) CreateInputRequest {
	typ := CreateInputRequestTypeInputCribl

	return CreateInputRequest{
		InputCribl: &inputCribl,
		Type:       typ,
	}
}

func CreateCreateInputRequestInputCriblTCP(inputCriblTCP InputCriblTCP) CreateInputRequest {
	typ := CreateInputRequestTypeInputCriblTCP

	return CreateInputRequest{
		InputCriblTCP: &inputCriblTCP,
		Type:          typ,
	}
}

func CreateCreateInputRequestInputCriblHTTP(inputCriblHTTP InputCriblHTTP) CreateInputRequest {
	typ := CreateInputRequestTypeInputCriblHTTP

	return CreateInputRequest{
		InputCriblHTTP: &inputCriblHTTP,
		Type:           typ,
	}
}

func CreateCreateInputRequestInputCriblLakeHTTP(inputCriblLakeHTTP InputCriblLakeHTTP) CreateInputRequest {
	typ := CreateInputRequestTypeInputCriblLakeHTTP

	return CreateInputRequest{
		InputCriblLakeHTTP: &inputCriblLakeHTTP,
		Type:               typ,
	}
}

func CreateCreateInputRequestInputTcpjson(inputTcpjson InputTcpjson) CreateInputRequest {
	typ := CreateInputRequestTypeInputTcpjson

	return CreateInputRequest{
		InputTcpjson: &inputTcpjson,
		Type:         typ,
	}
}

func CreateCreateInputRequestInputSystemMetrics(inputSystemMetrics components.InputSystemMetrics) CreateInputRequest {
	typ := CreateInputRequestTypeInputSystemMetrics

	return CreateInputRequest{
		InputSystemMetrics: &inputSystemMetrics,
		Type:               typ,
	}
}

func CreateCreateInputRequestInputSystemState(inputSystemState components.InputSystemState) CreateInputRequest {
	typ := CreateInputRequestTypeInputSystemState

	return CreateInputRequest{
		InputSystemState: &inputSystemState,
		Type:             typ,
	}
}

func CreateCreateInputRequestInputKubeMetrics(inputKubeMetrics components.InputKubeMetrics) CreateInputRequest {
	typ := CreateInputRequestTypeInputKubeMetrics

	return CreateInputRequest{
		InputKubeMetrics: &inputKubeMetrics,
		Type:             typ,
	}
}

func CreateCreateInputRequestInputKubeLogs(inputKubeLogs components.InputKubeLogs) CreateInputRequest {
	typ := CreateInputRequestTypeInputKubeLogs

	return CreateInputRequest{
		InputKubeLogs: &inputKubeLogs,
		Type:          typ,
	}
}

func CreateCreateInputRequestInputKubeEvents(inputKubeEvents components.InputKubeEvents) CreateInputRequest {
	typ := CreateInputRequestTypeInputKubeEvents

	return CreateInputRequest{
		InputKubeEvents: &inputKubeEvents,
		Type:            typ,
	}
}

func CreateCreateInputRequestInputWindowsMetrics(inputWindowsMetrics components.InputWindowsMetrics) CreateInputRequest {
	typ := CreateInputRequestTypeInputWindowsMetrics

	return CreateInputRequest{
		InputWindowsMetrics: &inputWindowsMetrics,
		Type:                typ,
	}
}

func CreateCreateInputRequestInputCrowdstrike(inputCrowdstrike InputCrowdstrike) CreateInputRequest {
	typ := CreateInputRequestTypeInputCrowdstrike

	return CreateInputRequest{
		InputCrowdstrike: &inputCrowdstrike,
		Type:             typ,
	}
}

func CreateCreateInputRequestInputDatadogAgent(inputDatadogAgent InputDatadogAgent) CreateInputRequest {
	typ := CreateInputRequestTypeInputDatadogAgent

	return CreateInputRequest{
		InputDatadogAgent: &inputDatadogAgent,
		Type:              typ,
	}
}

func CreateCreateInputRequestInputDatagen(inputDatagen InputDatagen) CreateInputRequest {
	typ := CreateInputRequestTypeInputDatagen

	return CreateInputRequest{
		InputDatagen: &inputDatagen,
		Type:         typ,
	}
}

func CreateCreateInputRequestInputHTTPRaw(inputHTTPRaw InputHTTPRaw) CreateInputRequest {
	typ := CreateInputRequestTypeInputHTTPRaw

	return CreateInputRequest{
		InputHTTPRaw: &inputHTTPRaw,
		Type:         typ,
	}
}

func CreateCreateInputRequestInputKinesis(inputKinesis InputKinesis) CreateInputRequest {
	typ := CreateInputRequestTypeInputKinesis

	return CreateInputRequest{
		InputKinesis: &inputKinesis,
		Type:         typ,
	}
}

func CreateCreateInputRequestInputCriblmetrics(inputCriblmetrics components.InputCriblmetrics) CreateInputRequest {
	typ := CreateInputRequestTypeInputCriblmetrics

	return CreateInputRequest{
		InputCriblmetrics: &inputCriblmetrics,
		Type:              typ,
	}
}

func CreateCreateInputRequestInputMetrics(inputMetrics InputMetrics) CreateInputRequest {
	typ := CreateInputRequestTypeInputMetrics

	return CreateInputRequest{
		InputMetrics: &inputMetrics,
		Type:         typ,
	}
}

func CreateCreateInputRequestInputS3(inputS3 InputS3) CreateInputRequest {
	typ := CreateInputRequestTypeInputS3

	return CreateInputRequest{
		InputS3: &inputS3,
		Type:    typ,
	}
}

func CreateCreateInputRequestInputS3Inventory(inputS3Inventory InputS3Inventory) CreateInputRequest {
	typ := CreateInputRequestTypeInputS3Inventory

	return CreateInputRequest{
		InputS3Inventory: &inputS3Inventory,
		Type:             typ,
	}
}

func CreateCreateInputRequestInputSnmp(inputSnmp InputSnmp) CreateInputRequest {
	typ := CreateInputRequestTypeInputSnmp

	return CreateInputRequest{
		InputSnmp: &inputSnmp,
		Type:      typ,
	}
}

func CreateCreateInputRequestInputOpenTelemetry(inputOpenTelemetry InputOpenTelemetry) CreateInputRequest {
	typ := CreateInputRequestTypeInputOpenTelemetry

	return CreateInputRequest{
		InputOpenTelemetry: &inputOpenTelemetry,
		Type:               typ,
	}
}

func CreateCreateInputRequestInputModelDrivenTelemetry(inputModelDrivenTelemetry InputModelDrivenTelemetry) CreateInputRequest {
	typ := CreateInputRequestTypeInputModelDrivenTelemetry

	return CreateInputRequest{
		InputModelDrivenTelemetry: &inputModelDrivenTelemetry,
		Type:                      typ,
	}
}

func CreateCreateInputRequestInputSqs(inputSqs InputSqs) CreateInputRequest {
	typ := CreateInputRequestTypeInputSqs

	return CreateInputRequest{
		InputSqs: &inputSqs,
		Type:     typ,
	}
}

func CreateCreateInputRequestInputSyslog(inputSyslog InputSyslog) CreateInputRequest {
	typ := CreateInputRequestTypeInputSyslog

	return CreateInputRequest{
		InputSyslog: &inputSyslog,
		Type:        typ,
	}
}

func CreateCreateInputRequestInputFile(inputFile components.InputFile) CreateInputRequest {
	typ := CreateInputRequestTypeInputFile

	return CreateInputRequest{
		InputFile: &inputFile,
		Type:      typ,
	}
}

func CreateCreateInputRequestInputTCP(inputTCP InputTCP) CreateInputRequest {
	typ := CreateInputRequestTypeInputTCP

	return CreateInputRequest{
		InputTCP: &inputTCP,
		Type:     typ,
	}
}

func CreateCreateInputRequestInputAppscope(inputAppscope components.InputAppscope) CreateInputRequest {
	typ := CreateInputRequestTypeInputAppscope

	return CreateInputRequest{
		InputAppscope: &inputAppscope,
		Type:          typ,
	}
}

func CreateCreateInputRequestInputWef(inputWef InputWef) CreateInputRequest {
	typ := CreateInputRequestTypeInputWef

	return CreateInputRequest{
		InputWef: &inputWef,
		Type:     typ,
	}
}

func CreateCreateInputRequestInputWinEventLogs(inputWinEventLogs InputWinEventLogs) CreateInputRequest {
	typ := CreateInputRequestTypeInputWinEventLogs

	return CreateInputRequest{
		InputWinEventLogs: &inputWinEventLogs,
		Type:              typ,
	}
}

func CreateCreateInputRequestInputRawUDP(inputRawUDP InputRawUDP) CreateInputRequest {
	typ := CreateInputRequestTypeInputRawUDP

	return CreateInputRequest{
		InputRawUDP: &inputRawUDP,
		Type:        typ,
	}
}

func CreateCreateInputRequestInputJournalFiles(inputJournalFiles InputJournalFiles) CreateInputRequest {
	typ := CreateInputRequestTypeInputJournalFiles

	return CreateInputRequest{
		InputJournalFiles: &inputJournalFiles,
		Type:              typ,
	}
}

func CreateCreateInputRequestInputWiz(inputWiz InputWiz) CreateInputRequest {
	typ := CreateInputRequestTypeInputWiz

	return CreateInputRequest{
		InputWiz: &inputWiz,
		Type:     typ,
	}
}

func CreateCreateInputRequestInputNetflow(inputNetflow InputNetflow) CreateInputRequest {
	typ := CreateInputRequestTypeInputNetflow

	return CreateInputRequest{
		InputNetflow: &inputNetflow,
		Type:         typ,
	}
}

func CreateCreateInputRequestInputSecurityLake(inputSecurityLake InputSecurityLake) CreateInputRequest {
	typ := CreateInputRequestTypeInputSecurityLake

	return CreateInputRequest{
		InputSecurityLake: &inputSecurityLake,
		Type:              typ,
	}
}

func CreateCreateInputRequestInputZscalerHec(inputZscalerHec InputZscalerHec) CreateInputRequest {
	typ := CreateInputRequestTypeInputZscalerHec

	return CreateInputRequest{
		InputZscalerHec: &inputZscalerHec,
		Type:            typ,
	}
}

func (u *CreateInputRequest) UnmarshalJSON(data []byte) error {

	var inputCribl components.InputCribl = components.InputCribl{}
	if err := utils.UnmarshalJSON(data, &inputCribl, "", true, true); err == nil {
		u.InputCribl = &inputCribl
		u.Type = CreateInputRequestTypeInputCribl
		return nil
	}

	var inputKubeEvents components.InputKubeEvents = components.InputKubeEvents{}
	if err := utils.UnmarshalJSON(data, &inputKubeEvents, "", true, true); err == nil {
		u.InputKubeEvents = &inputKubeEvents
		u.Type = CreateInputRequestTypeInputKubeEvents
		return nil
	}

	var inputDatagen InputDatagen = InputDatagen{}
	if err := utils.UnmarshalJSON(data, &inputDatagen, "", true, true); err == nil {
		u.InputDatagen = &inputDatagen
		u.Type = CreateInputRequestTypeInputDatagen
		return nil
	}

	var inputCriblmetrics components.InputCriblmetrics = components.InputCriblmetrics{}
	if err := utils.UnmarshalJSON(data, &inputCriblmetrics, "", true, true); err == nil {
		u.InputCriblmetrics = &inputCriblmetrics
		u.Type = CreateInputRequestTypeInputCriblmetrics
		return nil
	}

	var inputKubeMetrics components.InputKubeMetrics = components.InputKubeMetrics{}
	if err := utils.UnmarshalJSON(data, &inputKubeMetrics, "", true, true); err == nil {
		u.InputKubeMetrics = &inputKubeMetrics
		u.Type = CreateInputRequestTypeInputKubeMetrics
		return nil
	}

	var inputSystemState components.InputSystemState = components.InputSystemState{}
	if err := utils.UnmarshalJSON(data, &inputSystemState, "", true, true); err == nil {
		u.InputSystemState = &inputSystemState
		u.Type = CreateInputRequestTypeInputSystemState
		return nil
	}

	var inputCollection components.InputCollection = components.InputCollection{}
	if err := utils.UnmarshalJSON(data, &inputCollection, "", true, true); err == nil {
		u.InputCollection = &inputCollection
		u.Type = CreateInputRequestTypeInputCollection
		return nil
	}

	var inputSystemMetrics components.InputSystemMetrics = components.InputSystemMetrics{}
	if err := utils.UnmarshalJSON(data, &inputSystemMetrics, "", true, true); err == nil {
		u.InputSystemMetrics = &inputSystemMetrics
		u.Type = CreateInputRequestTypeInputSystemMetrics
		return nil
	}

	var inputModelDrivenTelemetry InputModelDrivenTelemetry = InputModelDrivenTelemetry{}
	if err := utils.UnmarshalJSON(data, &inputModelDrivenTelemetry, "", true, true); err == nil {
		u.InputModelDrivenTelemetry = &inputModelDrivenTelemetry
		u.Type = CreateInputRequestTypeInputModelDrivenTelemetry
		return nil
	}

	var inputWindowsMetrics components.InputWindowsMetrics = components.InputWindowsMetrics{}
	if err := utils.UnmarshalJSON(data, &inputWindowsMetrics, "", true, true); err == nil {
		u.InputWindowsMetrics = &inputWindowsMetrics
		u.Type = CreateInputRequestTypeInputWindowsMetrics
		return nil
	}

	var inputJournalFiles InputJournalFiles = InputJournalFiles{}
	if err := utils.UnmarshalJSON(data, &inputJournalFiles, "", true, true); err == nil {
		u.InputJournalFiles = &inputJournalFiles
		u.Type = CreateInputRequestTypeInputJournalFiles
		return nil
	}

	var inputRawUDP InputRawUDP = InputRawUDP{}
	if err := utils.UnmarshalJSON(data, &inputRawUDP, "", true, true); err == nil {
		u.InputRawUDP = &inputRawUDP
		u.Type = CreateInputRequestTypeInputRawUDP
		return nil
	}

	var inputWinEventLogs InputWinEventLogs = InputWinEventLogs{}
	if err := utils.UnmarshalJSON(data, &inputWinEventLogs, "", true, true); err == nil {
		u.InputWinEventLogs = &inputWinEventLogs
		u.Type = CreateInputRequestTypeInputWinEventLogs
		return nil
	}

	var inputExec InputExec = InputExec{}
	if err := utils.UnmarshalJSON(data, &inputExec, "", true, true); err == nil {
		u.InputExec = &inputExec
		u.Type = CreateInputRequestTypeInputExec
		return nil
	}

	var inputKubeLogs components.InputKubeLogs = components.InputKubeLogs{}
	if err := utils.UnmarshalJSON(data, &inputKubeLogs, "", true, true); err == nil {
		u.InputKubeLogs = &inputKubeLogs
		u.Type = CreateInputRequestTypeInputKubeLogs
		return nil
	}

	var inputMetrics InputMetrics = InputMetrics{}
	if err := utils.UnmarshalJSON(data, &inputMetrics, "", true, true); err == nil {
		u.InputMetrics = &inputMetrics
		u.Type = CreateInputRequestTypeInputMetrics
		return nil
	}

	var inputSnmp InputSnmp = InputSnmp{}
	if err := utils.UnmarshalJSON(data, &inputSnmp, "", true, true); err == nil {
		u.InputSnmp = &inputSnmp
		u.Type = CreateInputRequestTypeInputSnmp
		return nil
	}

	var inputCriblTCP InputCriblTCP = InputCriblTCP{}
	if err := utils.UnmarshalJSON(data, &inputCriblTCP, "", true, true); err == nil {
		u.InputCriblTCP = &inputCriblTCP
		u.Type = CreateInputRequestTypeInputCriblTCP
		return nil
	}

	var inputNetflow InputNetflow = InputNetflow{}
	if err := utils.UnmarshalJSON(data, &inputNetflow, "", true, true); err == nil {
		u.InputNetflow = &inputNetflow
		u.Type = CreateInputRequestTypeInputNetflow
		return nil
	}

	var inputGooglePubsub InputGooglePubsub = InputGooglePubsub{}
	if err := utils.UnmarshalJSON(data, &inputGooglePubsub, "", true, true); err == nil {
		u.InputGooglePubsub = &inputGooglePubsub
		u.Type = CreateInputRequestTypeInputGooglePubsub
		return nil
	}

	var inputTcpjson InputTcpjson = InputTcpjson{}
	if err := utils.UnmarshalJSON(data, &inputTcpjson, "", true, true); err == nil {
		u.InputTcpjson = &inputTcpjson
		u.Type = CreateInputRequestTypeInputTcpjson
		return nil
	}

	var inputOffice365Service InputOffice365Service = InputOffice365Service{}
	if err := utils.UnmarshalJSON(data, &inputOffice365Service, "", true, true); err == nil {
		u.InputOffice365Service = &inputOffice365Service
		u.Type = CreateInputRequestTypeInputOffice365Service
		return nil
	}

	var inputTCP InputTCP = InputTCP{}
	if err := utils.UnmarshalJSON(data, &inputTCP, "", true, true); err == nil {
		u.InputTCP = &inputTCP
		u.Type = CreateInputRequestTypeInputTCP
		return nil
	}

	var inputWiz InputWiz = InputWiz{}
	if err := utils.UnmarshalJSON(data, &inputWiz, "", true, true); err == nil {
		u.InputWiz = &inputWiz
		u.Type = CreateInputRequestTypeInputWiz
		return nil
	}

	var inputFirehose InputFirehose = InputFirehose{}
	if err := utils.UnmarshalJSON(data, &inputFirehose, "", true, true); err == nil {
		u.InputFirehose = &inputFirehose
		u.Type = CreateInputRequestTypeInputFirehose
		return nil
	}

	var inputCriblHTTP InputCriblHTTP = InputCriblHTTP{}
	if err := utils.UnmarshalJSON(data, &inputCriblHTTP, "", true, true); err == nil {
		u.InputCriblHTTP = &inputCriblHTTP
		u.Type = CreateInputRequestTypeInputCriblHTTP
		return nil
	}

	var inputCriblLakeHTTP InputCriblLakeHTTP = InputCriblLakeHTTP{}
	if err := utils.UnmarshalJSON(data, &inputCriblLakeHTTP, "", true, true); err == nil {
		u.InputCriblLakeHTTP = &inputCriblLakeHTTP
		u.Type = CreateInputRequestTypeInputCriblLakeHTTP
		return nil
	}

	var inputDatadogAgent InputDatadogAgent = InputDatadogAgent{}
	if err := utils.UnmarshalJSON(data, &inputDatadogAgent, "", true, true); err == nil {
		u.InputDatadogAgent = &inputDatadogAgent
		u.Type = CreateInputRequestTypeInputDatadogAgent
		return nil
	}

	var inputOffice365Mgmt InputOffice365Mgmt = InputOffice365Mgmt{}
	if err := utils.UnmarshalJSON(data, &inputOffice365Mgmt, "", true, true); err == nil {
		u.InputOffice365Mgmt = &inputOffice365Mgmt
		u.Type = CreateInputRequestTypeInputOffice365Mgmt
		return nil
	}

	var inputFile components.InputFile = components.InputFile{}
	if err := utils.UnmarshalJSON(data, &inputFile, "", true, true); err == nil {
		u.InputFile = &inputFile
		u.Type = CreateInputRequestTypeInputFile
		return nil
	}

	var inputSplunk InputSplunk = InputSplunk{}
	if err := utils.UnmarshalJSON(data, &inputSplunk, "", true, true); err == nil {
		u.InputSplunk = &inputSplunk
		u.Type = CreateInputRequestTypeInputSplunk
		return nil
	}

	var inputWef InputWef = InputWef{}
	if err := utils.UnmarshalJSON(data, &inputWef, "", true, true); err == nil {
		u.InputWef = &inputWef
		u.Type = CreateInputRequestTypeInputWef
		return nil
	}

	var inputAppscope components.InputAppscope = components.InputAppscope{}
	if err := utils.UnmarshalJSON(data, &inputAppscope, "", true, true); err == nil {
		u.InputAppscope = &inputAppscope
		u.Type = CreateInputRequestTypeInputAppscope
		return nil
	}

	var inputHTTPRaw InputHTTPRaw = InputHTTPRaw{}
	if err := utils.UnmarshalJSON(data, &inputHTTPRaw, "", true, true); err == nil {
		u.InputHTTPRaw = &inputHTTPRaw
		u.Type = CreateInputRequestTypeInputHTTPRaw
		return nil
	}

	var inputHTTP InputHTTP = InputHTTP{}
	if err := utils.UnmarshalJSON(data, &inputHTTP, "", true, true); err == nil {
		u.InputHTTP = &inputHTTP
		u.Type = CreateInputRequestTypeInputHTTP
		return nil
	}

	var inputAzureBlob InputAzureBlob = InputAzureBlob{}
	if err := utils.UnmarshalJSON(data, &inputAzureBlob, "", true, true); err == nil {
		u.InputAzureBlob = &inputAzureBlob
		u.Type = CreateInputRequestTypeInputAzureBlob
		return nil
	}

	var inputZscalerHec InputZscalerHec = InputZscalerHec{}
	if err := utils.UnmarshalJSON(data, &inputZscalerHec, "", true, true); err == nil {
		u.InputZscalerHec = &inputZscalerHec
		u.Type = CreateInputRequestTypeInputZscalerHec
		return nil
	}

	var inputSqs InputSqs = InputSqs{}
	if err := utils.UnmarshalJSON(data, &inputSqs, "", true, true); err == nil {
		u.InputSqs = &inputSqs
		u.Type = CreateInputRequestTypeInputSqs
		return nil
	}

	var inputConfluentCloud InputConfluentCloud = InputConfluentCloud{}
	if err := utils.UnmarshalJSON(data, &inputConfluentCloud, "", true, true); err == nil {
		u.InputConfluentCloud = &inputConfluentCloud
		u.Type = CreateInputRequestTypeInputConfluentCloud
		return nil
	}

	var inputKinesis InputKinesis = InputKinesis{}
	if err := utils.UnmarshalJSON(data, &inputKinesis, "", true, true); err == nil {
		u.InputKinesis = &inputKinesis
		u.Type = CreateInputRequestTypeInputKinesis
		return nil
	}

	var inputEventhub InputEventhub = InputEventhub{}
	if err := utils.UnmarshalJSON(data, &inputEventhub, "", true, true); err == nil {
		u.InputEventhub = &inputEventhub
		u.Type = CreateInputRequestTypeInputEventhub
		return nil
	}

	var inputKafka InputKafka = InputKafka{}
	if err := utils.UnmarshalJSON(data, &inputKafka, "", true, true); err == nil {
		u.InputKafka = &inputKafka
		u.Type = CreateInputRequestTypeInputKafka
		return nil
	}

	var inputElastic InputElastic = InputElastic{}
	if err := utils.UnmarshalJSON(data, &inputElastic, "", true, true); err == nil {
		u.InputElastic = &inputElastic
		u.Type = CreateInputRequestTypeInputElastic
		return nil
	}

	var inputSplunkHec InputSplunkHec = InputSplunkHec{}
	if err := utils.UnmarshalJSON(data, &inputSplunkHec, "", true, true); err == nil {
		u.InputSplunkHec = &inputSplunkHec
		u.Type = CreateInputRequestTypeInputSplunkHec
		return nil
	}

	var inputOffice365MsgTrace InputOffice365MsgTrace = InputOffice365MsgTrace{}
	if err := utils.UnmarshalJSON(data, &inputOffice365MsgTrace, "", true, true); err == nil {
		u.InputOffice365MsgTrace = &inputOffice365MsgTrace
		u.Type = CreateInputRequestTypeInputOffice365MsgTrace
		return nil
	}

	var inputLoki InputLoki = InputLoki{}
	if err := utils.UnmarshalJSON(data, &inputLoki, "", true, true); err == nil {
		u.InputLoki = &inputLoki
		u.Type = CreateInputRequestTypeInputLoki
		return nil
	}

	var inputPrometheusRw InputPrometheusRw = InputPrometheusRw{}
	if err := utils.UnmarshalJSON(data, &inputPrometheusRw, "", true, true); err == nil {
		u.InputPrometheusRw = &inputPrometheusRw
		u.Type = CreateInputRequestTypeInputPrometheusRw
		return nil
	}

	var inputCrowdstrike InputCrowdstrike = InputCrowdstrike{}
	if err := utils.UnmarshalJSON(data, &inputCrowdstrike, "", true, true); err == nil {
		u.InputCrowdstrike = &inputCrowdstrike
		u.Type = CreateInputRequestTypeInputCrowdstrike
		return nil
	}

	var inputPrometheus InputPrometheus = InputPrometheus{}
	if err := utils.UnmarshalJSON(data, &inputPrometheus, "", true, true); err == nil {
		u.InputPrometheus = &inputPrometheus
		u.Type = CreateInputRequestTypeInputPrometheus
		return nil
	}

	var inputEdgePrometheus InputEdgePrometheus = InputEdgePrometheus{}
	if err := utils.UnmarshalJSON(data, &inputEdgePrometheus, "", true, true); err == nil {
		u.InputEdgePrometheus = &inputEdgePrometheus
		u.Type = CreateInputRequestTypeInputEdgePrometheus
		return nil
	}

	var inputS3 InputS3 = InputS3{}
	if err := utils.UnmarshalJSON(data, &inputS3, "", true, true); err == nil {
		u.InputS3 = &inputS3
		u.Type = CreateInputRequestTypeInputS3
		return nil
	}

	var inputSecurityLake InputSecurityLake = InputSecurityLake{}
	if err := utils.UnmarshalJSON(data, &inputSecurityLake, "", true, true); err == nil {
		u.InputSecurityLake = &inputSecurityLake
		u.Type = CreateInputRequestTypeInputSecurityLake
		return nil
	}

	var inputOpenTelemetry InputOpenTelemetry = InputOpenTelemetry{}
	if err := utils.UnmarshalJSON(data, &inputOpenTelemetry, "", true, true); err == nil {
		u.InputOpenTelemetry = &inputOpenTelemetry
		u.Type = CreateInputRequestTypeInputOpenTelemetry
		return nil
	}

	var inputS3Inventory InputS3Inventory = InputS3Inventory{}
	if err := utils.UnmarshalJSON(data, &inputS3Inventory, "", true, true); err == nil {
		u.InputS3Inventory = &inputS3Inventory
		u.Type = CreateInputRequestTypeInputS3Inventory
		return nil
	}

	var inputMsk InputMsk = InputMsk{}
	if err := utils.UnmarshalJSON(data, &inputMsk, "", true, true); err == nil {
		u.InputMsk = &inputMsk
		u.Type = CreateInputRequestTypeInputMsk
		return nil
	}

	var inputSplunkSearch InputSplunkSearch = InputSplunkSearch{}
	if err := utils.UnmarshalJSON(data, &inputSplunkSearch, "", true, true); err == nil {
		u.InputSplunkSearch = &inputSplunkSearch
		u.Type = CreateInputRequestTypeInputSplunkSearch
		return nil
	}

	var inputSyslog InputSyslog = InputSyslog{}
	if err := utils.UnmarshalJSON(data, &inputSyslog, "", true, true); err == nil {
		u.InputSyslog = &inputSyslog
		u.Type = CreateInputRequestTypeInputSyslog
		return nil
	}

	var inputGrafana InputGrafana = InputGrafana{}
	if err := utils.UnmarshalJSON(data, &inputGrafana, "", true, true); err == nil {
		u.InputGrafana = &inputGrafana
		u.Type = CreateInputRequestTypeInputGrafana
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for CreateInputRequest", string(data))
}

func (u CreateInputRequest) MarshalJSON() ([]byte, error) {
	if u.InputCollection != nil {
		return utils.MarshalJSON(u.InputCollection, "", true)
	}

	if u.InputKafka != nil {
		return utils.MarshalJSON(u.InputKafka, "", true)
	}

	if u.InputMsk != nil {
		return utils.MarshalJSON(u.InputMsk, "", true)
	}

	if u.InputHTTP != nil {
		return utils.MarshalJSON(u.InputHTTP, "", true)
	}

	if u.InputSplunk != nil {
		return utils.MarshalJSON(u.InputSplunk, "", true)
	}

	if u.InputSplunkSearch != nil {
		return utils.MarshalJSON(u.InputSplunkSearch, "", true)
	}

	if u.InputSplunkHec != nil {
		return utils.MarshalJSON(u.InputSplunkHec, "", true)
	}

	if u.InputAzureBlob != nil {
		return utils.MarshalJSON(u.InputAzureBlob, "", true)
	}

	if u.InputElastic != nil {
		return utils.MarshalJSON(u.InputElastic, "", true)
	}

	if u.InputConfluentCloud != nil {
		return utils.MarshalJSON(u.InputConfluentCloud, "", true)
	}

	if u.InputGrafana != nil {
		return utils.MarshalJSON(u.InputGrafana, "", true)
	}

	if u.InputLoki != nil {
		return utils.MarshalJSON(u.InputLoki, "", true)
	}

	if u.InputPrometheusRw != nil {
		return utils.MarshalJSON(u.InputPrometheusRw, "", true)
	}

	if u.InputPrometheus != nil {
		return utils.MarshalJSON(u.InputPrometheus, "", true)
	}

	if u.InputEdgePrometheus != nil {
		return utils.MarshalJSON(u.InputEdgePrometheus, "", true)
	}

	if u.InputOffice365Mgmt != nil {
		return utils.MarshalJSON(u.InputOffice365Mgmt, "", true)
	}

	if u.InputOffice365Service != nil {
		return utils.MarshalJSON(u.InputOffice365Service, "", true)
	}

	if u.InputOffice365MsgTrace != nil {
		return utils.MarshalJSON(u.InputOffice365MsgTrace, "", true)
	}

	if u.InputEventhub != nil {
		return utils.MarshalJSON(u.InputEventhub, "", true)
	}

	if u.InputExec != nil {
		return utils.MarshalJSON(u.InputExec, "", true)
	}

	if u.InputFirehose != nil {
		return utils.MarshalJSON(u.InputFirehose, "", true)
	}

	if u.InputGooglePubsub != nil {
		return utils.MarshalJSON(u.InputGooglePubsub, "", true)
	}

	if u.InputCribl != nil {
		return utils.MarshalJSON(u.InputCribl, "", true)
	}

	if u.InputCriblTCP != nil {
		return utils.MarshalJSON(u.InputCriblTCP, "", true)
	}

	if u.InputCriblHTTP != nil {
		return utils.MarshalJSON(u.InputCriblHTTP, "", true)
	}

	if u.InputCriblLakeHTTP != nil {
		return utils.MarshalJSON(u.InputCriblLakeHTTP, "", true)
	}

	if u.InputTcpjson != nil {
		return utils.MarshalJSON(u.InputTcpjson, "", true)
	}

	if u.InputSystemMetrics != nil {
		return utils.MarshalJSON(u.InputSystemMetrics, "", true)
	}

	if u.InputSystemState != nil {
		return utils.MarshalJSON(u.InputSystemState, "", true)
	}

	if u.InputKubeMetrics != nil {
		return utils.MarshalJSON(u.InputKubeMetrics, "", true)
	}

	if u.InputKubeLogs != nil {
		return utils.MarshalJSON(u.InputKubeLogs, "", true)
	}

	if u.InputKubeEvents != nil {
		return utils.MarshalJSON(u.InputKubeEvents, "", true)
	}

	if u.InputWindowsMetrics != nil {
		return utils.MarshalJSON(u.InputWindowsMetrics, "", true)
	}

	if u.InputCrowdstrike != nil {
		return utils.MarshalJSON(u.InputCrowdstrike, "", true)
	}

	if u.InputDatadogAgent != nil {
		return utils.MarshalJSON(u.InputDatadogAgent, "", true)
	}

	if u.InputDatagen != nil {
		return utils.MarshalJSON(u.InputDatagen, "", true)
	}

	if u.InputHTTPRaw != nil {
		return utils.MarshalJSON(u.InputHTTPRaw, "", true)
	}

	if u.InputKinesis != nil {
		return utils.MarshalJSON(u.InputKinesis, "", true)
	}

	if u.InputCriblmetrics != nil {
		return utils.MarshalJSON(u.InputCriblmetrics, "", true)
	}

	if u.InputMetrics != nil {
		return utils.MarshalJSON(u.InputMetrics, "", true)
	}

	if u.InputS3 != nil {
		return utils.MarshalJSON(u.InputS3, "", true)
	}

	if u.InputS3Inventory != nil {
		return utils.MarshalJSON(u.InputS3Inventory, "", true)
	}

	if u.InputSnmp != nil {
		return utils.MarshalJSON(u.InputSnmp, "", true)
	}

	if u.InputOpenTelemetry != nil {
		return utils.MarshalJSON(u.InputOpenTelemetry, "", true)
	}

	if u.InputModelDrivenTelemetry != nil {
		return utils.MarshalJSON(u.InputModelDrivenTelemetry, "", true)
	}

	if u.InputSqs != nil {
		return utils.MarshalJSON(u.InputSqs, "", true)
	}

	if u.InputSyslog != nil {
		return utils.MarshalJSON(u.InputSyslog, "", true)
	}

	if u.InputFile != nil {
		return utils.MarshalJSON(u.InputFile, "", true)
	}

	if u.InputTCP != nil {
		return utils.MarshalJSON(u.InputTCP, "", true)
	}

	if u.InputAppscope != nil {
		return utils.MarshalJSON(u.InputAppscope, "", true)
	}

	if u.InputWef != nil {
		return utils.MarshalJSON(u.InputWef, "", true)
	}

	if u.InputWinEventLogs != nil {
		return utils.MarshalJSON(u.InputWinEventLogs, "", true)
	}

	if u.InputRawUDP != nil {
		return utils.MarshalJSON(u.InputRawUDP, "", true)
	}

	if u.InputJournalFiles != nil {
		return utils.MarshalJSON(u.InputJournalFiles, "", true)
	}

	if u.InputWiz != nil {
		return utils.MarshalJSON(u.InputWiz, "", true)
	}

	if u.InputNetflow != nil {
		return utils.MarshalJSON(u.InputNetflow, "", true)
	}

	if u.InputSecurityLake != nil {
		return utils.MarshalJSON(u.InputSecurityLake, "", true)
	}

	if u.InputZscalerHec != nil {
		return utils.MarshalJSON(u.InputZscalerHec, "", true)
	}

	return nil, errors.New("could not marshal union type CreateInputRequest: all fields are null")
}

// CreateInputResponseBody - a list of Source objects
type CreateInputResponseBody struct {
	// number of items present in the items array
	Count *int64             `json:"count,omitempty"`
	Items []components.Input `json:"items,omitempty"`
}

func (o *CreateInputResponseBody) GetCount() *int64 {
	if o == nil {
		return nil
	}
	return o.Count
}

func (o *CreateInputResponseBody) GetItems() []components.Input {
	if o == nil {
		return nil
	}
	return o.Items
}

type CreateInputResponse struct {
	HTTPMeta components.HTTPMetadata `json:"-"`
	// a list of Source objects
	Object *CreateInputResponseBody
}

func (o *CreateInputResponse) GetHTTPMeta() components.HTTPMetadata {
	if o == nil {
		return components.HTTPMetadata{}
	}
	return o.HTTPMeta
}

func (o *CreateInputResponse) GetObject() *CreateInputResponseBody {
	if o == nil {
		return nil
	}
	return o.Object
}
